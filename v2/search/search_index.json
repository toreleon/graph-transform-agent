{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"The 100 line AI agent that's actually useful <p>This is mini-swe-agent v2</p> <p>Read the migration guide. For the previous version, check out the v1 documentation or the v1 branch.</p> <p>In 2024, SWE-bench &amp; SWE-agent helped kickstart the coding agent revolution.</p> <p>We now ask: What if our agent was 100x simpler, and still worked nearly as well?</p> <p><code>mini</code> is</p> <ul> <li>Widely adopted: Used by Meta, NVIDIA, Essential AI, IBM, Nebius, Anyscale, Princeton University, Stanford University, and many more.</li> <li>Minimal: Just 100 lines of python (+100 total for env, model, script) \u2014 no fancy dependencies!</li> <li>Performant: Scores &gt;74% on the SWE-bench verified benchmark; starts much faster than Claude Code</li> <li>Deployable: Supports local environments, docker/podman, singularity/apptainer, bublewrap, contree, and more</li> <li>Compatible: Supports all models via litellm, openrouter, portkey, and more. Support for <code>/completion</code> and <code>/response</code> endpoints, interleaved thinking etc.</li> <li>Built by the Princeton &amp; Stanford team behind SWE-bench, SWE-agent, and more</li> <li>Tested: </li> </ul> Why use mini-SWE-agent for research? <p>SWE-agent jump-started the development of AI agents in 2024. Back then, we placed a lot of emphasis on tools and special interfaces for the agent. However, one year later, a lot of this is not needed at all to build a useful agent!</p> <p>In fact, the <code>mini</code> agent:</p> <ul> <li>Does not have any tools other than bash \u2014 it doesn't even use the tool-calling interface of the LMs.   This means that you can run it with literally any model.   When running in sandboxed environments you also don't need to take care of installing a single package \u2014 all it needs is bash.</li> <li>Has a completely linear history \u2014 every step of the agent just appends to the messages and that's it.   So there's no difference between the trajectory and the messages that you pass on to the LM.   Great for debugging &amp; fine-tuning.</li> <li>Executes actions with <code>subprocess.run</code> \u2014 every action is completely independent (as opposed to keeping a stateful shell session running). This makes it trivial to execute the actions in sandboxes (literally just switch out <code>subprocess.run</code> with <code>docker exec</code>) and to scale up effortlessly.   Seriously, this is a big deal, trust me.</li> </ul> <p>This makes it perfect as a baseline system and for a system that puts the language model (rather than the agent scaffold) in the middle of our attention. You can see the result on the SWE-bench (bash only) leaderboard, that evaluates the performance of different LMs with <code>mini</code>.</p> Why use mini-SWE-agent as a tool? <p>Some agents are overfitted research artifacts. Others are UI-heavy frontend monsters.</p> <p>The <code>mini</code> agent wants to be a hackable tool, not a black box.</p> <ul> <li>Simple enough to understand at a glance</li> <li>Convenient enough to use in daily workflows</li> <li>Flexible to extend</li> </ul> <p>Unlike other agents (including our own swe-agent), it is radically simpler, because it:</p> <ul> <li>Does not have any tools other than bash \u2014 it doesn't even use the tool-calling interface of the LMs.   Instead of implementing custom tools for every specific thing the agent might want to do, the focus is fully on the LM utilizing the shell to its full potential.   Want it to do something specific like opening a PR?   Just tell the LM to figure it out rather than spending time to implement it in the agent.</li> <li>Executes actions with <code>subprocess.run</code> \u2014 every action is completely independent (as opposed to keeping a stateful shell session running).   This is a big deal for the stability of the agent, trust me.</li> <li>Has a completely linear history \u2014 every step of the agent just appends to the messages that are passed to the LM in the next step and that's it.   This is great for debugging and understanding what the LM is prompted with.</li> </ul> Should I use mini-SWE-agent or swe-agent? <p>You should consider <code>mini-swe-agent</code> your default choice. In particular, you should use <code>mini-swe-agent</code> if</p> <ul> <li>You want a quick command line tool that works locally</li> <li>You want an agent with a very simple control flow</li> <li>You want even faster, simpler &amp; more stable sandboxing &amp; benchmark evaluations</li> <li>You are doing FT or RL and don't want to overfit to a specific agent scaffold</li> </ul> <p>You should use <code>swe-agent</code> if</p> <ul> <li>You want to experiment with different sets of tools, each with their own interface</li> <li>You want to experiment with different history processors</li> </ul> <p>What you get with both</p> <ul> <li>Excellent performance on SWE-Bench</li> <li>A trajectory browser</li> </ul> CLI (<code>mini</code>)  Batch inference Trajectory browser Python bindings <pre><code>agent = DefaultAgent(\n    LitellmModel(model_name=...),\n    LocalEnvironment(),\n)\nagent.run(\"Write a sudoku game\")</code></pre> <p>Upgrading to v2?</p> <p>Check out our v2 migration guide for all the changes and how to update your code.</p>"},{"location":"#continue-reading","title":"Continue reading:","text":"launch Installation &amp; Quick Start <p>Get started with mini-SWE-agent</p> flash_on Usage: Simple UI <p>Learn to use the <code>mini</code> command</p> help FAQ <p>Common questions and answers</p> settings Configuration <p>Setup and customize your agent</p> fitness_center Power up <p>Start hacking the agent!</p>"},{"location":"#news","title":"\ud83d\udce3 News","text":"<ul> <li>New tutorial on building minimal AI agents</li> <li>Nov 19: Gemini 3 Pro reaches 74% on SWE-bench verified with mini-swe-agent!</li> <li>Aug 19: New blogpost: Randomly switching between GPT-5 and Sonnet 4 boosts performance</li> </ul>"},{"location":"#new-features","title":"\ud83d\udce3 New features","text":"<p>Please check the github release notes for the latest updates.</p>"},{"location":"#documentation-updates","title":"\ud83d\udce3 Documentation updates","text":"<ul> <li>Jul 27: More notes on local models</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"SECURITY/","title":"Security Policy","text":""},{"location":"SECURITY/#security-policy","title":"Security Policy","text":""},{"location":"SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>Please contact Kilian Lieret (kl5675@princeton.edu), John Yang (johnby@stanford.edu), Carlos E. Jimenez (carlosej@princeton.edu), and Ofir Press (ofirp@princeton.edu).</p>"},{"location":"_footer/","title":"footer","text":"bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"\u2764\ufe0f Contributing","text":"<p>We happily accept contributions!</p>"},{"location":"contributing/#areas-of-help","title":"Areas of help","text":"<ul> <li>Documentation, examples, tutorials, etc. In particular, we're looking for<ul> <li>examples of how this library is used in the wild</li> <li>additional examples for the cookbook</li> </ul> </li> <li>Support for more models (anything where <code>litellm</code> doesn't work out of the box)</li> <li>Support for more environments &amp; deployments (e.g., run it as a github action, etc.)</li> <li>Take a look at the issues and look for issues marked <code>good-first-issue</code> or <code>help-wanted</code> (please read the guidelines below first)</li> </ul>"},{"location":"contributing/#design-architecture","title":"Design &amp; Architecture","text":"<ul> <li><code>mini-swe-agent</code> aims to stay minimalistic, hackable, and of high quality code.</li> <li>To extend features, we prefer to add a new version of the one of the four components (see cookbook), rather than making the existing components more complex.</li> <li>Components should be relatively self-contained, but if there are utilities that might be shared, add a <code>utils</code> folder (like this one). But keep it simple!</li> <li>If your component is a bit more specific, add it into an <code>extra</code> folder (like this one)</li> <li>Our target audience is anyone who doesn't shy away from modifying a bit of code (especially a run script) to get what they want.</li> <li>Therefore, not everything needs to be configurable with the config files, but it should be easy to create a run script that makes use of it.</li> <li>Many LMs write very verbose code -- please clean it up! Same goes for the tests. They should still be concise and readable.</li> <li>Please install <code>pre-commit</code> (<code>pip install pre-commit &amp;&amp; pre-commit install</code>) and run it before committing. This will enforce our style guide.</li> </ul>"},{"location":"contributing/#development-setup","title":"Development setup","text":"<p>Make sure to follow the dev setup instructions in quickstart.md.</p> <p>After that you can run <code>pytest</code> with <code>pytest -n auto</code> (this parallelizes the tests across all cores for speedup).</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#faq","title":"FAQ","text":""},{"location":"faq/#general","title":"General","text":"<p>Does mini-SWE-agent work on my system?</p> <p>mini-SWE-agent should work on any system that has a bash shell or uses a container runtime (e.g., docker, singularity, apptainer, etc.) to emulate one.</p> Should I use mini-SWE-agent or swe-agent? <p>You should use <code>mini-swe-agent</code> if</p> <ul> <li>You want a quick command line tool that works locally</li> <li>You want an agent with a very simple control flow</li> <li>You want even faster, simpler &amp; more stable sandboxing &amp; benchmark evaluations</li> <li>You are doing FT or RL and don't want to overfit to a specific agent scaffold</li> </ul> <p>You should use <code>swe-agent</code> if</p> <ul> <li>You need specific tools or want to experiment with different tools</li> <li>You want to experiment with different history processors</li> <li>You want very powerful yaml configuration without touching code</li> </ul> <p>What you get with both</p> <ul> <li>Excellent performance on SWE-Bench</li> <li>A trajectory browser</li> </ul> How is <code>mini</code> simpler than <code>swe-agent</code>? <p><code>mini</code> is simpler than <code>swe-agent</code> because it:</p> <ul> <li>Does not have any tools other than bash \u2014 it doesn't even use the tool-calling interface of the LMs.   This means you don't have to install anything in any environment you're running in. <code>bash</code> is all you need.</li> <li>Has a completely linear history \u2014 every step of the agent just appends to the messages and that's it.</li> <li>Executes actions with <code>subprocess.run</code> \u2014 every action is completely independent (as opposed to keeping a stateful shell session running).   This avoids so many issues, trust me.</li> </ul> What are the limitations of mini-SWE-agent? <p>mini-SWE-agent can be extended trivially in various ways, the following assumes the default setup. As reflected in the high SWE-bench scores, none of the following limitations are a problem in practice.</p> <ul> <li>No tools other than bash</li> <li>Actions are parsed from triple-backtick blocks (rather than assuming a function calling/tool calling format)</li> <li>By default, actions are executed as <code>subprocess.run</code>, i.e., every action is independent of the previous ones.   (meaning that the agent cannot change directories or export environment variables; however environment variables   can be set per-action). This avoids so many issues, trust me.</li> </ul> <p>If you want more flexibility with these items, you can use SWE-agent instead.</p> Where is global configuration stored? <p>The global configuration is stored in the <code>.env</code> file in the config directory. The location is printed when you run <code>mini --help</code>.</p> <p>The <code>.env</code> file is a simple key-value file that is read by the <code>dotenv</code> library.</p>"},{"location":"faq/#models","title":"Models","text":"<p>What models do you support?</p> <p>Currently, mini-SWE-agent supports all models that are supported by litellm or OpenRouter and we're open to extend the <code>models/</code> directory with more models should <code>litellm</code> not support them.</p> <p>How do I set the API key for a model?</p> <p>The API key can be stored either as an environment variable (note that enviroinment variables are not persistent unless you set them in your <code>~/.bashrc</code> or similar), or as a permanent key in the config file.</p> <p>To temporarily set the API key as an environment variable, you can use the following command:</p> <pre><code>export OPENAI_API_KEY=sk-test123\n</code></pre> <p>To permanently set the API key in the config file, you can use the following command:</p> <pre><code>mini-extra config set OPENAI_API_KEY sk-test123\n</code></pre> <p>Alternatively, you can directly edit the <code>.env</code> file in the config directory (the location is printed when you run <code>mini --help</code>).</p> <p>How can I set the default model?</p> <p>The default model is stored in the config/environment as <code>MSWEA_MODEL_NAME</code>. To permanently change it:</p> <pre><code>mini-extra config set MSWEA_MODEL_NAME anthropic/claude-sonnet-4-5-20250929\n</code></pre> <p>Alternatively, you can directly edit the <code>.env</code> file in the config directory (the location is printed when you run <code>mini --help</code>).</p>"},{"location":"faq/#minutia","title":"Minutia","text":"Why is not needing a running shell session such a big deal? <p>Most agents so far kept a running shell session. Every action from the agent was executed in this session. However, this is far from trivial:</p> <ol> <li>It's not obvious when a command has terminated. Essentially you're just pasting input into the shell session, and press enter\u2014but when do you stop reading output?    We've experimented with various heuristics (watching PIDs, watching for the shell to go back to the prompt, etc.) but all of them were flaky.    The <code>mini</code> agent doesn't need any of this!</li> <li>Particularly bad commands from the LM can kill the shell session. Then what?</li> <li>Interrupting a command running in a shell session can also mess up the shell itself and can in particular interfere with all the following outputs you want to extract.</li> </ol> <p><code>mini</code> is different: There is no running shell session. Every action is executed as a subprocess, that means every action is independent of the previous ones (it is literally a <code>subprocess.run</code>/<code>os.system</code>/<code>docker exec</code> call).</p> <p>This means that the agent cannot even change directories or export environment variables. But you don't need this! You can always prefix <code>cd /path/to/project</code> or <code>export FOO=bar</code> to every action (and in fact some LMs like Claude will do that even if you don't ask them to).</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"quickstart/","title":"Quick start","text":""},{"location":"quickstart/#quick-start","title":"Quick start","text":"<p>Installation Options</p> pipuv (isolated)pipx (isolated)From source/dev <p>Use pip to install <code>mini</code> in your current environment:</p> <pre><code>pip install --pre mini-swe-agent\n</code></pre> <p>And try our command line interface</p> <pre><code>mini  # CLI\nmini-extra  # extra utilities\n</code></pre> <p>Use <code>uv</code>/<code>uvx</code> (installation) to directly run the <code>mini</code> CLI. Use this if you're only interested in the CLI but don't need python bindings (<code>mini</code> will be installed in an anonymous virtual environment).</p> <p>Quickly install + run:</p> <pre><code>uvx --prerelease=allow mini-swe-agent  # CLI\nuvx --prerelease=allow --from mini-swe-agent mini-extra  # extra utilities\n</code></pre> <p>Permanently install</p> <pre><code>uv tool install --prerelease=allow mini-swe-agent\n# then\nmini  # CLI\nmini-extra  # extra utilities\n</code></pre> <p>Use pipx (installation) to directly run the <code>mini</code> CLI. Use this if you're only interested in the CLI but don't need python bindings (<code>mini</code> will be installed in an anonymous virtual environment).</p> <p>Quick install + run:</p> <pre><code># CLI\npipx run --pip-args='--pre' mini-swe-agent\n# Extra utilities\npipx run --pip-args='--pre' --spec mini-swe-agent mini-extra\n</code></pre> <p>or for a persistent installation (recommended):</p> <pre><code>pipx install --pip-args='--pre' mini-swe-agent\n# then\nmini  # CLI\nmini-extra  # extra utilities\n</code></pre> <p>If the invocation doesn't immediately work, you might need to run <code>pipx ensurepath</code>.</p> <p>For development or if you want to customize the agent:</p> <pre><code>git clone https://github.com/SWE-agent/mini-swe-agent.git\ncd mini-swe-agent\npip install -e .\n</code></pre> <p>Then run:</p> <pre><code>mini  # CLI\nmini-extra  # extra utilities\n</code></pre> <p>Or pick a run script:</p> <pre><code>python src/minisweagent/run/hello_world.py\n</code></pre> <p>If you are planning to contribute, please also install the dev dependencies and <code>pre-commit</code> hooks:</p> <pre><code>pip install -e '.[dev]'\npip install pre-commit &amp;&amp; pre-commit install\n</code></pre> <p>To check your installation, you can run <code>pytest -n auto</code> in the root folder. This should run all tests in parallel (should take ~3min to run).</p> <p>Note that there are still some extra dependencies that are not installed by default (basically anything that is in an <code>.../extra/...</code> folder). If you truly want to get the maximal package, you can run <code>pip install -e '.[full]'</code></p> <p>Changelog</p> <p>Please see the github release notes for recent changes.</p> <p>Upgrading to v2?</p> <p>Check out our v2 migration guide for all the changes and how to update your code.</p> <p>Example Prompts</p> <p>Try mini-SWE-agent with these example prompts:</p> <ul> <li>Implement a Sudoku solver in python in the <code>sudoku</code> folder. Make sure the codebase is modular and well tested with pytest.</li> <li>Please run pytest on the current project, discover failing unittests and help me fix them. Always make sure to test the final solution.</li> <li>Help me document &amp; type my codebase by adding short docstrings and type hints.</li> </ul>"},{"location":"quickstart/#models","title":"Models","text":"<p>Models should be set up the first time you run <code>mini</code></p> <ul> <li>If you missed the setup wizard, just run <code>mini-extra config setup</code></li> <li>For more information, please check the model setup quickstart.</li> <li>If you want to use local models, please check this guide.</li> </ul> <p>Tip: Please always include the provider in the model name, e.g., <code>anthropic/claude-...</code>.</p> <p>Which model to use?</p> <p>We recommend using <code>anthropic/claude-sonnet-4-5-20250929</code> for most tasks. For openai models, we recommend using <code>openai/gpt-5</code> or <code>openai/gpt-5-mini</code>. You can check scores of different models at our SWE-bench (bash-only) leaderboard.</p>"},{"location":"advanced/control_flow/","title":"Understanding the agent","text":""},{"location":"advanced/control_flow/#agent-control-flow","title":"Agent control flow","text":"<p>Understanding AI agent basics</p> <p>We also recently created a long tutorial on understanding the basics of building an AI agent: View it here.</p> <p>Understanding the default agent</p> <ul> <li>This guide shows the control flow of the default agent.</li> <li>After this, you're ready to remix &amp; extend mini</li> </ul> <p>The following diagram shows the control flow of the mini agent:</p> <pre><code>flowchart TD\n    subgraph run[\"&lt;b&gt;&lt;code&gt;Agent.run(task)&lt;/code&gt;&lt;/b&gt;\"]\n        direction TB\n        A[\"&lt;b&gt;&lt;code&gt;Initialize messages&lt;/code&gt;&lt;/b&gt;\"] --&gt; B\n        B[\"&lt;b&gt;&lt;code&gt;Agent.step&lt;/code&gt;&lt;/b&gt;\"] --&gt; C{\"&lt;b&gt;&lt;code&gt;Exception?&lt;/code&gt;&lt;/b&gt;\"}\n        C --&gt;|Yes| D[\"&lt;b&gt;&lt;code&gt;Agent.add_messages&lt;/code&gt;&lt;/b&gt;&lt;br/&gt;(also re-raises exceptions that don't inherit from InterruptAgentFlow)\"]\n        C --&gt;|No| E{\"&lt;b&gt;&lt;code&gt;messages[-1].role == exit?&lt;/code&gt;&lt;/b&gt;\"}\n        D --&gt; E\n        E --&gt;|No| B\n        E --&gt;|Yes| F[\"&lt;b&gt;&lt;code&gt;Return result&lt;/code&gt;&lt;/b&gt;\"]\n    end\n\n    subgraph step[\"&lt;b&gt;&lt;code&gt;Agent.step()&lt;/code&gt;&lt;/b&gt;&lt;br&gt;Single iteration&lt;/br&gt;\"]\n        direction TB\n        S1[\"&lt;b&gt;&lt;code&gt;Agent.query&lt;/code&gt;&lt;/b&gt;\"] --&gt; S2[\"&lt;b&gt;&lt;code&gt;Agent.execute_actions&lt;/code&gt;&lt;/b&gt;\"]\n    end\n\n    subgraph query[\"&lt;b&gt;&lt;code&gt;Agent.query()&lt;/code&gt;&lt;/b&gt;&lt;br&gt;Also checks for cost limits&lt;/br&gt;&lt;br&gt;&lt;/br&gt;\"]\n        direction TB\n        Q3[\"&lt;b&gt;&lt;code&gt;Model.query&lt;/code&gt;&lt;/b&gt;\"] --&gt; Q4[\"&lt;b&gt;&lt;code&gt;Agent.add_messages&lt;/code&gt;&lt;/b&gt;\"]\n    end\n\n    subgraph execute_actions[\"&lt;b&gt;&lt;code&gt;Agent.execute_actions(message)&lt;/code&gt;&lt;/b&gt;\"]\n        direction TB\n        E2[\"&lt;b&gt;&lt;code&gt;Environment.execute&lt;/code&gt;&lt;/b&gt;&lt;br/&gt;Also raises the Submitted exception if we're done\"] --&gt; E3[\"&lt;b&gt;&lt;code&gt;Model.format_observation_messages&lt;/code&gt;&lt;/b&gt;\"]\n        E3 --&gt; E4[\"&lt;b&gt;&lt;code&gt;Agent.add_messages&lt;/code&gt;&lt;/b&gt;\"]\n    end\n\n    B -.-&gt; step\n    S1 -.-&gt; query\n    S2 -.-&gt; execute_actions</code></pre> <p>And here is the code that implements it:</p> Default agent class <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>\"\"\"Basic agent class. See https://mini-swe-agent.com/latest/advanced/control_flow/ for visual explanation\nor https://minimal-agent.com for a tutorial on the basic building principles.\n\"\"\"\n\nimport json\nimport logging\nimport traceback\nfrom pathlib import Path\n\nfrom jinja2 import StrictUndefined, Template\nfrom pydantic import BaseModel\n\nfrom minisweagent import Environment, Model, __version__\nfrom minisweagent.exceptions import InterruptAgentFlow, LimitsExceeded\nfrom minisweagent.utils.serialize import recursive_merge\n\n\nclass AgentConfig(BaseModel):\n    \"\"\"Check the config files in minisweagent/config for example settings.\"\"\"\n\n    system_template: str\n    \"\"\"Template for the system message (the first message).\"\"\"\n    instance_template: str\n    \"\"\"Template for the first user message specifying the task (the second message overall).\"\"\"\n    step_limit: int = 0\n    \"\"\"Maximum number of steps the agent can take.\"\"\"\n    cost_limit: float = 3.0\n    \"\"\"Stop agent after exceeding (!) this cost.\"\"\"\n    output_path: Path | None = None\n    \"\"\"Save the trajectory to this path.\"\"\"\n\n\nclass DefaultAgent:\n    def __init__(self, model: Model, env: Environment, *, config_class: type = AgentConfig, **kwargs):\n        \"\"\"See the `AgentConfig` class for permitted keyword arguments.\"\"\"\n        self.config = config_class(**kwargs)\n        self.messages: list[dict] = []\n        self.model = model\n        self.env = env\n        self.extra_template_vars = {}\n        self.logger = logging.getLogger(\"agent\")\n        self.cost = 0.0\n        self.n_calls = 0\n\n    def get_template_vars(self, **kwargs) -&gt; dict:\n        return recursive_merge(\n            self.config.model_dump(),\n            self.env.get_template_vars(),\n            self.model.get_template_vars(),\n            {\"n_model_calls\": self.n_calls, \"model_cost\": self.cost},\n            self.extra_template_vars,\n            kwargs,\n        )\n\n    def _render_template(self, template: str) -&gt; str:\n        return Template(template, undefined=StrictUndefined).render(**self.get_template_vars())\n\n    def add_messages(self, *messages: dict) -&gt; list[dict]:\n        self.logger.debug(messages)  # set log level to debug to see\n        self.messages.extend(messages)\n        return list(messages)\n\n    def handle_uncaught_exception(self, e: Exception) -&gt; list[dict]:\n        return self.add_messages(\n            self.model.format_message(\n                role=\"exit\",\n                content=str(e),\n                extra={\n                    \"exit_status\": type(e).__name__,\n                    \"submission\": \"\",\n                    \"exception_str\": str(e),\n                    \"traceback\": traceback.format_exc(),\n                },\n            )\n        )\n\n    def run(self, task: str = \"\", **kwargs) -&gt; dict:\n        \"\"\"Run step() until agent is finished. Returns dictionary with exit_status, submission keys.\"\"\"\n        self.extra_template_vars |= {\"task\": task, **kwargs}\n        self.messages = []\n        self.add_messages(\n            self.model.format_message(role=\"system\", content=self._render_template(self.config.system_template)),\n            self.model.format_message(role=\"user\", content=self._render_template(self.config.instance_template)),\n        )\n        while True:\n            try:\n                self.step()\n            except InterruptAgentFlow as e:\n                self.add_messages(*e.messages)\n            except Exception as e:\n                self.handle_uncaught_exception(e)\n                raise\n            finally:\n                self.save(self.config.output_path)\n            if self.messages[-1].get(\"role\") == \"exit\":\n                break\n        return self.messages[-1].get(\"extra\", {})\n\n    def step(self) -&gt; list[dict]:\n        \"\"\"Query the LM, execute actions.\"\"\"\n        return self.execute_actions(self.query())\n\n    def query(self) -&gt; dict:\n        \"\"\"Query the model and return model messages. Override to add hooks.\"\"\"\n        if 0 &lt; self.config.step_limit &lt;= self.n_calls or 0 &lt; self.config.cost_limit &lt;= self.cost:\n            raise LimitsExceeded(\n                {\n                    \"role\": \"exit\",\n                    \"content\": \"LimitsExceeded\",\n                    \"extra\": {\"exit_status\": \"LimitsExceeded\", \"submission\": \"\"},\n                }\n            )\n        self.n_calls += 1\n        message = self.model.query(self.messages)\n        self.cost += message.get(\"extra\", {}).get(\"cost\", 0.0)\n        self.add_messages(message)\n        return message\n\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        \"\"\"Execute actions in message, add observation messages, return them.\"\"\"\n        outputs = [self.env.execute(action) for action in message.get(\"extra\", {}).get(\"actions\", [])]\n        return self.add_messages(*self.model.format_observation_messages(message, outputs, self.get_template_vars()))\n\n    def serialize(self, *extra_dicts) -&gt; dict:\n        \"\"\"Serialize agent state to a json-compatible nested dictionary for saving.\"\"\"\n        last_message = self.messages[-1] if self.messages else {}\n        last_extra = last_message.get(\"extra\", {})\n        agent_data = {\n            \"info\": {\n                \"model_stats\": {\n                    \"instance_cost\": self.cost,\n                    \"api_calls\": self.n_calls,\n                },\n                \"config\": {\n                    \"agent\": self.config.model_dump(mode=\"json\"),\n                    \"agent_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n                \"mini_version\": __version__,\n                \"exit_status\": last_extra.get(\"exit_status\", \"\"),\n                \"submission\": last_extra.get(\"submission\", \"\"),\n            },\n            \"messages\": self.messages,\n            \"trajectory_format\": \"mini-swe-agent-1.1\",\n        }\n        return recursive_merge(agent_data, self.model.serialize(), self.env.serialize(), *extra_dicts)\n\n    def save(self, path: Path | None, *extra_dicts) -&gt; dict:\n        \"\"\"Save the trajectory of the agent to a file if path is given. Returns full serialized data.\n        You can pass additional dictionaries with extra data to be (recursively) merged into the output data.\n        \"\"\"\n        data = self.serialize(*extra_dicts)\n        if path:\n            path.parent.mkdir(parents=True, exist_ok=True)\n            path.write_text(json.dumps(data, indent=2))\n        return data\n</code></pre> <p>Essentially, <code>DefaultAgent.run</code> calls <code>DefaultAgent.step</code> in a loop until the agent has finished its task.</p> <p>The <code>step</code> method is the core of the agent:</p> <pre><code>def step(self) -&gt; list[dict]:\n    return self.execute_actions(self.query())\n</code></pre> <p>It does the following:</p> <ol> <li>Queries the model for a response based on the current messages (<code>DefaultAgent.query</code>, calling <code>Model.query</code>)</li> <li>Executes all actions in the response (<code>DefaultAgent.execute_actions</code>, calling <code>Environment.execute</code> for each action)</li> <li>Formats the observation messages via <code>Model.format_observation_messages</code></li> <li>Adds the observations to the messages</li> </ol> <p>Here's <code>query</code>:</p> <pre><code>def query(self) -&gt; dict:\n    # ... limit checks ...\n    message = self.model.query(self.messages)\n    self.add_messages(message)\n    return message\n</code></pre> <p>And <code>execute_actions</code>:</p> <pre><code>def execute_actions(self, message: dict) -&gt; list[dict]:\n    outputs = [self.env.execute(action) for action in message.get...\n    return self.add_messages(*self.model.format_observation_messages(...))\n</code></pre> <p>The interesting bit is how we handle error conditions and the finish condition: This uses exceptions that inherit from <code>InterruptAgentFlow</code>. All these exceptions carry messages that get added to the trajectory.</p> <ul> <li> <p><code>Submitted</code> is raised when the agent has finished its task. For example, the environment checks if the command output starts with a magic string:</p> <pre><code># In Environment.execute\ndef _check_finished(self, output: dict):\n    lines = output.get(\"output\", \"\").lstrip().splitlines(keepends=True)\n    if lines and lines[0].strip() == \"COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT\":\n        raise Submitted({\"role\": \"exit\", \"content\": ..., \"extra\": {...}})\n</code></pre> </li> <li> <p><code>LimitsExceeded</code> is raised when we hit a cost or step limit</p> </li> <li><code>FormatError</code> is raised when the output from the LM is not in the expected format</li> <li><code>TimeoutError</code> is raised when the action took too long to execute</li> <li><code>UserInterruption</code> is raised when the user interrupts the agent</li> </ul> <p>The <code>DefaultAgent.run</code> method catches these exceptions and handles them by adding the corresponding messages to the messages list. The loop continues until a message with <code>role=\"exit\"</code> is added.</p> <pre><code>while True:\n    try:\n        self.step()\n    except InterruptAgentFlow as e:\n        self.add_messages(*e.messages)\n    if self.messages[-1].get(\"role\") == \"exit\":\n        break\n</code></pre> <p>Using exceptions for the control flow is a lot easier than passing around flags and states, especially when extending or subclassing the agent.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"advanced/cookbook/","title":"Subclassing and more","text":""},{"location":"advanced/cookbook/#cookbook","title":"Cookbook","text":"<p>Remixing &amp; extending mini</p> <ul> <li>This guide shows how to mix the different components of the <code>mini</code> agent to create your own custom version.</li> <li>You might want to first take a look at the control flow of the default agent first</li> </ul> <p>Development setup</p> <p>Make sure to follow the dev setup instructions in quickstart.md.</p> <p>We provide several different entry points to the agent, for example hello world, or the default when calling <code>mini</code>.</p> <p>Want to cook up your custom version and the config is not enough? Just follow the recipe below:</p> <ol> <li>What's the control flow you need? Pick an agent class (e.g., simplest example, with human in the loop)</li> <li>How should actions be executed? Pick an environment class (e.g., local, or docker)</li> <li>How is the LM queried? Pick a model class (e.g., litellm)</li> <li>How to invoke the agent? Bind them all together in a run script, possibly reading from a config (e.g., hello world, or <code>mini</code> entry point)</li> </ol> <p>We aim to keep all of these components very simple, but offer lots of choice between them -- enough to cover a broad range of things that you might want to do.</p> <p>You can override the default entry point by setting the <code>MSWEA_DEFAULT_RUN</code> environment variable to the import path of your run script.</p>"},{"location":"advanced/cookbook/#hello-world","title":"Hello world","text":"<p>See Python bindings for the most basic example.</p>"},{"location":"advanced/cookbook/#mix-match","title":"Mix &amp; match","text":""},{"location":"advanced/cookbook/#models","title":"Models","text":"Hello world (use automatic model selection)Hello world (Litellm) <pre><code>from minisweagent.agents.default import DefaultAgent\nfrom minisweagent.models import get_model\nfrom minisweagent.environments.local import LocalEnvironment\n\nmodel_name = \"anthropic/claude-sonnet-4-5-20250929\"\n\nagent = DefaultAgent(\n    get_model(input_model_name=model_name),\n    LocalEnvironment(),\n)\nagent.run(task)\n</code></pre> <pre><code>from minisweagent.agents.default import DefaultAgent\nfrom minisweagent.models.litellm_model import LitellmModel\nfrom minisweagent.environments.local import LocalEnvironment\n\nmodel_name = \"gpt-4o\"\n\nagent = DefaultAgent(\n    LitellmModel(model_name=model_name),\n    LocalEnvironment(),\n)\nagent.run(task)\n</code></pre>"},{"location":"advanced/cookbook/#environments","title":"Environments","text":"Hello world with local executionHello world with docker execution <pre><code>from minisweagent.environments.local import LocalEnvironment\n\nagent = DefaultAgent(\n    LitellmModel(model_name=model_name),\n    LocalEnvironment(),\n)\n</code></pre> <pre><code>from minisweagent.environments.docker import DockerEnvironment\n\nagent = DefaultAgent(\n    LitellmModel(model_name=model_name),\n    DockerEnvironment(),\n)\n</code></pre>"},{"location":"advanced/cookbook/#agents","title":"Agents","text":"Default agentHuman in the loop <pre><code>from minisweagent.agents.default import DefaultAgent\nfrom minisweagent.models import get_model\nfrom minisweagent.environments.local import LocalEnvironment\n\nagent = DefaultAgent(\n    get_model(input_model_name=model_name),\n    LocalEnvironment(),\n)\n</code></pre> <pre><code>from minisweagent.agents.interactive import InteractiveAgent\nfrom minisweagent.models import get_model\nfrom minisweagent.environments.local import LocalEnvironment\n\nagent = InteractiveAgent(\n    get_model(input_model_name=model_name),\n    LocalEnvironment(),\n)\n</code></pre>"},{"location":"advanced/cookbook/#advanced","title":"Advanced","text":""},{"location":"advanced/cookbook/#customizing-execution","title":"Customizing execution","text":"<p>An agent that uses python function for some actions:</p> Subclassing the agentSubclassing the environment <pre><code>from minisweagent.agents.default import DefaultAgent\nimport shlex\n\ndef python_function(*args) -&gt; dict:\n    ...\n    return {\"output\": \"...\"}\n\nclass AgentWithPythonFunctions(DefaultAgent):\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        for action in message.get(\"extra\", {}).get(\"actions\", []):\n            command = action.get(\"command\", \"\")\n            if command.startswith(\"python_function\"):\n                args = shlex.split(command.removeprefix(\"python_function\").strip())\n                return self.add_messages(self.model.format_observation_messages(\n                    message, [python_function(*args)], self.get_template_vars()\n                ))\n        # everything else works as usual\n        return super().execute_actions(message)\n</code></pre> <pre><code>from minisweagent.agents.default import DefaultAgent\nfrom minisweagent.environments.local import LocalEnvironment\nimport shlex\n\ndef python_function(*args) -&gt; dict:\n    ...\n    return {\"output\": \"...\"}\n\nclass EnvironmentWithPythonFunctions(LocalEnvironment):\n    def execute(self, action: dict, cwd: str = \"\") -&gt; dict:\n        command = action.get(\"command\", \"\")\n        if command.startswith(\"python_function\"):\n            args = shlex.split(command.removeprefix(\"python_function\").strip())\n            return python_function(*args)\n        # all other commands are executed as usual\n        return super().execute(action, cwd)\n\nagent = DefaultAgent(\n    LitellmModel(model_name=model_name),\n    EnvironmentWithPythonFunctions(),\n)\n</code></pre> <p>An agent that exits when the <code>submit</code> command is issued:</p> Subclassing the agentSubclassing the environment <pre><code>from minisweagent.agents.default import DefaultAgent\nfrom minisweagent.exceptions import Submitted\n\nclass AgentQuitsOnSubmit(DefaultAgent):\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        for action in message.get(\"extra\", {}).get(\"actions\", []):\n            if action.get(\"command\", \"\") == \"submit\":\n                # The `Submitted` exception will be caught by the agent and\n                # the final output will be printed.\n                raise Submitted({\n                    \"role\": \"exit\",\n                    \"content\": \"The agent has finished its task.\",\n                    \"extra\": {\"exit_status\": \"Submitted\", \"submission\": \"\"},\n                })\n        return super().execute_actions(message)\n</code></pre> <pre><code>from minisweagent.agents.default import DefaultAgent\nfrom minisweagent.environments.local import LocalEnvironment\nfrom minisweagent.exceptions import Submitted\n\nclass EnvironmentQuitsOnSubmit(LocalEnvironment):\n    def execute(self, action: dict, cwd: str = \"\") -&gt; dict:\n        if action.get(\"command\", \"\") == \"submit\":\n            raise Submitted({\n                \"role\": \"exit\",\n                \"content\": \"The agent has finished its task.\",\n                \"extra\": {\"exit_status\": \"Submitted\", \"submission\": \"\"},\n            })\n        return super().execute(action, cwd)\n\nagent = DefaultAgent(\n    LitellmModel(model_name=model_name),\n    EnvironmentQuitsOnSubmit(),\n)\n</code></pre> <p>An agent that validates actions before execution (also an example of how to use an extended config class):</p> Subclassing the agentSubclassing the environment <pre><code>import re\nfrom minisweagent.agents.default import DefaultAgent, AgentConfig\nfrom minisweagent.exceptions import FormatError\nfrom pydantic import BaseModel\n\nclass ValidatingAgentConfig(AgentConfig):\n    forbidden_patterns: list[str] = [\n        r\"rm -rf /\",\n        r\"sudo.*passwd\",\n        r\"mkfs\\.\",\n    ]\n\nclass ValidatingAgent(DefaultAgent):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs, config_class=ValidatingAgentConfig)\n\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        for action in message.get(\"extra\", {}).get(\"actions\", []):\n            command = action.get(\"command\", \"\")\n            for pattern in self.config.forbidden_patterns:\n                if re.search(pattern, command, re.IGNORECASE):\n                    raise FormatError(self.model.format_message(\n                        role=\"user\", content=\"Action blocked: forbidden pattern detected\"\n                    ))\n        return super().execute_actions(message)\n</code></pre> <pre><code>import re\nfrom minisweagent.agents.default import DefaultAgent\nfrom minisweagent.environments.local import LocalEnvironment, LocalEnvironmentConfig\nfrom minisweagent.models.litellm_model import LitellmModel\n\nclass EnvironmentWithForbiddenPatternsConfig(LocalEnvironmentConfig):\n    forbidden_patterns: list[str] = [\n        r\"rm -rf /\",\n        r\"sudo.*passwd\",\n        r\"mkfs\\.\",\n    ]\n\nclass EnvironmentWithForbiddenPatterns(LocalEnvironment):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs, config_class=EnvironmentWithForbiddenPatternsConfig)\n\n    def execute(self, action: dict, cwd: str = \"\") -&gt; dict:\n        command = action.get(\"command\", \"\")\n        for pattern in self.config.forbidden_patterns:\n            if re.search(pattern, command, re.IGNORECASE):\n                return {\"output\": \"Action blocked: forbidden pattern detected\", \"returncode\": 1}\n        return super().execute(action, cwd)\n\nagent = DefaultAgent(\n    LitellmModel(model_name=model_name),\n    EnvironmentWithForbiddenPatterns(),\n)\n</code></pre>"},{"location":"advanced/cookbook/#running-mini-swe-agent-on-ray","title":"Running mini-swe-agent on Ray","text":"<p>This blog post describes how to parallelize mini-swe-agent runs with Ray.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"advanced/environments/","title":"Environments","text":""},{"location":"advanced/environments/#environment-classes","title":"Environment classes","text":"<p>Environment classes</p> <ul> <li>Environments are what is executing the code generated by the LM/agent.</li> <li>We offer different classes for either executing code directly on the host machine, or in a container (e.g., Docker, Singularity, etc.).</li> </ul> <p>We support various environments for executing code through different backends.</p> <p>If you run the <code>mini</code> CLI, you will run in the <code>local</code> environment by default.</p> <p>However, particularly for evaluating on SWE-bench, you want to run in isolated environments, so we offer multiple \"backends\" that you can use.</p> <p>You can specify the environment class with the <code>--environment-class</code> flag or the <code>environment.environment_class</code> key in the agent config file.</p> <ul> <li> <p><code>local</code> (<code>LocalEnvironment</code>). Executes commands directly on the host machine using <code>subprocess.run</code>. No isolation. Directly works in your current python environment.</p> </li> <li> <p><code>docker</code> (<code>DockerEnvironment</code>). Executes commands with <code>docker exec</code>.</p> </li> <li> <p><code>singularity</code> (<code>SingularityEnvironment</code>) - Executes commands in Singularity/Apptainer containers. Good alternative to Docker in HPC environments where Docker is not available.</p> </li> </ul> <p>On top, there are a few more specialized environment classes that you can use:</p> <ul> <li> <p><code>swerex_docker</code> (<code>SwerexDockerEnvironment</code>) - Docker execution through SWE-ReX</p> </li> <li> <p><code>swerex_modal</code> (<code>SwerexModalEnvironment</code>) - Modal cloud execution through SWE-ReX. Useful for training coding agents at scale with remote execution.</p> </li> <li> <p><code>bubblewrap</code> (<code>BubblewrapEnvironment</code>) - Linux only. Uses bubblewrap for lightweight, unprivileged sandboxing. Experimental.</p> </li> <li> <p><code>contree</code> (<code>ContreeEnvironment</code>) - Uses ConTree for safe code execution sandboxing. Platform that built for agents and supports Git-like execution.</p> </li> </ul>"},{"location":"advanced/global_configuration/","title":"Global configuration","text":""},{"location":"advanced/global_configuration/#global-configuration","title":"Global configuration","text":"<p>Configuring mini</p> <ul> <li>This guide shows how to configure the <code>mini</code> agent's global settings (API keys, default model, etc.).   Basically anything that is set as environment variables or similar.</li> <li>You should already be familiar with the quickstart guide.</li> <li>For more agent specific settings, see the yaml configuration file guide.</li> </ul> <p>Setting up models</p> <p>Setting up models is also covered in the quickstart guide.</p>"},{"location":"advanced/global_configuration/#setting-global-configuration","title":"Setting global configuration","text":"<p>All global configuration can be either set as environment variables, or in the <code>.env</code> file (the exact location is printed when you run <code>mini</code>). Environment variables take precedence over variables set in the <code>.env</code> file.</p> <p>We provide several helper functions to update the global configuration.</p> <p>For example, to set the default model and API keys, you can run:</p> <pre><code>mini-extra config setup\n</code></pre> <p>or to update specific settings:</p> <pre><code>mini-extra config set KEY VALUE\n# e.g.,\nmini-extra config set MSWEA_MODEL_NAME \"anthropic/claude-sonnet-4-5-20250929\"\nmini-extra config set ANTHROPIC_API_KEY \"sk-...\"\n</code></pre> <p>or to unset a key:</p> <pre><code>mini-extra config unset KEY\n# e.g.,\nmini-extra config unset ANTHROPIC_API_KEY\n</code></pre> <p>You can also edit the <code>.env</code> file directly and we provide a helper function for that:</p> <pre><code>mini-extra config edit\n</code></pre> <p>To set environment variables (recommended for temporary experimentation or API keys):</p> <pre><code>export KEY=\"value\"\n# windows:\nsetx KEY \"value\"\n</code></pre>"},{"location":"advanced/global_configuration/#models-keys-costs","title":"Models, keys, costs","text":"<p>See also</p> <p>Read the quickstart guide first\u2014it already covers most of this.</p> <pre><code># Default model name\n# (default: not set)\nMSWEA_MODEL_NAME=\"anthropic/claude-sonnet-4-5-20250929\"\n</code></pre> <p>To ignore errors from cost tracking checks (for example for free models), set:</p> <pre><code># CAREFUL: This can lead to unmanaged spending!\nMSWEA_COST_TRACKING=\"ignore_errors\"\n</code></pre> <p>To register extra models to litellm (see local models for more details), you can either specify the path in the agent file, or set</p> <pre><code>LITELLM_MODEL_REGISTRY_PATH=\"/path/to/your/model/registry.json\"\n</code></pre> <p>Global cost limits:</p> <pre><code># Global limit on number of model calls (0 = no limit)\n# (default: 0)\nMSWEA_GLOBAL_CALL_LIMIT=\"100\"\n\n# Global cost limit in dollars (0 = no limit)\n# (default: 0)\nMSWEA_GLOBAL_COST_LIMIT=\"10.00\"\n\n# Number of retry attempts for model API calls\n# (default: 10)\nMSWEA_MODEL_RETRY_STOP_AFTER_ATTEMPT=\"10\"\n</code></pre>"},{"location":"advanced/global_configuration/#default-config-files","title":"Default config files","text":"<pre><code># Set a custom directory for agent config files in addition to the builtin ones\n# This allows to specify them by names\nMSWEA_CONFIG_DIR=\"/path/to/your/own/config/dir\"\n\n# Config path for mini run script\n# (default: package_dir / \"config\" / \"mini.yaml\")\nMSWEA_MINI_CONFIG_PATH=\"/path/to/your/own/config\"\n\n# Custom style path for trajectory inspector\n# (default: package_dir / \"config\" / \"inspector.tcss\")\nMSWEA_INSPECTOR_STYLE_PATH=\"/path/to/your/inspector/style.tcss\"\n</code></pre>"},{"location":"advanced/global_configuration/#settings-for-environments","title":"Settings for environments","text":"<pre><code># Path/name to the singularity/apptainer executable\n# (default: \"singularity\")\nMSWEA_SINGULARITY_EXECUTABLE=\"singularity\"\n\n# Path/name to the docker executable\n# (default: \"docker\")\nMSWEA_DOCKER_EXECUTABLE=\"docker\"\n\n# Path/name to the bubblewrap executable\n# (default: \"bwrap\")\nMSWEA_BUBBLEWRAP_EXECUTABLE=\"bwrap\"\n</code></pre>"},{"location":"advanced/global_configuration/#default-run-files","title":"Default run files","text":"<pre><code># Default run script entry point for the main CLI\n# (default: \"minisweagent.run.mini\")\nMSWEA_DEFAULT_RUN=\"minisweagent.run.mini\"\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"advanced/v2_migration/","title":"v2 migration guide","text":""},{"location":"advanced/v2_migration/#v20-migration-guide","title":"v2.0 Migration Guide","text":"<p>Breaking Changes</p> <p>mini-swe-agent v2.0 brings major improvements but requires migration. To stay with v1.x, pin your dependency: <code>mini-swe-agent~=1.0</code>. See the v1 documentation or the v1 branch on GitHub.</p>"},{"location":"advanced/v2_migration/#whats-new","title":"What's new","text":"<ul> <li>Tool calls: Native tool calling API support (now the default)</li> <li>Multimodal input: Support for images and other content types</li> </ul>"},{"location":"advanced/v2_migration/#what-do-i-need-to-change","title":"What do I need to change?","text":"<p>I only use the mini CLI with default configs</p> <p>No changes needed.</p> <p>I use custom configs</p> <p>You might need to move some config keys. See Config changes.</p> <p>I parse/analyze trajectories</p> <p>Some metadata fields moved to <code>extra</code>. See Trajectory format.</p> <p>I use the python bindings or built custom subclasses</p> <p>You will need to refactor. An agent can refactor your code based on the instructions below.</p>"},{"location":"advanced/v2_migration/#config-changes","title":"Config changes","text":"<p>If you only changed <code>system_template</code> and <code>instance_template</code>, no changes needed.</p> <p>Move from <code>agent</code> to <code>model</code>:</p> <ul> <li><code>observation_template</code> (renamed from <code>action_observation_template</code>)</li> <li><code>format_error_template</code></li> <li><code>action_regex</code> (only for text-based parsing)</li> </ul> <p>Removed:</p> <ul> <li><code>timeout_template</code></li> </ul> <p>Code block format changed:</p> <p>Default action regex changed from <code>```bash</code> to <code>```mswea_bash_command</code> to avoid conflicts with bash examples in prompts.</p> <p>Completion signal changed:</p> <p>From <code>echo MINI_SWE_AGENT_FINAL_OUTPUT</code> to <code>echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT</code>.</p> <p>New structure:</p> <pre><code>agent:\n  system_template: \"...\"\n  instance_template: \"...\"\n  step_limit: 0\n  cost_limit: 3.\nenvironment:\n  cwd: \"...\"\n  timeout: 30\nmodel:\n  model_name: \"...\"\n  observation_template: \"...\"\n  format_error_template: \"...\"\n</code></pre> <p>CLI now supports multiple configs and key-value overrides:</p> <pre><code>mini -c mini.yaml -c model.model_kwargs.temperature=0.5\nmini -c swebench.yaml -c agent.step_limit=100\nmini -c mini.yaml -c /path/to/model.yaml\n</code></pre> <p>Warning</p> <p>If you use <code>-c</code>, you will not load the full default config, so make sure to always specify your config file in addition to any overrides/updates.</p>"},{"location":"advanced/v2_migration/#tool-calling","title":"Tool calling","text":"<p>v2.0 uses native tool calling by default (instead of regex-based text parsing).</p> <p>What's the difference?</p> <ul> <li>Tool calling (default): Model uses native tool calling API to invoke a \"bash\" tool</li> <li>Text-based (legacy): Model outputs commands in markdown code blocks (or similar), regex extracts them</li> </ul> <p>How to use it:</p> <p>Tool calling is the default. The CLI uses <code>mini.yaml</code> and <code>swebench.yaml</code> which are configured for tool calling.</p> <pre><code># Default (tool calling)\nmini\npython -m minisweagent.run.benchmarks.swebench\nmini-extra swebench\n\n# Text-based parsing\nmini-extra swebench -c swebench_backticks.yaml\nmini -c mini_textbased.yaml\n</code></pre> <p>For custom configs:</p> <pre><code>model:\n  model_class: litellm  # tool calling (default)\n  model_name: anthropic/claude-sonnet-4-5-20250929\n\n# or for text-based:\nmodel:\n  model_class: litellm_textbased\n  action_regex: \"```mswea_bash_command\\\\s*\\\\n(.*?)\\\\n```\"\n</code></pre>"},{"location":"advanced/v2_migration/#trajectory-format","title":"Trajectory format","text":"<ul> <li>In v1, all messages in the trajectory's <code>messages</code> field were \"hand-formatted\", i.e., had a <code>content: str</code> and <code>role: str</code> field.</li> <li>In v2, we use the model's native output as the basis for the message and only add the <code>extra</code> field to it.</li> </ul> <p>If you use a model that uses the standard <code>/completion</code> endpoint, then you will still always have a <code>content: str</code> and <code>role: str</code> field. However, if you use the <code>/response</code> endpoint, then things might look different.</p> <p>In other words: the exact message structure depends on the model you use.</p> <ul> <li>Advantage: Any model message structure is supported</li> <li>Disadvantage: If you parse trajectories, you might need to adapt to the message structure of the model you use.</li> </ul>"},{"location":"advanced/v2_migration/#removed-renamed","title":"Removed &amp; renamed","text":"<p>Removed features:</p> <ul> <li>\"Visual\" UI: The <code>-v</code> flag for the alternate, textual based <code>mini -v</code> CLI is no longer supported. This was a tough decision to make, but in the end the visual mode didn't see the adoption we wanted and is significantly more complex to maintain than the default interface.</li> <li>Rotating API keys: <code>ANTHROPIC_API_KEYS</code> with <code>::</code> separator no longer supported. Use single <code>ANTHROPIC_API_KEY</code>.</li> <li><code>github_issue</code> run script: The dedicated <code>github_issue.py</code> run script was removed. Use the <code>mini</code> CLI instead.</li> <li><code>MSWEA_MODEL_API_KEY</code> environment variable: No longer used to override API keys.</li> </ul> <p>Removed model classes:</p> <ul> <li><code>anthropic</code> model class: Removed. Use <code>litellm</code> model class for Anthropic models (make sure that cache control is enabled).</li> </ul> <p>Renamed model classes:</p> v1 name v2 name <code>litellm_response_api</code> <code>litellm_response</code> <code>portkey_response_api</code> <code>portkey_response</code> <p>New model classes:</p> Name Description <code>litellm_textbased</code> Text-based parsing (regex) instead of tool calls <code>openrouter_textbased</code> Text-based parsing for OpenRouter <code>openrouter_response</code> OpenRouter with response API <p>New environment:</p> <ul> <li><code>swerex_modal</code>: Run environments on Modal (requires <code>pip install mini-swe-agent[modal]</code>)</li> </ul>"},{"location":"advanced/v2_migration/#architecture-changes","title":"Architecture changes","text":"<ol> <li> <p>Responsibility shift: Models now parse actions and format observations. This enables switching between tool calls and text parsing by changing model classes. The Agent class is now a simpler coordinator.</p> </li> <li> <p>Stateless models: Cost tracking moved to Agent. The <code>cost</code> and <code>n_calls</code> attributes were removed from the Model protocol.</p> </li> <li> <p>Pydantic configs: <code>AgentConfig</code> (and other configs) changed from <code>dataclass</code> to Pydantic <code>BaseModel</code>. This requires <code>pydantic &gt;= 2.0</code>.</p> </li> <li> <p>New protocol methods: All classes implement <code>get_template_vars()</code> and <code>serialize()</code> instead of requiring specific attributes.</p> </li> </ol>"},{"location":"advanced/v2_migration/#protocol-changes","title":"Protocol changes","text":"<p>If you want to write a custom Model, Environment or Agent compatible with <code>mini-swe-agent</code>, you don't need to subclass anything. Rather, mini-swe-agent fully uses duck typing with protocols (tl;dr: as long as you implement the required methods, you can use any class as a Model, Environment or Agent). Config options like <code>--config-class</code> also take full import classes, so you can put your classes wherever you want.</p> <p>Model protocol:</p> <pre><code># Removed attributes\ncost: float      # moved to Agent\nn_calls: int     # moved to Agent\n\n# New methods\ndef format_message(self, **kwargs) -&gt; dict: ...\ndef format_observation_messages(self, message: dict, outputs: list[dict], template_vars: dict | None = None) -&gt; list[dict]: ...\ndef serialize(self) -&gt; dict: ...\n</code></pre> <p>Environment protocol:</p> <pre><code># Changed signature\ndef execute(self, action: dict, cwd: str = \"\") -&gt; dict[str, Any]: ...  # was: (command: str) -&gt; dict[str, str]\n\n# New method\ndef serialize(self) -&gt; dict: ...\n</code></pre> <p>Agent protocol:</p> <pre><code># Removed attributes (you don't need to implement these anymore, but you can)\nmodel: Model\nenv: Environment\nmessages: list[dict]\n\n# Changed return type\ndef run(self, task: str, **kwargs) -&gt; dict: ...  # was: tuple[str, str]\n\n# New method\ndef save(self, path: Path | None, *extra_dicts) -&gt; dict: ...\n</code></pre>"},{"location":"advanced/v2_migration/#exception-changes","title":"Exception changes","text":"<p>All flow control exceptions now inherit from <code>InterruptAgentFlow</code> and moved to <code>minisweagent.exceptions</code>:</p> <pre><code>InterruptAgentFlow (base)\n\u251c\u2500\u2500 Submitted (task completed)\n\u251c\u2500\u2500 LimitsExceeded (cost/step limit)\n\u251c\u2500\u2500 FormatError (invalid model output)\n\u2514\u2500\u2500 UserInterruption (user cancelled)  # new\n</code></pre> <p>Removed exception classes:</p> <ul> <li><code>NonTerminatingException</code> - use <code>InterruptAgentFlow</code> base class</li> <li><code>TerminatingException</code> - use <code>InterruptAgentFlow</code> base class</li> <li><code>ExecutionTimeoutError</code> - removed (no longer used)</li> </ul> <pre><code># Old\nfrom minisweagent.agents.default import Submitted, FormatError\n\n# New\nfrom minisweagent.exceptions import Submitted, FormatError\n</code></pre>"},{"location":"advanced/v2_migration/#agentrun-return-value","title":"Agent.run() return value","text":"<pre><code># Old (v1)\nsubmission, exit_status = agent.run(task)  # tuple[str, str]\n\n# New (v2)\nresult = agent.run(task)  # dict\nsubmission = result[\"submission\"]\nexit_status = result[\"exit_status\"]\n</code></pre> <p>The <code>run()</code> method returns the <code>extra</code> dict from the final exit message. For full trajectory data, use <code>agent.save(path)</code> or <code>agent.serialize()</code>.</p>"},{"location":"advanced/yaml_configuration/","title":"Yaml config files","text":""},{"location":"advanced/yaml_configuration/#yaml-config-files","title":"Yaml config files","text":"<p>Agent configuration files</p> <ul> <li>You can configure the agent's behavior using YAML configuration files. This guide shows how to do that.</li> <li>You should already be familiar with the quickstart guide.</li> <li>For global environment settings (API keys, default model, etc., basically anything that can be set as environment variables), see global configuration.</li> <li>Want more? See python bindings for subclassing &amp; developing your own agent.</li> </ul>"},{"location":"advanced/yaml_configuration/#overall-structure","title":"Overall structure","text":"<p>Configuration files look like this:</p> Configuration file <pre><code>agent:\n  system_template: |\n    You are a helpful assistant that can interact with a computer.\n  instance_template: |\n    Please solve this issue: {{task}}\n\n    You can execute bash commands and edit files to implement the necessary changes.\n\n    ## Recommended Workflow\n\n    This workflows should be done step-by-step so that you can iterate on your changes and any possible problems.\n\n    1. Analyze the codebase by finding and reading relevant files\n    2. Create a script to reproduce the issue\n    3. Edit the source code to resolve the issue\n    4. Verify your fix works by running your script again\n    5. Test edge cases to ensure your fix is robust\n    6. Submit your changes and finish your work by issuing the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`.\n       Do not combine it with any other command. &lt;important&gt;After this command, you cannot continue working on this task.&lt;/important&gt;\n\n    ## Command Execution Rules\n\n    You are operating in an environment where\n\n    1. You issue at least one command\n    2. The system executes the command(s) in a subshell\n    3. You see the result(s)\n    4. You write your next command(s)\n\n    Each response should include:\n\n    1. **Reasoning text** where you explain your analysis and plan\n    2. At least one tool call with your command\n\n    **CRITICAL REQUIREMENTS:**\n\n    - Your response SHOULD include reasoning text explaining what you're doing\n    - Your response MUST include AT LEAST ONE bash tool call\n    - Directory or environment variable changes are not persistent. Every action is executed in a new subshell.\n    - However, you can prefix any action with `MY_ENV_VAR=MY_VALUE cd /path/to/working/dir &amp;&amp; ...` or write/load environment variables from files\n    - Submit your changes and finish your work by issuing the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`.\n      Do not combine it with any other command. &lt;important&gt;After this command, you cannot continue working on this task.&lt;/important&gt;\n\n    Example of a CORRECT response:\n    &lt;example_response&gt;\n    I need to understand the structure of the repository first. Let me check what files are in the current directory to get a better understanding of the codebase.\n\n    [Makes bash tool call with {\"command\": \"ls -la\"} as arguments]\n    &lt;/example_response&gt;\n\n    &lt;system_information&gt;\n    {{system}} {{release}} {{version}} {{machine}}\n    &lt;/system_information&gt;\n\n    ## Useful command examples\n\n    ### Create a new file:\n\n    ```bash\n    cat &lt;&lt;'EOF' &gt; newfile.py\n    import numpy as np\n    hello = \"world\"\n    print(hello)\n    EOF\n    ```\n\n    ### Edit files with sed:\n\n    {%- if system == \"Darwin\" -%}\n    &lt;important&gt;\n    You are on MacOS. For all the below examples, you need to use `sed -i ''` instead of `sed -i`.\n    &lt;/important&gt;\n    {%- endif -%}\n\n    ```bash\n    # Replace all occurrences\n    sed -i 's/old_string/new_string/g' filename.py\n\n    # Replace only first occurrence\n    sed -i 's/old_string/new_string/' filename.py\n\n    # Replace first occurrence on line 1\n    sed -i '1s/old_string/new_string/' filename.py\n\n    # Replace all occurrences in lines 1-10\n    sed -i '1,10s/old_string/new_string/g' filename.py\n    ```\n\n    ### View file content:\n\n    ```bash\n    # View specific lines with numbers\n    nl -ba filename.py | sed -n '10,20p'\n    ```\n\n    ### Any other command you want to run\n\n    ```bash\n    anything\n    ```\n  step_limit: 0\n  cost_limit: 3.\n  mode: confirm\nenvironment:\n  env:\n    PAGER: cat\n    MANPAGER: cat\n    LESS: -R\n    PIP_PROGRESS_BAR: 'off'\n    TQDM_DISABLE: '1'\nmodel:\n  observation_template: |\n    {%- if output.output | length &lt; 10000 -%}\n    {\n      \"returncode\": {{ output.returncode }},\n      \"output\": {{ output.output | tojson }}\n      {%- if output.exception_info %}, \"exception_info\": {{ output.exception_info | tojson }}{% endif %}\n    }\n    {%- else -%}\n    {\n      \"returncode\": {{ output.returncode }},\n      \"output_head\": {{ output.output[:5000] | tojson }},\n      \"output_tail\": {{ output.output[-5000:] | tojson }},\n      \"elided_chars\": {{ output.output | length - 10000 }},\n      \"warning\": \"Output too long.\"\n      {%- if output.exception_info %}, \"exception_info\": {{ output.exception_info | tojson }}{% endif %}\n    }\n    {%- endif -%}\n  format_error_template: |\n    Tool call error:\n\n    &lt;error&gt;\n    {{error}}\n    &lt;/error&gt;\n\n    Here is general guidance on how to submit correct toolcalls:\n\n    Every response needs to use the 'bash' tool at least once to execute commands.\n\n    Call the bash tool with your command as the argument:\n    - Tool: bash\n    - Arguments: {\"command\": \"your_command_here\"}\n\n    If you want to end the task, please issue the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`\n    without any other command.\n  model_kwargs:\n    drop_params: true\n</code></pre> <p>We use the following top-level keys:</p> <ul> <li><code>agent</code>: Agent configuration (prompt templates, cost limits etc.)</li> <li><code>environment</code>: Environment configuration (if you want to run in a docker container, etc.)</li> <li><code>model</code>: Model configuration (model name, reasoning strength, etc.)</li> <li><code>run</code>: Run configuration (output file, etc.)</li> </ul>"},{"location":"advanced/yaml_configuration/#agent-configuration","title":"Agent configuration","text":"<p>Different agent classes might have slightly different configuration options. You can find the full list of options in the API reference.</p> <p>To use a different agent class, you can set the <code>agent_class</code> key to the name of the agent class you want to use or even to an import path (to use your own custom agent class even if it is not yet part of the mini-SWE-agent package).</p>"},{"location":"advanced/yaml_configuration/#prompt-templates","title":"Prompt templates","text":"<p>We use Jinja2 to render templates (e.g., the instance template).</p> <p>TL;DR: You include variables with double (!) curly braces, e.g. <code>{{task}}</code> to include the task that was given to the agent.</p> <p>However, you can also do fairly complicated logic like this directly from your template:</p> Example: Dealing with long observations <p>The following snippets shortens long observations and displays a warning if the output is too long.</p> <pre><code>&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\n{% if output.output | length &lt; 10000 -%}\n    &lt;output&gt;\n        {{ output.output -}}\n    &lt;/output&gt;\n{%- else -%}\n    &lt;warning&gt;\n        The output of your last command was too long.\n        Please try a different command that produces less output.\n        If you're looking at a file you can try use head, tail or sed to view a smaller number of lines selectively.\n        If you're using grep or find and it produced too much output, you can use a more selective search pattern.\n        If you really need to see something from the full command's output, you can redirect output to a file and then search in that file.\n    &lt;/warning&gt;\n\n    {%- set elided_chars = output.output | length - 10000 -%}\n\n    &lt;output_head&gt;\n        {{ output.output[:5000] }}\n    &lt;/output_head&gt;\n\n    &lt;elided_chars&gt;\n        {{ elided_chars }} characters elided\n    &lt;/elided_chars&gt;\n\n    &lt;output_tail&gt;\n        {{ output.output[-5000:] }}\n    &lt;/output_tail&gt;\n{%- endif -%}\n</code></pre> <p>In all builtin agents, you can use the following variables:</p> <ul> <li>Environment variables (<code>LocalEnvironment</code> only, see discussion here)</li> <li>Agent config variables (i.e., anything that was set in the <code>agent</code> section of the config file, e.g., <code>step_limit</code>, <code>cost_limit</code>, etc.)</li> <li>Environment config variables (i.e., anything that was set in the <code>environment</code> section of the config file, e.g., <code>cwd</code>, <code>timeout</code>, etc.)</li> <li>Variables passed to the <code>run</code> method of the agent (by default that's only <code>task</code>, but you can pass other variables if you want to)</li> <li>Output of the last action execution (i.e., <code>output</code> from the <code>execute_action</code> method)</li> </ul>"},{"location":"advanced/yaml_configuration/#using-tool-calls","title":"Using tool calls","text":"<p>Make sure to use the appropriate model class and matching configuration.</p>"},{"location":"advanced/yaml_configuration/#custom-action-parsing-from-text","title":"Custom Action Parsing from Text","text":"<p>mini-SWE-agent can parse actions from markdown code blocks (<code>```mswea_bash_command ... ```</code>) or from tool calls. You can customize this behavior by setting the <code>action_regex</code> field to support different formats like XML.</p> <p>Important</p> <p>If you set a custom action_regex (e.g. <code>&lt;action&gt;(.*?)&lt;/action&gt;</code>), you must use the same output format across all prompt templates (system_template, instance_template, format_error_template, etc.), ensuring the LLM wraps commands accordingly. See the example below for a complete configuration.</p> Using XML format instead of markdown <p>This example uses the same structure as the default mini.yaml config, but with <code>&lt;action&gt;</code> tags instead of markdown code blocks:</p> <pre><code>agent:\n  system_template: |\n    You are a helpful assistant that can interact multiple times with a computer shell to solve programming tasks.\n    Your response must contain exactly ONE bash code block with ONE command (or commands connected with &amp;&amp; or ||).\n\n    Include a THOUGHT section before your command where you explain your reasoning process.\n    Format your response as shown in &lt;format_example&gt;.\n\n    &lt;format_example&gt;\n    THOUGHT: Your reasoning and analysis here\n\n    &lt;mswea_bash_command&gt;your_command_here&lt;/mswea_bash_command&gt;\n    &lt;/format_example&gt;\n\n    Failure to follow these rules will cause your response to be rejected.\n  instance_template: |\n    &lt;pr_description&gt;\n    Consider the following PR description:\n    {{task}}\n    &lt;/pr_description&gt;\n\n    &lt;instructions&gt;\n    # Task Instructions\n\n    ## Overview\n\n    You're a software engineer interacting continuously with a computer by submitting commands.\n    You'll be helping implement necessary changes to meet requirements in the PR description.\n    Your task is specifically to make changes to non-test files in the current directory in order to fix the issue described in the PR description in a way that is general and consistent with the codebase.\n\n    &lt;IMPORTANT&gt;This is an interactive process where you will think and issue ONE command, see its result, then think and issue your next command.&lt;/IMPORTANT&gt;\n\n    For each response:\n\n    1. Include a THOUGHT section explaining your reasoning and what you're trying to accomplish\n    2. Provide exactly ONE bash command to execute\n\n    ## Important Boundaries\n\n    - MODIFY: Regular source code files in /testbed (this is the working directory for all your subsequent commands)\n    - DO NOT MODIFY: Tests, configuration files (pyproject.toml, setup.cfg, etc.)\n\n    ## Recommended Workflow\n\n    1. Analyze the codebase by finding and reading relevant files\n    2. Create a script to reproduce the issue\n    3. Edit the source code to resolve the issue\n    4. Verify your fix works by running your script again\n    5. Test edge cases to ensure your fix is robust\n\n    ## Command Execution Rules\n\n    You are operating in an environment where\n\n    1. You write a single command\n    2. The system executes that command in a subshell\n    3. You see the result\n    4. You write your next command\n\n    Each response should include:\n\n    1. A **THOUGHT** section where you explain your reasoning and plan\n    2. A single bash code block with your command\n\n    Format your responses like demonstrated within the &lt;format_example&gt; block:\n\n    &lt;format_example&gt;\n    THOUGHT: Here I explain my reasoning process, analysis of the current situation,\n    and what I'm trying to accomplish with the command below.\n\n    &lt;mswea_bash_command&gt;your_command_here&lt;/mswea_bash_command&gt;&lt;/format_example&gt;\n    Commands must be specified in a single bash XML tag:\n\n    &lt;mswea_bash_command&gt;your_command_here&lt;/mswea_bash_command&gt;\n\n    **CRITICAL REQUIREMENTS:**\n\n    - Your response SHOULD include a THOUGHT section explaining your reasoning\n    - Your response MUST include EXACTLY ONE mswea_bash_command tag\n    - This bash mswea_bash_command MUST contain EXACTLY ONE command (or a set of commands connected with &amp;&amp; or ||)\n    - If you include zero or multiple tags, or no command at all, YOUR RESPONSE WILL FAIL\n    - Do NOT try to run multiple independent commands in separate blocks in one response\n    - Directory or environment variable changes are not persistent. Every action is executed in a new subshell.\n    - However, you can prefix any action with `MY_ENV_VAR=MY_VALUE cd /path/to/working/dir &amp;&amp; ...` or write/load environment variables from files\n\n    Example of a CORRECT response:\n\n    &lt;example_response&gt;\n    THOUGHT: I need to understand the structure of the repository first. Let me check what files are in the current directory to get a better understanding of the codebase.\n\n    &lt;mswea_bash_command&gt;ls -la&lt;/mswea_bash_command&gt;\n    &lt;/example_response&gt;\n\n    Example of an INCORRECT response:\n\n    &lt;example_response&gt;\n    THOUGHT: I need to examine the codebase and then look at a specific file. I'll run multiple commands to do this.\n\n    &lt;mswea_bash_command&gt;ls -la&lt;/mswea_bash_command&gt;\n\n    Now I'll read the file:\n\n    &lt;mswea_bash_command&gt;cat file.txt&lt;/mswea_bash_command&gt;\n    &lt;/example_response&gt;\n\n    If you need to run multiple commands, either:\n\n    1. Combine them in one block using &amp;&amp; or ||\n\n    &lt;mswea_bash_command&gt;command1 &amp;&amp; command2 || echo \"Error occurred\"&lt;/mswea_bash_command&gt;\n\n    2. Wait for the first command to complete, see its output, then issue the next command in your following response.\n\n    ## Environment Details\n\n    - You have a full Linux shell environment\n    - Always use non-interactive flags (-y, -f) for commands\n    - Avoid interactive tools like vi, nano, or any that require user input\n    - You can use bash commands or invoke any tool that is available in the environment\n    - You can also create new tools or scripts to help you with the task\n    - If a tool isn't available, you can also install it\n\n    ## Submission\n\n    When you've completed your work, you MUST submit your changes as a git patch.\n    Follow these steps IN ORDER, with SEPARATE commands:\n\n    Step 1: Create the patch file\n    Run `git diff -- path/to/file1 path/to/file2 &gt; patch.txt` listing only the source files you modified.\n    Do NOT commit your changes.\n\n    &lt;IMPORTANT&gt;\n    The patch must only contain changes to the specific source files you modified to fix the issue.\n    Do not submit file creations or changes to any of the following files:\n\n    - test and reproduction files\n    - helper scripts, tests, or tools that you created\n    - installation, build, packaging, configuration, or setup scripts unless they are directly part of the issue you were fixing (you can assume that the environment is already set up for your client)\n    - binary or compiled files\n    &lt;/IMPORTANT&gt;\n\n    Step 2: Verify your patch\n    Inspect patch.txt to confirm it only contains your intended changes and headers show `--- a/` and `+++ b/` paths.\n\n    Step 3: Submit (EXACT command required)\n    You MUST use this EXACT command to submit:\n\n    &lt;mswea_bash_command&gt;echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT &amp;&amp; cat patch.txt&lt;/mswea_bash_command&gt;\n\n    If the command fails (nonzero exit status), it will not submit.\n\n    &lt;CRITICAL&gt;\n    - Creating/viewing the patch and submitting it MUST be separate commands (not combined with &amp;&amp;).\n    - If you modify patch.txt after verifying, you SHOULD verify again before submitting.\n    - You CANNOT continue working (reading, editing, testing) in any way on this task after submitting.\n    &lt;/CRITICAL&gt;\n    &lt;/instructions&gt;\n  step_limit: 250\n  cost_limit: 3.\n\nenvironment:\n  cwd: \"/testbed\"\n  timeout: 60\n  interpreter: [\"bash\", \"-c\"]\n  env:\n    PAGER: cat\n    MANPAGER: cat\n    LESS: -R\n    PIP_PROGRESS_BAR: 'off'\n    TQDM_DISABLE: '1'\n  environment_class: docker\n\nmodel:\n  observation_template: |\n    {% if output.exception_info -%}\n    &lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\n    {% endif -%}\n    &lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\n    {% if output.output | length &lt; 10000 -%}\n    &lt;output&gt;\n    {{ output.output -}}\n    &lt;/output&gt;\n    {%- else -%}\n    &lt;warning&gt;\n    The output of your last command was too long.\n    Please try a different command that produces less output.\n    If you're looking at a file you can try use head, tail or sed to view a smaller number of lines selectively.\n    If you're using grep or find and it produced too much output, you can use a more selective search pattern.\n    If you really need to see something from the full command's output, you can redirect output to a file and then search in that file.\n    &lt;/warning&gt;\n    {%- set elided_chars = output.output | length - 10000 -%}\n    &lt;output_head&gt;\n    {{ output.output[:5000] }}\n    &lt;/output_head&gt;\n    &lt;elided_chars&gt;\n    {{ elided_chars }} characters elided\n    &lt;/elided_chars&gt;\n    &lt;output_tail&gt;\n    {{ output.output[-5000:] }}\n    &lt;/output_tail&gt;\n    {%- endif -%}\n  action_regex: &lt;mswea_bash_command&gt;(.*?)&lt;/mswea_bash_command&gt;\n  format_error_template: |\n    Format error:\n\n    &lt;error&gt;\n    {{error}}\n    &lt;/error&gt;\n\n    Here is general guidance on how to format your response:\n\n    Please always provide EXACTLY ONE action in the `&lt;mswea_bash_command&gt;` block, found {{actions|length}} actions.\n\n    Please format your action in a `&lt;mswea_bash_command&gt;` block as shown in &lt;response_example&gt;.\n\n    &lt;response_example&gt;\n    Here are some thoughts about why you want to perform the action.\n\n    &lt;mswea_bash_command&gt;ls -la&lt;/mswea_bash_command&gt;\n    &lt;/response_example&gt;\n\n    If you have completed your assignment, please consult the first message about how to\n    submit your solution (you will not be able to continue working on this task after that).\n  model_name: \"minimax/minimax-m2\"\n  model_class: openrouter\n  model_kwargs:\n    temperature: 0.0\n</code></pre> <p>You can also directly load this config by specifying <code>--config swebench_xml</code>.</p> Default markdown format <p>This is the default configuration (already the default, you don't need to specify this):</p> <pre><code>model:\n  action_regex: ```mswea_bash_command\\s*\\n(.*?)\\n```\nagent:\n  system_template: |\n    Your response must contain exactly ONE bash code block.\n\n    ```mswea_bash_command\n    your_command_here\n    ```\n</code></pre> <p>Linebreaks &amp; escaping</p> <p>When specifying <code>action_regex</code> from the <code>yaml</code> config file, make sure you understand how escaping in yaml files works. For example, when you use the <code>|</code> primitive, your regex might have a linbreak at the end which is probably not what you want. The best way is to keep your regex on a single line and NOT use any quotation marks around it. You do NOT need to escape any characters in the regex. Example: <code>action_regex: &lt;bash_code&gt;(.*?)&lt;/bash_code&gt;</code></p>"},{"location":"advanced/yaml_configuration/#model-configuration","title":"Model configuration","text":"<p>See this guide for more details on model configuration.</p>"},{"location":"advanced/yaml_configuration/#environment-configuration","title":"Environment configuration","text":"<p>See this guide for more details on environment configuration.</p>"},{"location":"advanced/yaml_configuration/#run-configuration","title":"Run configuration","text":"<p>See the information in \"Usage\".</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"models/local_models/","title":"Local models","text":"<p>Local models</p> <ul> <li>This guide shows how to set up local models.</li> <li>You should already be familiar with the quickstart guide.</li> <li>You should also quickly skim the global configuration guide to understand   the global configuration and yaml configuration files guide.</li> </ul> <p>Examples</p> <ul> <li>Issue #303 has several examples of how to use local models.</li> <li>We also welcome concrete examples of how to use local models per pull request into this guide.</li> </ul>"},{"location":"models/local_models/#using-litellm","title":"Using litellm","text":"<p>Currently, models are supported via <code>litellm</code> by default.</p> <p>There are typically two steps to using local models:</p> <ol> <li>Editing the agent config file to add settings like <code>custom_llm_provider</code> and <code>api_base</code>.</li> <li>Either ignoring errors from cost tracking or updating the model registry to include your local model.</li> </ol>"},{"location":"models/local_models/#setting-api-baseprovider","title":"Setting API base/provider","text":"<p>If you use local models, you most likely need to add some extra keywords to the <code>litellm</code> call. This is done with the <code>model_kwargs</code> dictionary which is directly passed to <code>litellm.completion</code>.</p> <p>In other words, this is how we invoke litellm:</p> <pre><code>litellm.completion(\n    model=model_name,\n    messages=messages,\n    **model_kwargs\n)\n</code></pre> <p>You can set <code>model_kwargs</code> in an agent config file like the following one:</p> Default configuration file <pre><code>agent:\n  system_template: |\n    You are a helpful assistant that can interact with a computer.\n  instance_template: |\n    Please solve this issue: {{task}}\n\n    You can execute bash commands and edit files to implement the necessary changes.\n\n    ## Recommended Workflow\n\n    This workflows should be done step-by-step so that you can iterate on your changes and any possible problems.\n\n    1. Analyze the codebase by finding and reading relevant files\n    2. Create a script to reproduce the issue\n    3. Edit the source code to resolve the issue\n    4. Verify your fix works by running your script again\n    5. Test edge cases to ensure your fix is robust\n    6. Submit your changes and finish your work by issuing the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`.\n       Do not combine it with any other command. &lt;important&gt;After this command, you cannot continue working on this task.&lt;/important&gt;\n\n    ## Command Execution Rules\n\n    You are operating in an environment where\n\n    1. You issue at least one command\n    2. The system executes the command(s) in a subshell\n    3. You see the result(s)\n    4. You write your next command(s)\n\n    Each response should include:\n\n    1. **Reasoning text** where you explain your analysis and plan\n    2. At least one tool call with your command\n\n    **CRITICAL REQUIREMENTS:**\n\n    - Your response SHOULD include reasoning text explaining what you're doing\n    - Your response MUST include AT LEAST ONE bash tool call\n    - Directory or environment variable changes are not persistent. Every action is executed in a new subshell.\n    - However, you can prefix any action with `MY_ENV_VAR=MY_VALUE cd /path/to/working/dir &amp;&amp; ...` or write/load environment variables from files\n    - Submit your changes and finish your work by issuing the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`.\n      Do not combine it with any other command. &lt;important&gt;After this command, you cannot continue working on this task.&lt;/important&gt;\n\n    Example of a CORRECT response:\n    &lt;example_response&gt;\n    I need to understand the structure of the repository first. Let me check what files are in the current directory to get a better understanding of the codebase.\n\n    [Makes bash tool call with {\"command\": \"ls -la\"} as arguments]\n    &lt;/example_response&gt;\n\n    &lt;system_information&gt;\n    {{system}} {{release}} {{version}} {{machine}}\n    &lt;/system_information&gt;\n\n    ## Useful command examples\n\n    ### Create a new file:\n\n    ```bash\n    cat &lt;&lt;'EOF' &gt; newfile.py\n    import numpy as np\n    hello = \"world\"\n    print(hello)\n    EOF\n    ```\n\n    ### Edit files with sed:\n\n    {%- if system == \"Darwin\" -%}\n    &lt;important&gt;\n    You are on MacOS. For all the below examples, you need to use `sed -i ''` instead of `sed -i`.\n    &lt;/important&gt;\n    {%- endif -%}\n\n    ```bash\n    # Replace all occurrences\n    sed -i 's/old_string/new_string/g' filename.py\n\n    # Replace only first occurrence\n    sed -i 's/old_string/new_string/' filename.py\n\n    # Replace first occurrence on line 1\n    sed -i '1s/old_string/new_string/' filename.py\n\n    # Replace all occurrences in lines 1-10\n    sed -i '1,10s/old_string/new_string/g' filename.py\n    ```\n\n    ### View file content:\n\n    ```bash\n    # View specific lines with numbers\n    nl -ba filename.py | sed -n '10,20p'\n    ```\n\n    ### Any other command you want to run\n\n    ```bash\n    anything\n    ```\n  step_limit: 0\n  cost_limit: 3.\n  mode: confirm\nenvironment:\n  env:\n    PAGER: cat\n    MANPAGER: cat\n    LESS: -R\n    PIP_PROGRESS_BAR: 'off'\n    TQDM_DISABLE: '1'\nmodel:\n  observation_template: |\n    {%- if output.output | length &lt; 10000 -%}\n    {\n      \"returncode\": {{ output.returncode }},\n      \"output\": {{ output.output | tojson }}\n      {%- if output.exception_info %}, \"exception_info\": {{ output.exception_info | tojson }}{% endif %}\n    }\n    {%- else -%}\n    {\n      \"returncode\": {{ output.returncode }},\n      \"output_head\": {{ output.output[:5000] | tojson }},\n      \"output_tail\": {{ output.output[-5000:] | tojson }},\n      \"elided_chars\": {{ output.output | length - 10000 }},\n      \"warning\": \"Output too long.\"\n      {%- if output.exception_info %}, \"exception_info\": {{ output.exception_info | tojson }}{% endif %}\n    }\n    {%- endif -%}\n  format_error_template: |\n    Tool call error:\n\n    &lt;error&gt;\n    {{error}}\n    &lt;/error&gt;\n\n    Here is general guidance on how to submit correct toolcalls:\n\n    Every response needs to use the 'bash' tool at least once to execute commands.\n\n    Call the bash tool with your command as the argument:\n    - Tool: bash\n    - Arguments: {\"command\": \"your_command_here\"}\n\n    If you want to end the task, please issue the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`\n    without any other command.\n  model_kwargs:\n    drop_params: true\n</code></pre> <p>In the last section, you can add</p> <pre><code>model:\n  model_name: \"my-local-model\"\n  model_kwargs:\n    custom_llm_provider: \"openai\"\n    api_base: \"https://...\"\n    ...\n  ...\n</code></pre> <p>Updating the default <code>mini</code> configuration file</p> <p>You can set the <code>MSWEA_MINI_CONFIG_PATH</code> setting to set path to the default <code>mini</code> configuration file. This will allow you to override the default configuration file with your own. See the global configuration guide for more details.</p> <p>If this is not enough, our model class should be simple to modify:</p> Complete model class <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>import json\nimport logging\nimport os\nimport time\nfrom collections.abc import Callable\nfrom pathlib import Path\nfrom typing import Any, Literal\n\nimport litellm\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_toolcall import (\n    BASH_TOOL,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions,\n)\nfrom minisweagent.models.utils.anthropic_utils import _reorder_anthropic_thinking_blocks\nfrom minisweagent.models.utils.cache_control import set_cache_control\nfrom minisweagent.models.utils.openai_multimodal import expand_multimodal_content\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"litellm_model\")\n\n# Fields from model_dump() that are safe to pass through to the API.\n# Litellm-internal fields (e.g., provider_specific_fields) are stripped.\n_KNOWN_MESSAGE_FIELDS = {\n    \"role\", \"content\", \"name\", \"tool_calls\", \"tool_call_id\", \"function_call\",\n    \"refusal\", \"audio\", \"annotations\",\n}\n\n# Roles accepted by the OpenAI chat completions API.\n# Messages with other roles (e.g., \"exit\") are internal to mini-swe-agent\n# and must be filtered before sending to the API.  The OpenAI SDK's Pydantic\n# Union discriminator serializes unrecognised roles as ``null``, which causes\n# \"Invalid type for 'messages[N]': expected an object, but got null\" errors.\n_VALID_API_ROLES = {\"system\", \"user\", \"assistant\", \"tool\", \"function\", \"developer\"}\n\n\ndef _diagnose_null_messages(messages: list) -&gt; None:\n    \"\"\"Log diagnostic info when a null-message BadRequestError occurs.\"\"\"\n    import json as _json\n\n    logger.error(\"=== NULL MESSAGE DIAGNOSTIC ===\")\n    logger.error(\"Total messages: %d\", len(messages))\n    for i, msg in enumerate(messages):\n        if msg is None:\n            logger.error(\"  messages[%d] = NULL\", i)\n        elif not isinstance(msg, dict):\n            logger.error(\"  messages[%d] = type=%s value=%r\", i, type(msg).__name__, msg)\n        else:\n            role = msg.get(\"role\", \"&lt;missing&gt;\")\n            has_content = \"content\" in msg\n            content_val = msg.get(\"content\")\n            content_repr = repr(content_val)[:80] if content_val is not None else \"null\"\n            keys = sorted(msg.keys())\n            logger.error(\n                \"  messages[%d] = role=%s, has_content=%s, content=%s, keys=%s\",\n                i, role, has_content, content_repr, keys,\n            )\n    # Also dump the raw JSON to a temp file for inspection\n    try:\n        import tempfile\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\"_null_msg_debug.json\", delete=False, prefix=\"litellm_\") as f:\n            _json.dump(messages, f, indent=2, default=str)\n            logger.error(\"Full messages dumped to: %s\", f.name)\n    except Exception:\n        pass\n    logger.error(\"=== END DIAGNOSTIC ===\")\n\n\ndef _sanitize_message(msg: dict) -&gt; dict:\n    \"\"\"Clean a message dict for API submission.\n\n    - Strips the ``extra`` key (internal to mini-swe-agent).\n    - Strips unknown/litellm-internal keys (e.g., ``provider_specific_fields``).\n    - Removes keys whose value is ``None`` **except** ``content`` (which is\n      legitimately ``None`` for assistant messages that only carry tool_calls).\n    - Deep-sanitizes ``tool_calls`` to remove Pydantic artifacts.\n    \"\"\"\n    out: dict = {}\n    for k, v in msg.items():\n        if k == \"extra\":\n            continue\n        if k not in _KNOWN_MESSAGE_FIELDS:\n            continue\n        # Keep content even when None (valid for assistant tool_call messages)\n        if v is None and k != \"content\":\n            continue\n        out[k] = v\n    # Deep-sanitize tool_calls: strip None values and Pydantic internals\n    if \"tool_calls\" in out and isinstance(out[\"tool_calls\"], list):\n        out[\"tool_calls\"] = _sanitize_tool_calls(out[\"tool_calls\"])\n    return out\n\n\ndef _sanitize_tool_calls(tool_calls: list) -&gt; list:\n    \"\"\"Deep-clean tool_calls list for API submission.\n\n    Ensures each tool call is a plain dict with only known fields,\n    preventing Pydantic serialization artifacts from causing API errors.\n    \"\"\"\n    _KNOWN_TC_FIELDS = {\"id\", \"type\", \"function\", \"index\"}\n    _KNOWN_FN_FIELDS = {\"name\", \"arguments\"}\n    cleaned = []\n    for tc in tool_calls:\n        if tc is None:\n            continue\n        if not isinstance(tc, dict):\n            # Convert Pydantic models to dicts\n            tc = tc.model_dump() if hasattr(tc, \"model_dump\") else dict(tc)\n        out = {k: v for k, v in tc.items() if k in _KNOWN_TC_FIELDS and v is not None}\n        # Ensure function sub-dict is also clean\n        fn = out.get(\"function\")\n        if isinstance(fn, dict):\n            out[\"function\"] = {k: v for k, v in fn.items() if k in _KNOWN_FN_FIELDS}\n        cleaned.append(out)\n    return cleaned\n\n\nclass LitellmModelConfig(BaseModel):\n    model_name: str\n    \"\"\"Model name. Highly recommended to include the provider in the model name, e.g., `anthropic/claude-sonnet-4-5-20250929`.\"\"\"\n    model_kwargs: dict[str, Any] = {}\n    \"\"\"Additional arguments passed to the API.\"\"\"\n    litellm_model_registry: Path | str | None = os.getenv(\"LITELLM_MODEL_REGISTRY_PATH\")\n    \"\"\"Model registry for cost tracking and model metadata. See the local model guide (https://mini-swe-agent.com/latest/models/local_models/) for more details.\"\"\"\n    set_cache_control: Literal[\"default_end\"] | None = None\n    \"\"\"Set explicit cache control markers, for example for Anthropic models\"\"\"\n    cost_tracking: Literal[\"default\", \"ignore_errors\"] = os.getenv(\"MSWEA_COST_TRACKING\", \"default\")\n    \"\"\"Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)\"\"\"\n    format_error_template: str = \"{{ error }}\"\n    \"\"\"Template used when the LM's output is not in the expected format.\"\"\"\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass LitellmModel:\n    abort_exceptions: list[type[Exception]] = [\n        litellm.exceptions.UnsupportedParamsError,\n        litellm.exceptions.NotFoundError,\n        litellm.exceptions.PermissionDeniedError,\n        litellm.exceptions.ContextWindowExceededError,\n        litellm.exceptions.AuthenticationError,\n        litellm.exceptions.BadRequestError,\n        KeyboardInterrupt,\n    ]\n\n    def __init__(self, *, config_class: Callable = LitellmModelConfig, **kwargs):\n        self.config = config_class(**kwargs)\n        if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n            litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        # Final defense: filter any null entries that slipped through\n        n_before = len(messages)\n        messages = [m for m in messages if m is not None and isinstance(m, dict)]\n        if len(messages) != n_before:\n            logger.warning(\n                \"Filtered %d invalid entries from %d messages before API call\",\n                n_before - len(messages), n_before,\n            )\n        try:\n            return litellm.completion(\n                model=self.config.model_name,\n                messages=messages,\n                tools=[BASH_TOOL],\n                **(self.config.model_kwargs | kwargs),\n            )\n        except litellm.exceptions.AuthenticationError as e:\n            e.message += \" You can permanently set your API key with `mini-extra config set KEY VALUE`.\"\n            raise e\n        except litellm.exceptions.BadRequestError as e:\n            if \"got null\" in str(e):\n                _diagnose_null_messages(messages)\n            raise\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        prepared = []\n        for msg in messages:\n            if msg is None:\n                continue\n            # Skip messages with non-API roles (e.g., \"exit\") \u2014 the OpenAI SDK\n            # serializes unrecognised roles as null, causing API errors.\n            if msg.get(\"role\") not in _VALID_API_ROLES:\n                continue\n            prepared.append(_sanitize_message(msg))\n        prepared = _reorder_anthropic_thinking_blocks(prepared)\n        return set_cache_control(prepared, mode=self.config.set_cache_control)\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = response.choices[0].message.model_dump()\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            \"response\": response.model_dump(),\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _calculate_cost(self, response) -&gt; dict[str, float]:\n        try:\n            cost = litellm.cost_calculator.completion_cost(response, model=self.config.model_name)\n            if cost &lt;= 0.0:\n                raise ValueError(f\"Cost must be &gt; 0.0, got {cost}\")\n        except Exception as e:\n            cost = 0.0\n            if self.config.cost_tracking != \"ignore_errors\":\n                msg = (\n                    f\"Error calculating cost for model {self.config.model_name}: {e}, perhaps it's not registered? \"\n                    \"You can ignore this issue from your config file with cost_tracking: 'ignore_errors' or \"\n                    \"globally with export MSWEA_COST_TRACKING='ignore_errors'. \"\n                    \"Alternatively check the 'Cost tracking' section in the documentation at \"\n                    \"https://klieret.short.gy/mini-local-models. \"\n                    \" Still stuck? Please open a github issue at https://github.com/SWE-agent/mini-swe-agent/issues/new/choose!\"\n                )\n                logger.critical(msg)\n                raise RuntimeError(msg) from e\n        return {\"cost\": cost}\n\n    def _parse_actions(self, response) -&gt; list[dict]:\n        \"\"\"Parse tool calls from the response. Raises FormatError if unknown tool.\"\"\"\n        tool_calls = response.choices[0].message.tool_calls or []\n        return parse_toolcall_actions(tool_calls, format_error_template=self.config.format_error_template)\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n</code></pre> <p>The other part that you most likely need to figure out are costs. There are two ways to do this with <code>litellm</code>:</p> <ol> <li>You set up a litellm proxy server (which gives you a lot of control over all the LM calls)</li> <li>You update the model registry (next section)</li> </ol>"},{"location":"models/local_models/#cost-tracking","title":"Cost tracking","text":"<p>If you run with the above, you will most likely get an error about missing cost information.</p> <p>If you do not need cost tracking, you can ignore these errors, ideally by editing your agent config file to add:</p> <pre><code>model:\n  cost_tracking: \"ignore_errors\"\n  ...\n...\n</code></pre> <p>Alternatively, you can set the global setting:</p> <pre><code>export MSWEA_COST_TRACKING=\"ignore_errors\"\n</code></pre> <p>However, note that this is a global setting, and will affect all models!</p> <p>However, the best way to handle the cost issue is to add a model registry to litellm to include your local model.</p> <p>LiteLLM gets its cost and model metadata from this file. You can override or add data from this file if it's outdated or missing your desired model by including a custom registry file.</p> <p>The model registry JSON file should follow LiteLLM's format:</p> <pre><code>{\n  \"my-custom-model\": {\n    \"max_tokens\": 4096,\n    \"input_cost_per_token\": 0.0001,\n    \"output_cost_per_token\": 0.0002,\n    \"litellm_provider\": \"openai\",\n    \"mode\": \"chat\"\n  },\n  \"my-local-model\": {\n    \"max_tokens\": 8192,\n    \"input_cost_per_token\": 0.0,\n    \"output_cost_per_token\": 0.0,\n    \"litellm_provider\": \"ollama\",\n    \"mode\": \"chat\"\n  }\n}\n</code></pre> <p>Model names</p> <p>Model names are case sensitive. Please make sure you have an exact match.</p> <p>Model provider</p> <p>If you use the <code>custom_llm_provider</code> or have a provider prefixed to the model name (e.g., <code>openai/...</code>), then this must also match <code>litellm_provider</code> in the config!</p> <p>There are two ways of setting the path to the model registry:</p> <ol> <li>Set <code>LITELLM_MODEL_REGISTRY_PATH</code> (e.g., <code>mini-extra config set LITELLM_MODEL_REGISTRY_PATH /path/to/model_registry.json</code>)</li> <li>Set <code>litellm_model_registry</code> in the agent config file</li> </ol> <pre><code>model:\n  litellm_model_registry: \"/path/to/model_registry.json\"\n  ...\n...\n</code></pre>"},{"location":"models/local_models/#concrete-examples","title":"Concrete examples","text":""},{"location":"models/local_models/#generating-swe-bench-trajectories-with-vllm","title":"Generating SWE-bench trajectories with vLLM","text":"<p>This example shows how to generate SWE-bench trajectories using vLLM as the local inference engine.</p> <p>First, launch a vLLM server with your chosen model. For example:</p> <pre><code>vllm serve ricdomolm/mini-coder-1.7b &amp;\n</code></pre> <p>By default, the server will be available at <code>http://localhost:8000</code>.</p> <p>Second, edit the mini-swe-agent SWE-bench config file located in <code>src/minisweagent/config/benchmarks/swebench.yaml</code> to include your local vLLM model:</p> <pre><code>model:\n  model_name: \"hosted_vllm/ricdomolm/mini-coder-1.7b\"  # or hosted_vllm/path/to/local/model\n  model_kwargs:\n    api_base: \"http://localhost:8000/v1\"  # adjust if using a non-default port/address\n</code></pre> <p>If you need a custom registry, as detailed above, create a <code>registry.json</code> file:</p> <pre><code>cat &gt; registry.json &lt;&lt;'EOF'\n{\n  \"ricdomolm/mini-coder-1.7b\": {\n    \"max_tokens\": 40960,\n    \"input_cost_per_token\": 0.0,\n    \"output_cost_per_token\": 0.0,\n    \"litellm_provider\": \"hosted_vllm\",\n    \"mode\": \"chat\"\n  }\n}\nEOF\n</code></pre> <p>Now you\u2019re ready to generate trajectories! Let's solve the <code>django__django-11099</code> instance of SWE-bench Verified:</p> <pre><code>LITELLM_MODEL_REGISTRY_PATH=registry.json mini-extra swebench \\\n    --output test/ --subset verified --split test --filter '^(django__django-11099)$'\n</code></pre> <p>You should now see the generated trajectory in the <code>test/</code> directory.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"models/quickstart/","title":"Quick start","text":""},{"location":"models/quickstart/#model-setup-quickstart","title":"Model setup quickstart","text":"<p>Setup</p> <ul> <li>In most cases, you can simply run <code>mini-extra config setup</code> to set up your default model and API keys.   This should be run the first time you run <code>mini</code>.</li> <li>By default we support all models using <code>litellm</code>.</li> <li>We also offer support for models via Openrouter and Portkey.</li> </ul>"},{"location":"models/quickstart/#setting-api-keys","title":"Setting API keys","text":"<p>There are several ways to set your API keys:</p> <ul> <li>Recommended: Run our setup script: <code>mini-extra config setup</code>. This should also run automatically the first time you run <code>mini</code>.</li> <li>Use <code>mini-extra config set ANTHROPIC_API_KEY &lt;your-api-key&gt;</code> to put the key in the <code>mini</code> config file.</li> <li>Export your key as an environment variable: <code>export ANTHROPIC_API_KEY=&lt;your-api-key&gt;</code> (this is not persistent if you restart your shell, unless you add it to your shell config, like <code>~/.bashrc</code> or <code>~/.zshrc</code>).</li> <li>If you run several agents in parallel, see our note about rotating anthropic keys here.</li> </ul> All the API key names <p>We use <code>litellm</code> to support most models. Here's a list of all the API key names available in <code>litellm</code>:</p> <pre><code>ALEPH_ALPHA_API_KEY\nALEPHALPHA_API_KEY\nANTHROPIC_API_KEY\nANYSCALE_API_KEY\nAZURE_AI_API_KEY\nAZURE_API_KEY\nAZURE_OPENAI_API_KEY\nBASETEN_API_KEY\nCEREBRAS_API_KEY\nCLARIFAI_API_KEY\nCLOUDFLARE_API_KEY\nCO_API_KEY\nCODESTRAL_API_KEY\nCOHERE_API_KEY\nDATABRICKS_API_KEY\nDEEPINFRA_API_KEY\nDEEPSEEK_API_KEY\nFEATHERLESS_AI_API_KEY\nFIREWORKS_AI_API_KEY\nFIREWORKS_API_KEY\nFIREWORKSAI_API_KEY\nGEMINI_API_KEY\nGROQ_API_KEY\nHUGGINGFACE_API_KEY\nINFINITY_API_KEY\nMARITALK_API_KEY\nMISTRAL_API_KEY\nNEBIUS_API_KEY\nNLP_CLOUD_API_KEY\nNOVITA_API_KEY\nNVIDIA_NIM_API_KEY\nOLLAMA_API_KEY\nOPENAI_API_KEY\nOPENAI_LIKE_API_KEY\nOPENROUTER_API_KEY\nOR_API_KEY\nPALM_API_KEY\nPERPLEXITYAI_API_KEY\nPREDIBASE_API_KEY\nPROVIDER_API_KEY\nREPLICATE_API_KEY\nTOGETHERAI_API_KEY\nVOLCENGINE_API_KEY\nVOYAGE_API_KEY\nWATSONX_API_KEY\nWX_API_KEY\nXAI_API_KEY\nXINFERENCE_API_KEY\n</code></pre> <p>In addition, Portkey models use the <code>PORTKEY_API_KEY</code> environment variable.</p>"},{"location":"models/quickstart/#selecting-a-model","title":"Selecting a model","text":"<p>Model names and providers.</p> <p>We support most models using <code>litellm</code>. You can find a list of their supported models here. Please always include the provider in the model name, e.g., <code>anthropic/claude-...</code>.</p> <ul> <li>Recommended: <code>mini-extra config setup</code> (should be run the first time you run <code>mini</code>) can set the default model for you</li> <li>All command line interfaces allow you to set the model name with <code>-m</code> or <code>--model</code>.</li> <li>In addition, you can set the default model with <code>mini-extra config set MSWEA_MODEL_NAME &lt;model-name&gt;</code>, by editing the global config file (shortcut: <code>mini-extra config edit</code>), or by setting the <code>MSWEA_MODEL_NAME</code> environment variable.</li> <li>You can also set your model in a config file (key <code>model_name</code> under <code>model</code>).</li> <li>If you want to use local models, please check this guide.</li> </ul> <p>Popular models</p> <p>Here's a few examples of popular models:</p> <pre><code>anthropic/claude-sonnet-4-5-20250929\nopenai/gpt-5\nopenai/gpt-5-mini\ngemini/gemini-2.5-pro\ndeepseek/deepseek-chat\n</code></pre> List of all supported models <p>Here's a list of all model names supported by <code>litellm</code> as of Aug 29th 2025. For even more recent models, check the <code>model_prices_and_context_window.json</code> file from litellm.</p> <pre><code>1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0\n1024-x-1024/50-steps/stability.stable-diffusion-xl-v1\n1024-x-1024/dall-e-2\n1024-x-1024/max-steps/stability.stable-diffusion-xl-v1\n256-x-256/dall-e-2\n512-x-512/50-steps/stability.stable-diffusion-xl-v0\n512-x-512/dall-e-2\n512-x-512/max-steps/stability.stable-diffusion-xl-v0\nai21.j2-mid-v1\nai21.j2-ultra-v1\nai21.jamba-1-5-large-v1:0\nai21.jamba-1-5-mini-v1:0\nai21.jamba-instruct-v1:0\naiml/dall-e-2\naiml/dall-e-3\naiml/flux-pro\naiml/flux-pro/v1.1\naiml/flux-pro/v1.1-ultra\naiml/flux-realism\naiml/flux/dev\naiml/flux/kontext-max/text-to-image\naiml/flux/kontext-pro/text-to-image\naiml/flux/schnell\namazon.nova-lite-v1:0\namazon.nova-micro-v1:0\namazon.nova-pro-v1:0\namazon.rerank-v1:0\namazon.titan-embed-image-v1\namazon.titan-embed-text-v1\namazon.titan-embed-text-v2:0\namazon.titan-text-express-v1\namazon.titan-text-lite-v1\namazon.titan-text-premier-v1:0\nanthropic.claude-3-5-haiku-20241022-v1:0\nanthropic.claude-3-5-sonnet-20240620-v1:0\nanthropic.claude-3-5-sonnet-20241022-v2:0\nanthropic.claude-3-7-sonnet-20250219-v1:0\nanthropic.claude-3-haiku-20240307-v1:0\nanthropic.claude-3-opus-20240229-v1:0\nanthropic.claude-3-sonnet-20240229-v1:0\nanthropic.claude-instant-v1\nanthropic.claude-opus-4-1-20250805-v1:0\nanthropic.claude-opus-4-20250514-v1:0\nanthropic.claude-sonnet-4-20250514-v1:0\nanthropic.claude-sonnet-4-5-20250929-v1:0\nanthropic.claude-v1\nanthropic.claude-v2\nanthropic.claude-v2:1\nanyscale/HuggingFaceH4/zephyr-7b-beta\nanyscale/codellama/CodeLlama-34b-Instruct-hf\nanyscale/codellama/CodeLlama-70b-Instruct-hf\nanyscale/google/gemma-7b-it\nanyscale/meta-llama/Llama-2-13b-chat-hf\nanyscale/meta-llama/Llama-2-70b-chat-hf\nanyscale/meta-llama/Llama-2-7b-chat-hf\nanyscale/meta-llama/Meta-Llama-3-70B-Instruct\nanyscale/meta-llama/Meta-Llama-3-8B-Instruct\nanyscale/mistralai/Mistral-7B-Instruct-v0.1\nanyscale/mistralai/Mixtral-8x22B-Instruct-v0.1\nanyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\napac.amazon.nova-lite-v1:0\napac.amazon.nova-micro-v1:0\napac.amazon.nova-pro-v1:0\napac.anthropic.claude-3-5-sonnet-20240620-v1:0\napac.anthropic.claude-3-5-sonnet-20241022-v2:0\napac.anthropic.claude-3-haiku-20240307-v1:0\napac.anthropic.claude-3-sonnet-20240229-v1:0\napac.anthropic.claude-sonnet-4-20250514-v1:0\napac.anthropic.claude-sonnet-4-5-20250929-v1:0\nassemblyai/best\nassemblyai/nano\nazure/ada\nazure/codex-mini\nazure/command-r-plus\nazure/computer-use-preview\nazure/eu/gpt-4o-2024-08-06\nazure/eu/gpt-4o-2024-11-20\nazure/eu/gpt-4o-mini-2024-07-18\nazure/eu/gpt-4o-mini-realtime-preview-2024-12-17\nazure/eu/gpt-4o-realtime-preview-2024-10-01\nazure/eu/gpt-4o-realtime-preview-2024-12-17\nazure/eu/o1-2024-12-17\nazure/eu/o1-mini-2024-09-12\nazure/eu/o1-preview-2024-09-12\nazure/eu/o3-mini-2025-01-31\nazure/global-standard/gpt-4o-2024-08-06\nazure/global-standard/gpt-4o-2024-11-20\nazure/global-standard/gpt-4o-mini\nazure/global/gpt-4o-2024-08-06\nazure/global/gpt-4o-2024-11-20\nazure/gpt-3.5-turbo\nazure/gpt-3.5-turbo-0125\nazure/gpt-3.5-turbo-instruct-0914\nazure/gpt-35-turbo\nazure/gpt-35-turbo-0125\nazure/gpt-35-turbo-0301\nazure/gpt-35-turbo-0613\nazure/gpt-35-turbo-1106\nazure/gpt-35-turbo-16k\nazure/gpt-35-turbo-16k-0613\nazure/gpt-35-turbo-instruct\nazure/gpt-35-turbo-instruct-0914\nazure/gpt-4\nazure/gpt-4-0125-preview\nazure/gpt-4-0613\nazure/gpt-4-1106-preview\nazure/gpt-4-32k\nazure/gpt-4-32k-0613\nazure/gpt-4-turbo\nazure/gpt-4-turbo-2024-04-09\nazure/gpt-4-turbo-vision-preview\nazure/gpt-4.1\nazure/gpt-4.1-2025-04-14\nazure/gpt-4.1-mini\nazure/gpt-4.1-mini-2025-04-14\nazure/gpt-4.1-nano\nazure/gpt-4.1-nano-2025-04-14\nazure/gpt-4.5-preview\nazure/gpt-4o\nazure/gpt-4o-2024-05-13\nazure/gpt-4o-2024-08-06\nazure/gpt-4o-2024-11-20\nazure/gpt-4o-audio-preview-2024-12-17\nazure/gpt-4o-mini\nazure/gpt-4o-mini-2024-07-18\nazure/gpt-4o-mini-audio-preview-2024-12-17\nazure/gpt-4o-mini-realtime-preview-2024-12-17\nazure/gpt-4o-mini-transcribe\nazure/gpt-4o-mini-tts\nazure/gpt-4o-realtime-preview-2024-10-01\nazure/gpt-4o-realtime-preview-2024-12-17\nazure/gpt-4o-transcribe\nazure/gpt-5\nazure/gpt-5-2025-08-07\nazure/gpt-5-chat\nazure/gpt-5-chat-latest\nazure/gpt-5-mini\nazure/gpt-5-mini-2025-08-07\nazure/gpt-5-nano\nazure/gpt-5-nano-2025-08-07\nazure/gpt-image-1\nazure/hd/1024-x-1024/dall-e-3\nazure/hd/1024-x-1792/dall-e-3\nazure/hd/1792-x-1024/dall-e-3\nazure/high/1024-x-1024/gpt-image-1\nazure/high/1024-x-1536/gpt-image-1\nazure/high/1536-x-1024/gpt-image-1\nazure/low/1024-x-1024/gpt-image-1\nazure/low/1024-x-1536/gpt-image-1\nazure/low/1536-x-1024/gpt-image-1\nazure/medium/1024-x-1024/gpt-image-1\nazure/medium/1024-x-1536/gpt-image-1\nazure/medium/1536-x-1024/gpt-image-1\nazure/mistral-large-2402\nazure/mistral-large-latest\nazure/o1\nazure/o1-2024-12-17\nazure/o1-mini\nazure/o1-mini-2024-09-12\nazure/o1-preview\nazure/o1-preview-2024-09-12\nazure/o3\nazure/o3-2025-04-16\nazure/o3-deep-research\nazure/o3-mini\nazure/o3-mini-2025-01-31\nazure/o3-pro\nazure/o3-pro-2025-06-10\nazure/o4-mini\nazure/o4-mini-2025-04-16\nazure/standard/1024-x-1024/dall-e-2\nazure/standard/1024-x-1024/dall-e-3\nazure/standard/1024-x-1792/dall-e-3\nazure/standard/1792-x-1024/dall-e-3\nazure/text-embedding-3-large\nazure/text-embedding-3-small\nazure/text-embedding-ada-002\nazure/tts-1\nazure/tts-1-hd\nazure/us/gpt-4o-2024-08-06\nazure/us/gpt-4o-2024-11-20\nazure/us/gpt-4o-mini-2024-07-18\nazure/us/gpt-4o-mini-realtime-preview-2024-12-17\nazure/us/gpt-4o-realtime-preview-2024-10-01\nazure/us/gpt-4o-realtime-preview-2024-12-17\nazure/us/o1-2024-12-17\nazure/us/o1-mini-2024-09-12\nazure/us/o1-preview-2024-09-12\nazure/us/o3-mini-2025-01-31\nazure/whisper-1\nazure_ai/Cohere-embed-v3-english\nazure_ai/Cohere-embed-v3-multilingual\nazure_ai/FLUX-1.1-pro\nazure_ai/FLUX.1-Kontext-pro\nazure_ai/Llama-3.2-11B-Vision-Instruct\nazure_ai/Llama-3.2-90B-Vision-Instruct\nazure_ai/Llama-3.3-70B-Instruct\nazure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8\nazure_ai/Llama-4-Scout-17B-16E-Instruct\nazure_ai/Meta-Llama-3-70B-Instruct\nazure_ai/Meta-Llama-3.1-405B-Instruct\nazure_ai/Meta-Llama-3.1-70B-Instruct\nazure_ai/Meta-Llama-3.1-8B-Instruct\nazure_ai/Phi-3-medium-128k-instruct\nazure_ai/Phi-3-medium-4k-instruct\nazure_ai/Phi-3-mini-128k-instruct\nazure_ai/Phi-3-mini-4k-instruct\nazure_ai/Phi-3-small-128k-instruct\nazure_ai/Phi-3-small-8k-instruct\nazure_ai/Phi-3.5-MoE-instruct\nazure_ai/Phi-3.5-mini-instruct\nazure_ai/Phi-3.5-vision-instruct\nazure_ai/Phi-4\nazure_ai/Phi-4-mini-instruct\nazure_ai/Phi-4-multimodal-instruct\nazure_ai/cohere-rerank-v3-english\nazure_ai/cohere-rerank-v3-multilingual\nazure_ai/cohere-rerank-v3.5\nazure_ai/deepseek-r1\nazure_ai/deepseek-v3\nazure_ai/deepseek-v3-0324\nazure_ai/embed-v-4-0\nazure_ai/global/grok-3\nazure_ai/global/grok-3-mini\nazure_ai/grok-3\nazure_ai/grok-3-mini\nazure_ai/jais-30b-chat\nazure_ai/jamba-instruct\nazure_ai/ministral-3b\nazure_ai/mistral-large\nazure_ai/mistral-large-2407\nazure_ai/mistral-large-latest\nazure_ai/mistral-medium-2505\nazure_ai/mistral-nemo\nazure_ai/mistral-small\nazure_ai/mistral-small-2503\nbabbage-002\nbedrock/*/1-month-commitment/cohere.command-light-text-v14\nbedrock/*/1-month-commitment/cohere.command-text-v14\nbedrock/*/6-month-commitment/cohere.command-light-text-v14\nbedrock/*/6-month-commitment/cohere.command-text-v14\nbedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1\nbedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1\nbedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2\nbedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1\nbedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1\nbedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1\nbedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2\nbedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1\nbedrock/ap-northeast-1/anthropic.claude-instant-v1\nbedrock/ap-northeast-1/anthropic.claude-v1\nbedrock/ap-northeast-1/anthropic.claude-v2\nbedrock/ap-northeast-1/anthropic.claude-v2:1\nbedrock/ap-south-1/meta.llama3-70b-instruct-v1:0\nbedrock/ap-south-1/meta.llama3-8b-instruct-v1:0\nbedrock/ca-central-1/meta.llama3-70b-instruct-v1:0\nbedrock/ca-central-1/meta.llama3-8b-instruct-v1:0\nbedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1\nbedrock/eu-central-1/1-month-commitment/anthropic.claude-v1\nbedrock/eu-central-1/1-month-commitment/anthropic.claude-v2\nbedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1\nbedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1\nbedrock/eu-central-1/6-month-commitment/anthropic.claude-v1\nbedrock/eu-central-1/6-month-commitment/anthropic.claude-v2\nbedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1\nbedrock/eu-central-1/anthropic.claude-instant-v1\nbedrock/eu-central-1/anthropic.claude-v1\nbedrock/eu-central-1/anthropic.claude-v2\nbedrock/eu-central-1/anthropic.claude-v2:1\nbedrock/eu-west-1/meta.llama3-70b-instruct-v1:0\nbedrock/eu-west-1/meta.llama3-8b-instruct-v1:0\nbedrock/eu-west-2/meta.llama3-70b-instruct-v1:0\nbedrock/eu-west-2/meta.llama3-8b-instruct-v1:0\nbedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2\nbedrock/eu-west-3/mistral.mistral-large-2402-v1:0\nbedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1\nbedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0\nbedrock/sa-east-1/meta.llama3-70b-instruct-v1:0\nbedrock/sa-east-1/meta.llama3-8b-instruct-v1:0\nbedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1\nbedrock/us-east-1/1-month-commitment/anthropic.claude-v1\nbedrock/us-east-1/1-month-commitment/anthropic.claude-v2\nbedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1\nbedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1\nbedrock/us-east-1/6-month-commitment/anthropic.claude-v1\nbedrock/us-east-1/6-month-commitment/anthropic.claude-v2\nbedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1\nbedrock/us-east-1/anthropic.claude-instant-v1\nbedrock/us-east-1/anthropic.claude-v1\nbedrock/us-east-1/anthropic.claude-v2\nbedrock/us-east-1/anthropic.claude-v2:1\nbedrock/us-east-1/meta.llama3-70b-instruct-v1:0\nbedrock/us-east-1/meta.llama3-8b-instruct-v1:0\nbedrock/us-east-1/mistral.mistral-7b-instruct-v0:2\nbedrock/us-east-1/mistral.mistral-large-2402-v1:0\nbedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1\nbedrock/us-gov-east-1/amazon.nova-pro-v1:0\nbedrock/us-gov-east-1/amazon.titan-embed-text-v1\nbedrock/us-gov-east-1/amazon.titan-embed-text-v2:0\nbedrock/us-gov-east-1/amazon.titan-text-express-v1\nbedrock/us-gov-east-1/amazon.titan-text-lite-v1\nbedrock/us-gov-east-1/amazon.titan-text-premier-v1:0\nbedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0\nbedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0\nbedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0\nbedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0\nbedrock/us-gov-west-1/amazon.nova-pro-v1:0\nbedrock/us-gov-west-1/amazon.titan-embed-text-v1\nbedrock/us-gov-west-1/amazon.titan-embed-text-v2:0\nbedrock/us-gov-west-1/amazon.titan-text-express-v1\nbedrock/us-gov-west-1/amazon.titan-text-lite-v1\nbedrock/us-gov-west-1/amazon.titan-text-premier-v1:0\nbedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0\nbedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0\nbedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0\nbedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0\nbedrock/us-west-1/meta.llama3-70b-instruct-v1:0\nbedrock/us-west-1/meta.llama3-8b-instruct-v1:0\nbedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1\nbedrock/us-west-2/1-month-commitment/anthropic.claude-v1\nbedrock/us-west-2/1-month-commitment/anthropic.claude-v2\nbedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1\nbedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1\nbedrock/us-west-2/6-month-commitment/anthropic.claude-v1\nbedrock/us-west-2/6-month-commitment/anthropic.claude-v2\nbedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1\nbedrock/us-west-2/anthropic.claude-instant-v1\nbedrock/us-west-2/anthropic.claude-v1\nbedrock/us-west-2/anthropic.claude-v2\nbedrock/us-west-2/anthropic.claude-v2:1\nbedrock/us-west-2/mistral.mistral-7b-instruct-v0:2\nbedrock/us-west-2/mistral.mistral-large-2402-v1:0\nbedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1\ncerebras/llama-3.3-70b\ncerebras/llama3.1-70b\ncerebras/llama3.1-8b\ncerebras/openai/gpt-oss-120b\ncerebras/openai/gpt-oss-20b\ncerebras/qwen-3-32b\nchat-bison\nchat-bison-32k\nchat-bison-32k@002\nchat-bison@001\nchat-bison@002\nchatdolphin\nchatgpt-4o-latest\nclaude-3-5-haiku-20241022\nclaude-3-5-haiku-latest\nclaude-3-5-sonnet-20240620\nclaude-3-5-sonnet-20241022\nclaude-3-5-sonnet-latest\nclaude-3-7-sonnet-20250219\nclaude-3-7-sonnet-latest\nclaude-3-haiku-20240307\nclaude-3-opus-20240229\nclaude-3-opus-latest\nclaude-4-opus-20250514\nclaude-4-sonnet-20250514\nclaude-opus-4-1\nclaude-opus-4-1-20250805\nclaude-opus-4-20250514\nclaude-sonnet-4-20250514\nclaude-sonnet-4-5-20250929\ncloudflare/@cf/meta/llama-2-7b-chat-fp16\ncloudflare/@cf/meta/llama-2-7b-chat-int8\ncloudflare/@cf/mistral/mistral-7b-instruct-v0.1\ncloudflare/@hf/thebloke/codellama-7b-instruct-awq\ncode-bison\ncode-bison-32k@002\ncode-bison32k\ncode-bison@001\ncode-bison@002\ncode-gecko\ncode-gecko-latest\ncode-gecko@001\ncode-gecko@002\ncodechat-bison\ncodechat-bison-32k\ncodechat-bison-32k@002\ncodechat-bison@001\ncodechat-bison@002\ncodechat-bison@latest\ncodestral/codestral-2405\ncodestral/codestral-latest\ncodex-mini-latest\ncohere.command-light-text-v14\ncohere.command-r-plus-v1:0\ncohere.command-r-v1:0\ncohere.command-text-v14\ncohere.embed-english-v3\ncohere.embed-multilingual-v3\ncohere.rerank-v3-5:0\ncommand\ncommand-a-03-2025\ncommand-light\ncommand-nightly\ncommand-r\ncommand-r-08-2024\ncommand-r-plus\ncommand-r-plus-08-2024\ncommand-r7b-12-2024\ncomputer-use-preview\ndashscope/qwen-max\ndashscope/qwen-plus-latest\ndashscope/qwen-turbo-latest\ndashscope/qwen3-30b-a3b\ndatabricks/databricks-bge-large-en\ndatabricks/databricks-claude-3-7-sonnet\ndatabricks/databricks-gte-large-en\ndatabricks/databricks-llama-2-70b-chat\ndatabricks/databricks-llama-4-maverick\ndatabricks/databricks-meta-llama-3-1-405b-instruct\ndatabricks/databricks-meta-llama-3-3-70b-instruct\ndatabricks/databricks-meta-llama-3-70b-instruct\ndatabricks/databricks-mixtral-8x7b-instruct\ndatabricks/databricks-mpt-30b-instruct\ndatabricks/databricks-mpt-7b-instruct\ndavinci-002\ndeepgram/base\ndeepgram/base-conversationalai\ndeepgram/base-finance\ndeepgram/base-general\ndeepgram/base-meeting\ndeepgram/base-phonecall\ndeepgram/base-video\ndeepgram/base-voicemail\ndeepgram/enhanced\ndeepgram/enhanced-finance\ndeepgram/enhanced-general\ndeepgram/enhanced-meeting\ndeepgram/enhanced-phonecall\ndeepgram/nova\ndeepgram/nova-2\ndeepgram/nova-2-atc\ndeepgram/nova-2-automotive\ndeepgram/nova-2-conversationalai\ndeepgram/nova-2-drivethru\ndeepgram/nova-2-finance\ndeepgram/nova-2-general\ndeepgram/nova-2-meeting\ndeepgram/nova-2-phonecall\ndeepgram/nova-2-video\ndeepgram/nova-2-voicemail\ndeepgram/nova-3\ndeepgram/nova-3-general\ndeepgram/nova-3-medical\ndeepgram/nova-general\ndeepgram/nova-phonecall\ndeepgram/whisper\ndeepgram/whisper-base\ndeepgram/whisper-large\ndeepgram/whisper-medium\ndeepgram/whisper-small\ndeepgram/whisper-tiny\ndeepinfra/Austism/chronos-hermes-13b-v2\ndeepinfra/Gryphe/MythoMax-L2-13b\ndeepinfra/Gryphe/MythoMax-L2-13b-turbo\ndeepinfra/KoboldAI/LLaMA2-13B-Tiefighter\ndeepinfra/NousResearch/Hermes-3-Llama-3.1-405B\ndeepinfra/NousResearch/Hermes-3-Llama-3.1-70B\ndeepinfra/NovaSky-AI/Sky-T1-32B-Preview\ndeepinfra/Phind/Phind-CodeLlama-34B-v2\ndeepinfra/Qwen/QVQ-72B-Preview\ndeepinfra/Qwen/QwQ-32B\ndeepinfra/Qwen/QwQ-32B-Preview\ndeepinfra/Qwen/Qwen2-72B-Instruct\ndeepinfra/Qwen/Qwen2-7B-Instruct\ndeepinfra/Qwen/Qwen2.5-72B-Instruct\ndeepinfra/Qwen/Qwen2.5-7B-Instruct\ndeepinfra/Qwen/Qwen2.5-Coder-32B-Instruct\ndeepinfra/Qwen/Qwen2.5-Coder-7B\ndeepinfra/Qwen/Qwen2.5-VL-32B-Instruct\ndeepinfra/Qwen/Qwen3-14B\ndeepinfra/Qwen/Qwen3-235B-A22B\ndeepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507\ndeepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507\ndeepinfra/Qwen/Qwen3-30B-A3B\ndeepinfra/Qwen/Qwen3-32B\ndeepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct\ndeepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo\ndeepinfra/Sao10K/L3-70B-Euryale-v2.1\ndeepinfra/Sao10K/L3-8B-Lunaris-v1\ndeepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo\ndeepinfra/Sao10K/L3.1-70B-Euryale-v2.2\ndeepinfra/Sao10K/L3.3-70B-Euryale-v2.3\ndeepinfra/allenai/olmOCR-7B-0725-FP8\ndeepinfra/anthropic/claude-3-7-sonnet-latest\ndeepinfra/anthropic/claude-4-opus\ndeepinfra/anthropic/claude-4-sonnet\ndeepinfra/bigcode/starcoder2-15b-instruct-v0.1\ndeepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b\ndeepinfra/cognitivecomputations/dolphin-2.9.1-llama-3-70b\ndeepinfra/deepinfra/airoboros-70b\ndeepinfra/deepseek-ai/DeepSeek-Prover-V2-671B\ndeepinfra/deepseek-ai/DeepSeek-R1\ndeepinfra/deepseek-ai/DeepSeek-R1-0528\ndeepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo\ndeepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\ndeepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\ndeepinfra/deepseek-ai/DeepSeek-R1-Turbo\ndeepinfra/deepseek-ai/DeepSeek-V3\ndeepinfra/deepseek-ai/DeepSeek-V3-0324\ndeepinfra/deepseek-ai/DeepSeek-V3-0324-Turbo\ndeepinfra/deepseek-ai/DeepSeek-V3.1\ndeepinfra/google/codegemma-7b-it\ndeepinfra/google/gemini-1.5-flash\ndeepinfra/google/gemini-1.5-flash-8b\ndeepinfra/google/gemini-2.0-flash-001\ndeepinfra/google/gemini-2.5-flash\ndeepinfra/google/gemini-2.5-pro\ndeepinfra/google/gemma-1.1-7b-it\ndeepinfra/google/gemma-2-27b-it\ndeepinfra/google/gemma-2-9b-it\ndeepinfra/google/gemma-3-12b-it\ndeepinfra/google/gemma-3-27b-it\ndeepinfra/google/gemma-3-4b-it\ndeepinfra/lizpreciatior/lzlv_70b_fp16_hf\ndeepinfra/mattshumer/Reflection-Llama-3.1-70B\ndeepinfra/meta-llama/Llama-2-13b-chat-hf\ndeepinfra/meta-llama/Llama-2-70b-chat-hf\ndeepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct\ndeepinfra/meta-llama/Llama-3.2-1B-Instruct\ndeepinfra/meta-llama/Llama-3.2-3B-Instruct\ndeepinfra/meta-llama/Llama-3.2-90B-Vision-Instruct\ndeepinfra/meta-llama/Llama-3.3-70B-Instruct\ndeepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo\ndeepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\ndeepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo\ndeepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct\ndeepinfra/meta-llama/Llama-Guard-3-8B\ndeepinfra/meta-llama/Llama-Guard-4-12B\ndeepinfra/meta-llama/Meta-Llama-3-70B-Instruct\ndeepinfra/meta-llama/Meta-Llama-3-8B-Instruct\ndeepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct\ndeepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct\ndeepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\ndeepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct\ndeepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\ndeepinfra/microsoft/Phi-3-medium-4k-instruct\ndeepinfra/microsoft/Phi-4-multimodal-instruct\ndeepinfra/microsoft/WizardLM-2-7B\ndeepinfra/microsoft/WizardLM-2-8x22B\ndeepinfra/microsoft/phi-4\ndeepinfra/microsoft/phi-4-reasoning-plus\ndeepinfra/mistralai/Devstral-Small-2505\ndeepinfra/mistralai/Devstral-Small-2507\ndeepinfra/mistralai/Mistral-7B-Instruct-v0.1\ndeepinfra/mistralai/Mistral-7B-Instruct-v0.2\ndeepinfra/mistralai/Mistral-7B-Instruct-v0.3\ndeepinfra/mistralai/Mistral-Nemo-Instruct-2407\ndeepinfra/mistralai/Mistral-Small-24B-Instruct-2501\ndeepinfra/mistralai/Mistral-Small-3.1-24B-Instruct-2503\ndeepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506\ndeepinfra/mistralai/Mixtral-8x22B-Instruct-v0.1\ndeepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1\ndeepinfra/moonshotai/Kimi-K2-Instruct\ndeepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct\ndeepinfra/nvidia/Nemotron-4-340B-Instruct\ndeepinfra/openai/gpt-oss-120b\ndeepinfra/openai/gpt-oss-20b\ndeepinfra/openbmb/MiniCPM-Llama3-V-2_5\ndeepinfra/openchat/openchat-3.6-8b\ndeepinfra/openchat/openchat_3.5\ndeepinfra/zai-org/GLM-4.5\ndeepinfra/zai-org/GLM-4.5-Air\ndeepseek/deepseek-chat\ndeepseek/deepseek-coder\ndeepseek/deepseek-r1\ndeepseek/deepseek-reasoner\ndeepseek/deepseek-v3\ndolphin\nelevenlabs/scribe_v1\nelevenlabs/scribe_v1_experimental\nembed-english-light-v2.0\nembed-english-light-v3.0\nembed-english-v2.0\nembed-english-v3.0\nembed-multilingual-v2.0\nembed-multilingual-v3.0\neu.amazon.nova-lite-v1:0\neu.amazon.nova-micro-v1:0\neu.amazon.nova-pro-v1:0\neu.anthropic.claude-3-5-haiku-20241022-v1:0\neu.anthropic.claude-3-5-sonnet-20240620-v1:0\neu.anthropic.claude-3-5-sonnet-20241022-v2:0\neu.anthropic.claude-3-7-sonnet-20250219-v1:0\neu.anthropic.claude-3-haiku-20240307-v1:0\neu.anthropic.claude-3-opus-20240229-v1:0\neu.anthropic.claude-3-sonnet-20240229-v1:0\neu.anthropic.claude-opus-4-1-20250805-v1:0\neu.anthropic.claude-opus-4-20250514-v1:0\neu.anthropic.claude-sonnet-4-20250514-v1:0\neu.anthropic.claude-sonnet-4-5-20250929-v1:0\neu.meta.llama3-2-1b-instruct-v1:0\neu.meta.llama3-2-3b-instruct-v1:0\neu.mistral.pixtral-large-2502-v1:0\nfeatherless_ai/featherless-ai/Qwerky-72B\nfeatherless_ai/featherless-ai/Qwerky-QwQ-32B\nfireworks-ai-4.1b-to-16b\nfireworks-ai-56b-to-176b\nfireworks-ai-above-16b\nfireworks-ai-default\nfireworks-ai-embedding-150m-to-350m\nfireworks-ai-embedding-up-to-150m\nfireworks-ai-moe-up-to-56b\nfireworks-ai-up-to-4b\nfireworks_ai/WhereIsAI/UAE-Large-V1\nfireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct\nfireworks_ai/accounts/fireworks/models/deepseek-r1\nfireworks_ai/accounts/fireworks/models/deepseek-r1-0528\nfireworks_ai/accounts/fireworks/models/deepseek-r1-basic\nfireworks_ai/accounts/fireworks/models/deepseek-v3\nfireworks_ai/accounts/fireworks/models/deepseek-v3-0324\nfireworks_ai/accounts/fireworks/models/deepseek-v3p1\nfireworks_ai/accounts/fireworks/models/firefunction-v2\nfireworks_ai/accounts/fireworks/models/glm-4p5\nfireworks_ai/accounts/fireworks/models/glm-4p5-air\nfireworks_ai/accounts/fireworks/models/gpt-oss-120b\nfireworks_ai/accounts/fireworks/models/gpt-oss-20b\nfireworks_ai/accounts/fireworks/models/kimi-k2-instruct\nfireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct\nfireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct\nfireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct\nfireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct\nfireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct\nfireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct\nfireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic\nfireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic\nfireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf\nfireworks_ai/accounts/fireworks/models/qwen2-72b-instruct\nfireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct\nfireworks_ai/accounts/fireworks/models/yi-large\nfireworks_ai/nomic-ai/nomic-embed-text-v1\nfireworks_ai/nomic-ai/nomic-embed-text-v1.5\nfireworks_ai/thenlper/gte-base\nfireworks_ai/thenlper/gte-large\nfriendliai/meta-llama-3.1-70b-instruct\nfriendliai/meta-llama-3.1-8b-instruct\nft:babbage-002\nft:davinci-002\nft:gpt-3.5-turbo\nft:gpt-3.5-turbo-0125\nft:gpt-3.5-turbo-0613\nft:gpt-3.5-turbo-1106\nft:gpt-4-0613\nft:gpt-4o-2024-08-06\nft:gpt-4o-2024-11-20\nft:gpt-4o-mini-2024-07-18\ngemini-1.0-pro\ngemini-1.0-pro-001\ngemini-1.0-pro-002\ngemini-1.0-pro-vision\ngemini-1.0-pro-vision-001\ngemini-1.0-ultra\ngemini-1.0-ultra-001\ngemini-1.5-flash\ngemini-1.5-flash-001\ngemini-1.5-flash-002\ngemini-1.5-flash-exp-0827\ngemini-1.5-flash-preview-0514\ngemini-1.5-pro\ngemini-1.5-pro-001\ngemini-1.5-pro-002\ngemini-1.5-pro-preview-0215\ngemini-1.5-pro-preview-0409\ngemini-1.5-pro-preview-0514\ngemini-2.0-flash\ngemini-2.0-flash-001\ngemini-2.0-flash-exp\ngemini-2.0-flash-lite\ngemini-2.0-flash-lite-001\ngemini-2.0-flash-live-preview-04-09\ngemini-2.0-flash-preview-image-generation\ngemini-2.0-flash-thinking-exp\ngemini-2.0-flash-thinking-exp-01-21\ngemini-2.0-pro-exp-02-05\ngemini-2.5-flash\ngemini-2.5-flash-image-preview\ngemini-2.5-flash-lite\ngemini-2.5-flash-lite-preview-06-17\ngemini-2.5-flash-preview-04-17\ngemini-2.5-flash-preview-05-20\ngemini-2.5-pro\ngemini-2.5-pro-exp-03-25\ngemini-2.5-pro-preview-03-25\ngemini-2.5-pro-preview-05-06\ngemini-2.5-pro-preview-06-05\ngemini-2.5-pro-preview-tts\ngemini-embedding-001\ngemini-flash-experimental\ngemini-pro\ngemini-pro-experimental\ngemini-pro-vision\ngemini/gemini-1.5-flash\ngemini/gemini-1.5-flash-001\ngemini/gemini-1.5-flash-002\ngemini/gemini-1.5-flash-8b\ngemini/gemini-1.5-flash-8b-exp-0827\ngemini/gemini-1.5-flash-8b-exp-0924\ngemini/gemini-1.5-flash-exp-0827\ngemini/gemini-1.5-flash-latest\ngemini/gemini-1.5-pro\ngemini/gemini-1.5-pro-001\ngemini/gemini-1.5-pro-002\ngemini/gemini-1.5-pro-exp-0801\ngemini/gemini-1.5-pro-exp-0827\ngemini/gemini-1.5-pro-latest\ngemini/gemini-2.0-flash\ngemini/gemini-2.0-flash-001\ngemini/gemini-2.0-flash-exp\ngemini/gemini-2.0-flash-lite\ngemini/gemini-2.0-flash-lite-preview-02-05\ngemini/gemini-2.0-flash-live-001\ngemini/gemini-2.0-flash-preview-image-generation\ngemini/gemini-2.0-flash-thinking-exp\ngemini/gemini-2.0-flash-thinking-exp-01-21\ngemini/gemini-2.0-pro-exp-02-05\ngemini/gemini-2.5-flash\ngemini/gemini-2.5-flash-image-preview\ngemini/gemini-2.5-flash-lite\ngemini/gemini-2.5-flash-lite-preview-06-17\ngemini/gemini-2.5-flash-preview-04-17\ngemini/gemini-2.5-flash-preview-05-20\ngemini/gemini-2.5-flash-preview-tts\ngemini/gemini-2.5-pro\ngemini/gemini-2.5-pro-exp-03-25\ngemini/gemini-2.5-pro-preview-03-25\ngemini/gemini-2.5-pro-preview-05-06\ngemini/gemini-2.5-pro-preview-06-05\ngemini/gemini-2.5-pro-preview-tts\ngemini/gemini-exp-1114\ngemini/gemini-exp-1206\ngemini/gemini-gemma-2-27b-it\ngemini/gemini-gemma-2-9b-it\ngemini/gemini-pro\ngemini/gemini-pro-vision\ngemini/gemma-3-27b-it\ngemini/imagen-3.0-fast-generate-001\ngemini/imagen-3.0-generate-001\ngemini/imagen-3.0-generate-002\ngemini/imagen-4.0-fast-generate-001\ngemini/imagen-4.0-generate-001\ngemini/imagen-4.0-ultra-generate-001\ngemini/learnlm-1.5-pro-experimental\ngpt-3.5-turbo\ngpt-3.5-turbo-0125\ngpt-3.5-turbo-0301\ngpt-3.5-turbo-0613\ngpt-3.5-turbo-1106\ngpt-3.5-turbo-16k\ngpt-3.5-turbo-16k-0613\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct-0914\ngpt-4\ngpt-4-0125-preview\ngpt-4-0314\ngpt-4-0613\ngpt-4-1106-preview\ngpt-4-1106-vision-preview\ngpt-4-32k\ngpt-4-32k-0314\ngpt-4-32k-0613\ngpt-4-turbo\ngpt-4-turbo-2024-04-09\ngpt-4-turbo-preview\ngpt-4-vision-preview\ngpt-4.1\ngpt-4.1-2025-04-14\ngpt-4.1-mini\ngpt-4.1-mini-2025-04-14\ngpt-4.1-nano\ngpt-4.1-nano-2025-04-14\ngpt-4.5-preview\ngpt-4.5-preview-2025-02-27\ngpt-4o\ngpt-4o-2024-05-13\ngpt-4o-2024-08-06\ngpt-4o-2024-11-20\ngpt-4o-audio-preview\ngpt-4o-audio-preview-2024-10-01\ngpt-4o-audio-preview-2024-12-17\ngpt-4o-audio-preview-2025-06-03\ngpt-4o-mini\ngpt-4o-mini-2024-07-18\ngpt-4o-mini-audio-preview\ngpt-4o-mini-audio-preview-2024-12-17\ngpt-4o-mini-realtime-preview\ngpt-4o-mini-realtime-preview-2024-12-17\ngpt-4o-mini-search-preview\ngpt-4o-mini-search-preview-2025-03-11\ngpt-4o-mini-transcribe\ngpt-4o-mini-tts\ngpt-4o-realtime-preview\ngpt-4o-realtime-preview-2024-10-01\ngpt-4o-realtime-preview-2024-12-17\ngpt-4o-realtime-preview-2025-06-03\ngpt-4o-search-preview\ngpt-4o-search-preview-2025-03-11\ngpt-4o-transcribe\ngpt-5\ngpt-5-2025-08-07\ngpt-5-chat\ngpt-5-chat-latest\ngpt-5-mini\ngpt-5-mini-2025-08-07\ngpt-5-nano\ngpt-5-nano-2025-08-07\ngpt-image-1\ngradient_ai/alibaba-qwen3-32b\ngradient_ai/anthropic-claude-3-opus\ngradient_ai/anthropic-claude-3.5-haiku\ngradient_ai/anthropic-claude-3.5-sonnet\ngradient_ai/anthropic-claude-3.7-sonnet\ngradient_ai/deepseek-r1-distill-llama-70b\ngradient_ai/llama3-8b-instruct\ngradient_ai/llama3.3-70b-instruct\ngradient_ai/mistral-nemo-instruct-2407\ngradient_ai/openai-gpt-4o\ngradient_ai/openai-gpt-4o-mini\ngradient_ai/openai-o3\ngradient_ai/openai-o3-mini\ngroq/deepseek-r1-distill-llama-70b\ngroq/distil-whisper-large-v3-en\ngroq/gemma-7b-it\ngroq/gemma2-9b-it\ngroq/llama-3.1-405b-reasoning\ngroq/llama-3.1-70b-versatile\ngroq/llama-3.1-8b-instant\ngroq/llama-3.2-11b-text-preview\ngroq/llama-3.2-11b-vision-preview\ngroq/llama-3.2-1b-preview\ngroq/llama-3.2-3b-preview\ngroq/llama-3.2-90b-text-preview\ngroq/llama-3.2-90b-vision-preview\ngroq/llama-3.3-70b-specdec\ngroq/llama-3.3-70b-versatile\ngroq/llama-guard-3-8b\ngroq/llama2-70b-4096\ngroq/llama3-70b-8192\ngroq/llama3-8b-8192\ngroq/llama3-groq-70b-8192-tool-use-preview\ngroq/llama3-groq-8b-8192-tool-use-preview\ngroq/meta-llama/llama-4-maverick-17b-128e-instruct\ngroq/meta-llama/llama-4-scout-17b-16e-instruct\ngroq/mistral-saba-24b\ngroq/mixtral-8x7b-32768\ngroq/moonshotai/kimi-k2-instruct\ngroq/openai/gpt-oss-120b\ngroq/openai/gpt-oss-20b\ngroq/playai-tts\ngroq/qwen/qwen3-32b\ngroq/whisper-large-v3\ngroq/whisper-large-v3-turbo\nhd/1024-x-1024/dall-e-3\nhd/1024-x-1792/dall-e-3\nhd/1792-x-1024/dall-e-3\nhigh/1024-x-1024/gpt-image-1\nhigh/1024-x-1536/gpt-image-1\nhigh/1536-x-1024/gpt-image-1\nhyperbolic/NousResearch/Hermes-3-Llama-3.1-70B\nhyperbolic/Qwen/QwQ-32B\nhyperbolic/Qwen/Qwen2.5-72B-Instruct\nhyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct\nhyperbolic/Qwen/Qwen3-235B-A22B\nhyperbolic/deepseek-ai/DeepSeek-R1\nhyperbolic/deepseek-ai/DeepSeek-R1-0528\nhyperbolic/deepseek-ai/DeepSeek-V3\nhyperbolic/deepseek-ai/DeepSeek-V3-0324\nhyperbolic/meta-llama/Llama-3.2-3B-Instruct\nhyperbolic/meta-llama/Llama-3.3-70B-Instruct\nhyperbolic/meta-llama/Meta-Llama-3-70B-Instruct\nhyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct\nhyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct\nhyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct\nhyperbolic/moonshotai/Kimi-K2-Instruct\nj2-light\nj2-mid\nj2-ultra\njamba-1.5\njamba-1.5-large\njamba-1.5-large@001\njamba-1.5-mini\njamba-1.5-mini@001\njamba-large-1.6\njamba-large-1.7\njamba-mini-1.6\njamba-mini-1.7\njina-reranker-v2-base-multilingual\nlambda_ai/deepseek-llama3.3-70b\nlambda_ai/deepseek-r1-0528\nlambda_ai/deepseek-r1-671b\nlambda_ai/deepseek-v3-0324\nlambda_ai/hermes3-405b\nlambda_ai/hermes3-70b\nlambda_ai/hermes3-8b\nlambda_ai/lfm-40b\nlambda_ai/lfm-7b\nlambda_ai/llama-4-maverick-17b-128e-instruct-fp8\nlambda_ai/llama-4-scout-17b-16e-instruct\nlambda_ai/llama3.1-405b-instruct-fp8\nlambda_ai/llama3.1-70b-instruct-fp8\nlambda_ai/llama3.1-8b-instruct\nlambda_ai/llama3.1-nemotron-70b-instruct-fp8\nlambda_ai/llama3.2-11b-vision-instruct\nlambda_ai/llama3.2-3b-instruct\nlambda_ai/llama3.3-70b-instruct-fp8\nlambda_ai/qwen25-coder-32b-instruct\nlambda_ai/qwen3-32b-fp8\nlow/1024-x-1024/gpt-image-1\nlow/1024-x-1536/gpt-image-1\nlow/1536-x-1024/gpt-image-1\nluminous-base\nluminous-base-control\nluminous-extended\nluminous-extended-control\nluminous-supreme\nluminous-supreme-control\nmax-x-max/50-steps/stability.stable-diffusion-xl-v0\nmax-x-max/max-steps/stability.stable-diffusion-xl-v0\nmedium/1024-x-1024/gpt-image-1\nmedium/1024-x-1536/gpt-image-1\nmedium/1536-x-1024/gpt-image-1\nmedlm-large\nmedlm-medium\nmeta.llama2-13b-chat-v1\nmeta.llama2-70b-chat-v1\nmeta.llama3-1-405b-instruct-v1:0\nmeta.llama3-1-70b-instruct-v1:0\nmeta.llama3-1-8b-instruct-v1:0\nmeta.llama3-2-11b-instruct-v1:0\nmeta.llama3-2-1b-instruct-v1:0\nmeta.llama3-2-3b-instruct-v1:0\nmeta.llama3-2-90b-instruct-v1:0\nmeta.llama3-3-70b-instruct-v1:0\nmeta.llama3-70b-instruct-v1:0\nmeta.llama3-8b-instruct-v1:0\nmeta.llama4-maverick-17b-instruct-v1:0\nmeta.llama4-scout-17b-instruct-v1:0\nmeta_llama/Llama-3.3-70B-Instruct\nmeta_llama/Llama-3.3-8B-Instruct\nmeta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8\nmeta_llama/Llama-4-Scout-17B-16E-Instruct-FP8\nmistral.mistral-7b-instruct-v0:2\nmistral.mistral-large-2402-v1:0\nmistral.mistral-large-2407-v1:0\nmistral.mistral-small-2402-v1:0\nmistral.mixtral-8x7b-instruct-v0:1\nmistral/codestral-2405\nmistral/codestral-latest\nmistral/codestral-mamba-latest\nmistral/devstral-medium-2507\nmistral/devstral-small-2505\nmistral/devstral-small-2507\nmistral/magistral-medium-2506\nmistral/magistral-medium-latest\nmistral/magistral-small-2506\nmistral/magistral-small-latest\nmistral/mistral-embed\nmistral/mistral-large-2402\nmistral/mistral-large-2407\nmistral/mistral-large-2411\nmistral/mistral-large-latest\nmistral/mistral-medium\nmistral/mistral-medium-2312\nmistral/mistral-medium-2505\nmistral/mistral-medium-latest\nmistral/mistral-small\nmistral/mistral-small-latest\nmistral/mistral-tiny\nmistral/open-codestral-mamba\nmistral/open-mistral-7b\nmistral/open-mistral-nemo\nmistral/open-mistral-nemo-2407\nmistral/open-mixtral-8x22b\nmistral/open-mixtral-8x7b\nmistral/pixtral-12b-2409\nmistral/pixtral-large-2411\nmistral/pixtral-large-latest\nmoonshot/kimi-k2-0711-preview\nmoonshot/kimi-latest\nmoonshot/kimi-latest-128k\nmoonshot/kimi-latest-32k\nmoonshot/kimi-latest-8k\nmoonshot/kimi-thinking-preview\nmoonshot/moonshot-v1-128k\nmoonshot/moonshot-v1-128k-0430\nmoonshot/moonshot-v1-128k-vision-preview\nmoonshot/moonshot-v1-32k\nmoonshot/moonshot-v1-32k-0430\nmoonshot/moonshot-v1-32k-vision-preview\nmoonshot/moonshot-v1-8k\nmoonshot/moonshot-v1-8k-0430\nmoonshot/moonshot-v1-8k-vision-preview\nmoonshot/moonshot-v1-auto\nmorph/morph-v3-fast\nmorph/morph-v3-large\nmultimodalembedding\nmultimodalembedding@001\nnscale/Qwen/QwQ-32B\nnscale/Qwen/Qwen2.5-Coder-32B-Instruct\nnscale/Qwen/Qwen2.5-Coder-3B-Instruct\nnscale/Qwen/Qwen2.5-Coder-7B-Instruct\nnscale/black-forest-labs/FLUX.1-schnell\nnscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nnscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\nnscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\nnscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\nnscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\nnscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\nnscale/meta-llama/Llama-3.1-8B-Instruct\nnscale/meta-llama/Llama-3.3-70B-Instruct\nnscale/meta-llama/Llama-4-Scout-17B-16E-Instruct\nnscale/mistralai/mixtral-8x22b-instruct-v0.1\nnscale/stabilityai/stable-diffusion-xl-base-1.0\no1\no1-2024-12-17\no1-mini\no1-mini-2024-09-12\no1-preview\no1-preview-2024-09-12\no1-pro\no1-pro-2025-03-19\no3\no3-2025-04-16\no3-deep-research\no3-deep-research-2025-06-26\no3-mini\no3-mini-2025-01-31\no3-pro\no3-pro-2025-06-10\no4-mini\no4-mini-2025-04-16\no4-mini-deep-research\no4-mini-deep-research-2025-06-26\noci/meta.llama-3.1-405b-instruct\noci/meta.llama-3.2-90b-vision-instruct\noci/meta.llama-3.3-70b-instruct\noci/meta.llama-4-maverick-17b-128e-instruct-fp8\noci/meta.llama-4-scout-17b-16e-instruct\noci/xai.grok-3\noci/xai.grok-3-fast\noci/xai.grok-3-mini\noci/xai.grok-3-mini-fast\noci/xai.grok-4\nollama/codegeex4\nollama/codegemma\nollama/codellama\nollama/deepseek-coder-v2-base\nollama/deepseek-coder-v2-instruct\nollama/deepseek-coder-v2-lite-base\nollama/deepseek-coder-v2-lite-instruct\nollama/internlm2_5-20b-chat\nollama/llama2\nollama/llama2-uncensored\nollama/llama2:13b\nollama/llama2:70b\nollama/llama2:7b\nollama/llama3\nollama/llama3.1\nollama/llama3:70b\nollama/llama3:8b\nollama/mistral\nollama/mistral-7B-Instruct-v0.1\nollama/mistral-7B-Instruct-v0.2\nollama/mistral-large-instruct-2407\nollama/mixtral-8x22B-Instruct-v0.1\nollama/mixtral-8x7B-Instruct-v0.1\nollama/orca-mini\nollama/vicuna\nomni-moderation-2024-09-26\nomni-moderation-latest\nomni-moderation-latest-intents\nopenai.gpt-oss-120b-1:0\nopenai.gpt-oss-20b-1:0\nopenrouter/anthropic/claude-2\nopenrouter/anthropic/claude-3-5-haiku\nopenrouter/anthropic/claude-3-5-haiku-20241022\nopenrouter/anthropic/claude-3-haiku\nopenrouter/anthropic/claude-3-haiku-20240307\nopenrouter/anthropic/claude-3-opus\nopenrouter/anthropic/claude-3-sonnet\nopenrouter/anthropic/claude-3.5-sonnet\nopenrouter/anthropic/claude-3.5-sonnet:beta\nopenrouter/anthropic/claude-3.7-sonnet\nopenrouter/anthropic/claude-3.7-sonnet:beta\nopenrouter/anthropic/claude-instant-v1\nopenrouter/anthropic/claude-opus-4\nopenrouter/anthropic/claude-opus-4.1\nopenrouter/anthropic/claude-sonnet-4\nopenrouter/bytedance/ui-tars-1.5-7b\nopenrouter/cognitivecomputations/dolphin-mixtral-8x7b\nopenrouter/cohere/command-r-plus\nopenrouter/databricks/dbrx-instruct\nopenrouter/deepseek/deepseek-chat\nopenrouter/deepseek/deepseek-chat-v3-0324\nopenrouter/deepseek/deepseek-chat-v3.1\nopenrouter/deepseek/deepseek-coder\nopenrouter/deepseek/deepseek-r1\nopenrouter/deepseek/deepseek-r1-0528\nopenrouter/fireworks/firellava-13b\nopenrouter/google/gemini-2.0-flash-001\nopenrouter/google/gemini-2.5-flash\nopenrouter/google/gemini-2.5-pro\nopenrouter/google/gemini-pro-1.5\nopenrouter/google/gemini-pro-vision\nopenrouter/google/palm-2-chat-bison\nopenrouter/google/palm-2-codechat-bison\nopenrouter/gryphe/mythomax-l2-13b\nopenrouter/jondurbin/airoboros-l2-70b-2.1\nopenrouter/mancer/weaver\nopenrouter/meta-llama/codellama-34b-instruct\nopenrouter/meta-llama/llama-2-13b-chat\nopenrouter/meta-llama/llama-2-70b-chat\nopenrouter/meta-llama/llama-3-70b-instruct\nopenrouter/meta-llama/llama-3-70b-instruct:nitro\nopenrouter/meta-llama/llama-3-8b-instruct:extended\nopenrouter/meta-llama/llama-3-8b-instruct:free\nopenrouter/microsoft/wizardlm-2-8x22b:nitro\nopenrouter/mistralai/mistral-7b-instruct\nopenrouter/mistralai/mistral-7b-instruct:free\nopenrouter/mistralai/mistral-large\nopenrouter/mistralai/mistral-small-3.1-24b-instruct\nopenrouter/mistralai/mistral-small-3.2-24b-instruct\nopenrouter/mistralai/mixtral-8x22b-instruct\nopenrouter/nousresearch/nous-hermes-llama2-13b\nopenrouter/openai/gpt-3.5-turbo\nopenrouter/openai/gpt-3.5-turbo-16k\nopenrouter/openai/gpt-4\nopenrouter/openai/gpt-4-vision-preview\nopenrouter/openai/gpt-4o\nopenrouter/openai/gpt-4o-2024-05-13\nopenrouter/openai/gpt-5-chat\nopenrouter/openai/gpt-5-mini\nopenrouter/openai/gpt-5-nano\nopenrouter/openai/gpt-oss-120b\nopenrouter/openai/gpt-oss-20b\nopenrouter/openai/o1\nopenrouter/openai/o1-mini\nopenrouter/openai/o1-mini-2024-09-12\nopenrouter/openai/o1-preview\nopenrouter/openai/o1-preview-2024-09-12\nopenrouter/openai/o3-mini\nopenrouter/openai/o3-mini-high\nopenrouter/pygmalionai/mythalion-13b\nopenrouter/qwen/qwen-2.5-coder-32b-instruct\nopenrouter/qwen/qwen-vl-plus\nopenrouter/qwen/qwen3-coder\nopenrouter/switchpoint/router\nopenrouter/undi95/remm-slerp-l2-13b\nopenrouter/x-ai/grok-4\npalm/chat-bison\npalm/chat-bison-001\npalm/text-bison\npalm/text-bison-001\npalm/text-bison-safety-off\npalm/text-bison-safety-recitation-off\nperplexity/codellama-34b-instruct\nperplexity/codellama-70b-instruct\nperplexity/llama-2-70b-chat\nperplexity/llama-3.1-70b-instruct\nperplexity/llama-3.1-8b-instruct\nperplexity/llama-3.1-sonar-huge-128k-online\nperplexity/llama-3.1-sonar-large-128k-chat\nperplexity/llama-3.1-sonar-large-128k-online\nperplexity/llama-3.1-sonar-small-128k-chat\nperplexity/llama-3.1-sonar-small-128k-online\nperplexity/mistral-7b-instruct\nperplexity/mixtral-8x7b-instruct\nperplexity/pplx-70b-chat\nperplexity/pplx-70b-online\nperplexity/pplx-7b-chat\nperplexity/pplx-7b-online\nperplexity/sonar\nperplexity/sonar-deep-research\nperplexity/sonar-medium-chat\nperplexity/sonar-medium-online\nperplexity/sonar-pro\nperplexity/sonar-reasoning\nperplexity/sonar-reasoning-pro\nperplexity/sonar-small-chat\nperplexity/sonar-small-online\nrecraft/recraftv2\nrecraft/recraftv3\nreplicate/meta/llama-2-13b\nreplicate/meta/llama-2-13b-chat\nreplicate/meta/llama-2-70b\nreplicate/meta/llama-2-70b-chat\nreplicate/meta/llama-2-7b\nreplicate/meta/llama-2-7b-chat\nreplicate/meta/llama-3-70b\nreplicate/meta/llama-3-70b-instruct\nreplicate/meta/llama-3-8b\nreplicate/meta/llama-3-8b-instruct\nreplicate/mistralai/mistral-7b-instruct-v0.2\nreplicate/mistralai/mistral-7b-v0.1\nreplicate/mistralai/mixtral-8x7b-instruct-v0.1\nrerank-english-v2.0\nrerank-english-v3.0\nrerank-multilingual-v2.0\nrerank-multilingual-v3.0\nrerank-v3.5\nsagemaker/meta-textgeneration-llama-2-13b\nsagemaker/meta-textgeneration-llama-2-13b-f\nsagemaker/meta-textgeneration-llama-2-70b\nsagemaker/meta-textgeneration-llama-2-70b-b-f\nsagemaker/meta-textgeneration-llama-2-7b\nsagemaker/meta-textgeneration-llama-2-7b-f\nsambanova/DeepSeek-R1\nsambanova/DeepSeek-R1-Distill-Llama-70B\nsambanova/DeepSeek-V3-0324\nsambanova/Llama-4-Maverick-17B-128E-Instruct\nsambanova/Llama-4-Scout-17B-16E-Instruct\nsambanova/Meta-Llama-3.1-405B-Instruct\nsambanova/Meta-Llama-3.1-8B-Instruct\nsambanova/Meta-Llama-3.2-1B-Instruct\nsambanova/Meta-Llama-3.2-3B-Instruct\nsambanova/Meta-Llama-3.3-70B-Instruct\nsambanova/Meta-Llama-Guard-3-8B\nsambanova/QwQ-32B\nsambanova/Qwen2-Audio-7B-Instruct\nsambanova/Qwen3-32B\nsample_spec\nsnowflake/claude-3-5-sonnet\nsnowflake/deepseek-r1\nsnowflake/gemma-7b\nsnowflake/jamba-1.5-large\nsnowflake/jamba-1.5-mini\nsnowflake/jamba-instruct\nsnowflake/llama2-70b-chat\nsnowflake/llama3-70b\nsnowflake/llama3-8b\nsnowflake/llama3.1-405b\nsnowflake/llama3.1-70b\nsnowflake/llama3.1-8b\nsnowflake/llama3.2-1b\nsnowflake/llama3.2-3b\nsnowflake/llama3.3-70b\nsnowflake/mistral-7b\nsnowflake/mistral-large\nsnowflake/mistral-large2\nsnowflake/mixtral-8x7b\nsnowflake/reka-core\nsnowflake/reka-flash\nsnowflake/snowflake-arctic\nsnowflake/snowflake-llama-3.1-405b\nsnowflake/snowflake-llama-3.3-70b\nstability.sd3-5-large-v1:0\nstability.sd3-large-v1:0\nstability.stable-image-core-v1:0\nstability.stable-image-core-v1:1\nstability.stable-image-ultra-v1:0\nstability.stable-image-ultra-v1:1\nstandard/1024-x-1024/dall-e-3\nstandard/1024-x-1792/dall-e-3\nstandard/1792-x-1024/dall-e-3\ntext-bison\ntext-bison32k\ntext-bison32k@002\ntext-bison@001\ntext-bison@002\ntext-completion-codestral/codestral-2405\ntext-completion-codestral/codestral-latest\ntext-embedding-004\ntext-embedding-005\ntext-embedding-3-large\ntext-embedding-3-small\ntext-embedding-ada-002\ntext-embedding-ada-002-v2\ntext-embedding-large-exp-03-07\ntext-embedding-preview-0409\ntext-moderation-007\ntext-moderation-latest\ntext-moderation-stable\ntext-multilingual-embedding-002\ntext-multilingual-embedding-preview-0409\ntext-unicorn\ntext-unicorn@001\ntextembedding-gecko\ntextembedding-gecko-multilingual\ntextembedding-gecko-multilingual@001\ntextembedding-gecko@001\ntextembedding-gecko@003\ntogether-ai-21.1b-41b\ntogether-ai-4.1b-8b\ntogether-ai-41.1b-80b\ntogether-ai-8.1b-21b\ntogether-ai-81.1b-110b\ntogether-ai-embedding-151m-to-350m\ntogether-ai-embedding-up-to-150m\ntogether-ai-up-to-4b\ntogether_ai/OpenAI/gpt-oss-20B\ntogether_ai/Qwen/Qwen2.5-72B-Instruct-Turbo\ntogether_ai/Qwen/Qwen2.5-7B-Instruct-Turbo\ntogether_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput\ntogether_ai/Qwen/Qwen3-235B-A22B-Thinking-2507\ntogether_ai/Qwen/Qwen3-235B-A22B-fp8-tput\ntogether_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8\ntogether_ai/deepseek-ai/DeepSeek-R1\ntogether_ai/deepseek-ai/DeepSeek-R1-0528-tput\ntogether_ai/deepseek-ai/DeepSeek-V3\ntogether_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo\ntogether_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\ntogether_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\ntogether_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\ntogether_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\ntogether_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\ntogether_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\ntogether_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\ntogether_ai/mistralai/Mistral-7B-Instruct-v0.1\ntogether_ai/mistralai/Mistral-Small-24B-Instruct-2501\ntogether_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\ntogether_ai/moonshotai/Kimi-K2-Instruct\ntogether_ai/openai/gpt-oss-120b\ntogether_ai/togethercomputer/CodeLlama-34b-Instruct\ntogether_ai/zai-org/GLM-4.5-Air-FP8\ntts-1\ntts-1-hd\nus.amazon.nova-lite-v1:0\nus.amazon.nova-micro-v1:0\nus.amazon.nova-premier-v1:0\nus.amazon.nova-pro-v1:0\nus.anthropic.claude-3-5-haiku-20241022-v1:0\nus.anthropic.claude-3-5-sonnet-20240620-v1:0\nus.anthropic.claude-3-5-sonnet-20241022-v2:0\nus.anthropic.claude-3-7-sonnet-20250219-v1:0\nus.anthropic.claude-3-haiku-20240307-v1:0\nus.anthropic.claude-3-opus-20240229-v1:0\nus.anthropic.claude-3-sonnet-20240229-v1:0\nus.anthropic.claude-opus-4-1-20250805-v1:0\nus.anthropic.claude-opus-4-20250514-v1:0\nus.anthropic.claude-sonnet-4-20250514-v1:0\nus.anthropic.claude-sonnet-4-5-20250929-v1:0\nus.deepseek.r1-v1:0\nus.meta.llama3-1-405b-instruct-v1:0\nus.meta.llama3-1-70b-instruct-v1:0\nus.meta.llama3-1-8b-instruct-v1:0\nus.meta.llama3-2-11b-instruct-v1:0\nus.meta.llama3-2-1b-instruct-v1:0\nus.meta.llama3-2-3b-instruct-v1:0\nus.meta.llama3-2-90b-instruct-v1:0\nus.meta.llama3-3-70b-instruct-v1:0\nus.meta.llama4-maverick-17b-instruct-v1:0\nus.meta.llama4-scout-17b-instruct-v1:0\nus.mistral.pixtral-large-2502-v1:0\nv0/v0-1.0-md\nv0/v0-1.5-lg\nv0/v0-1.5-md\nvertex_ai/claude-3-5-haiku\nvertex_ai/claude-3-5-haiku@20241022\nvertex_ai/claude-3-5-sonnet\nvertex_ai/claude-3-5-sonnet-v2\nvertex_ai/claude-3-5-sonnet-v2@20241022\nvertex_ai/claude-3-5-sonnet@20240620\nvertex_ai/claude-3-7-sonnet@20250219\nvertex_ai/claude-3-haiku\nvertex_ai/claude-3-haiku@20240307\nvertex_ai/claude-3-opus\nvertex_ai/claude-3-opus@20240229\nvertex_ai/claude-3-sonnet\nvertex_ai/claude-3-sonnet@20240229\nvertex_ai/claude-opus-4\nvertex_ai/claude-opus-4-1\nvertex_ai/claude-opus-4-1@20250805\nvertex_ai/claude-opus-4@20250514\nvertex_ai/claude-sonnet-4\nvertex_ai/claude-sonnet-4@20250514\nvertex_ai/codestral-2501\nvertex_ai/codestral@2405\nvertex_ai/codestral@latest\nvertex_ai/deepseek-ai/deepseek-r1-0528-maas\nvertex_ai/imagegeneration@006\nvertex_ai/imagen-3.0-fast-generate-001\nvertex_ai/imagen-3.0-generate-001\nvertex_ai/imagen-3.0-generate-002\nvertex_ai/imagen-4.0-fast-generate-001\nvertex_ai/imagen-4.0-generate-001\nvertex_ai/imagen-4.0-ultra-generate-001\nvertex_ai/jamba-1.5\nvertex_ai/jamba-1.5-large\nvertex_ai/jamba-1.5-large@001\nvertex_ai/jamba-1.5-mini\nvertex_ai/jamba-1.5-mini@001\nvertex_ai/meta/llama-3.1-405b-instruct-maas\nvertex_ai/meta/llama-3.1-70b-instruct-maas\nvertex_ai/meta/llama-3.1-8b-instruct-maas\nvertex_ai/meta/llama-3.2-90b-vision-instruct-maas\nvertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas\nvertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas\nvertex_ai/meta/llama-4-scout-17b-128e-instruct-maas\nvertex_ai/meta/llama-4-scout-17b-16e-instruct-maas\nvertex_ai/meta/llama3-405b-instruct-maas\nvertex_ai/meta/llama3-70b-instruct-maas\nvertex_ai/meta/llama3-8b-instruct-maas\nvertex_ai/mistral-large-2411\nvertex_ai/mistral-large@2407\nvertex_ai/mistral-large@2411-001\nvertex_ai/mistral-large@latest\nvertex_ai/mistral-nemo@2407\nvertex_ai/mistral-nemo@latest\nvertex_ai/mistral-small-2503\nvertex_ai/mistral-small-2503@001\nvertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas\nvertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas\nvoyage/rerank-2\nvoyage/rerank-2-lite\nvoyage/voyage-2\nvoyage/voyage-3\nvoyage/voyage-3-large\nvoyage/voyage-3-lite\nvoyage/voyage-code-2\nvoyage/voyage-code-3\nvoyage/voyage-context-3\nvoyage/voyage-finance-2\nvoyage/voyage-large-2\nvoyage/voyage-law-2\nvoyage/voyage-lite-01\nvoyage/voyage-lite-02-instruct\nvoyage/voyage-multimodal-3\nwatsonx/ibm/granite-3-8b-instruct\nwatsonx/mistralai/mistral-large\nwhisper-1\nxai/grok-2\nxai/grok-2-1212\nxai/grok-2-latest\nxai/grok-2-vision\nxai/grok-2-vision-1212\nxai/grok-2-vision-latest\nxai/grok-3\nxai/grok-3-beta\nxai/grok-3-fast-beta\nxai/grok-3-fast-latest\nxai/grok-3-latest\nxai/grok-3-mini\nxai/grok-3-mini-beta\nxai/grok-3-mini-fast\nxai/grok-3-mini-fast-beta\nxai/grok-3-mini-fast-latest\nxai/grok-3-mini-latest\nxai/grok-4\nxai/grok-4-0709\nxai/grok-4-latest\nxai/grok-beta\nxai/grok-code-fast\nxai/grok-code-fast-1\nxai/grok-code-fast-1-0825\nxai/grok-vision-beta\n</code></pre> <p>To find the corresponding API key, check the previous section.</p>"},{"location":"models/quickstart/#extra-model-settings","title":"Extra model settings","text":"<p>To configure reasoning efforts or similar settings, you need to edit the agent config file. In newer versions, the location of the config file is printed when you run <code>mini</code> (\"agent config\" in the output).</p> <p>Here's a few general examples:</p> TemperatureGPT-5 reasoning effort (Chat Completions API)GPT-5 with Responses APIOpenRouterLocal models <p><code>litellm</code> allows to set model-specific settings with the <code>model_kwargs</code> key:</p> <pre><code>model:\n  model_name: \"anthropic/claude-sonnet-4-5-20250929\"\n    model_kwargs:\n      temperature: 0.0\n</code></pre> <p>Note that temperature isn't supported by all models.</p> <p><code>litellm</code> allows to set model-specific settings with the <code>model_kwargs</code> key:</p> <pre><code>model:\n  model_name: \"openai/gpt-5-mini\"\n  model_kwargs:\n    drop_params: true\n    reasoning_effort: \"high\"\n    verbosity: \"medium\"\n</code></pre> <p>Here, <code>drop_params</code> is used to drop any parameters that are not supported by the model.</p> <p>For OpenAI models that support the Responses API, you can use the <code>litellm_response_toolcall</code> model class:</p> <pre><code>model:\n  model_class: \"litellm_response_toolcall\"\n  model_name: \"openai/gpt-5-mini\"\n  model_kwargs:\n    drop_params: true\n    reasoning:\n      effort: \"high\"\n</code></pre> <p>This example explicitly sets the model class to <code>openrouter</code> (see the next section for more details). It also explicitly sets the providers to disable switching between them (this is useful if you need very consistent cost behavior, e.g., for benchmarking, but it's not recommended if you're just interested in getting low latency and good prices).</p> <pre><code>model:\n    model_name: \"moonshotai/kimi-k2-0905\"\n    model_class: \"openrouter\"\n    model_kwargs:\n        temperature: 0.0\n        provider:\n          allow_fallbacks: false\n          only: [\"Moonshot AI\"]\n</code></pre> <p>Using <code>litellm</code> with local models:</p> <pre><code>model:\n  model_name: \"my-local-model\"\n  model_kwargs:\n    custom_llm_provider: \"openai\"\n    api_base: \"https://...\"\n    ...\n</code></pre> <p>See this guide for more details on local models. In particular, you need to configure token costs for local models.</p> <p>Here are more examples of how to configure specific models:</p> Gemini 3 (Openrouter)GPT 5.1 medium (Portkey)Claude Haiku 4.5GPT 5 mini (Portkey)DeepseekMinimax (Openrouter) <pre><code>model:\n    model_name: \"google/gemini-3-pro-preview\"\n    model_class: openrouter\n    model_kwargs:\n        temperature: 0.0\n</code></pre> <pre><code>model:\n    model_name: \"@openai/gpt-5.1\"\n    model_class: portkey\n    model_kwargs:\n        reasoning_effort: \"medium\"\n        verbosity: \"medium\"\n</code></pre> <pre><code>model:\n    model_name: \"anthropic/claude-haiku-4-5-20251001\"\n    model_kwargs:\n        temperature: 0.0\n</code></pre> <pre><code>model:\n    model_name: \"@openai/gpt-5-mini\"\n    model_class: portkey\n</code></pre> <pre><code>model:\n    model_name: \"deepseek/deepseek-reasoner\"\n    model_kwargs:\n        temperature: 0.0\n</code></pre> <pre><code>model:\n    model_name: \"minimax/minimax-m2\"\n    model_class: openrouter\n    model_kwargs:\n        temperature: 0.0\n</code></pre>"},{"location":"models/quickstart/#model-classes","title":"Model classes","text":"<p>We support the various models through different backends. By default (if you only specify the model name), we pick the best backend for you. This will almost always default to <code>litellm</code> (with Anthropic models being a special case as they need to have explicit cache breakpoint handling).</p> <p>However, there are a few other backends that you can use and specify with the <code>--model-class</code> flag or the <code>model.model_class</code> key in the agent config file (see previous section).</p> <p>For example:</p> Openrouter modelPortkey model <pre><code>mini -m \"moonshotai/kimi-k2-0905\" --model-class openrouter\n</code></pre> <p>Alternatively: In the agent config file:</p> <pre><code>model:\n    model_name: \"moonshotai/kimi-k2-0905\"\n    model_class: openrouter\n</code></pre> <pre><code>mini -m \"claude-sonnet-4-5-20250929\" --model-class portkey\n</code></pre> <p>Alternatively: In the agent config file: </p><pre><code>model:\n    model_name: \"claude-sonnet-4-5-20250929\"\n    model_class: portkey\n</code></pre><p></p> <ul> <li> <p><code>litellm</code> (<code>LitellmModel</code>) - Default and recommended. Supports most models through litellm. Works with OpenAI, Anthropic, Google, and many other providers. Anthropic models automatically get cache control settings when the model name contains \"anthropic\", \"claude\", \"sonnet\", or \"opus\".</p> </li> <li> <p><code>litellm_response</code> (<code>LitellmResponseModel</code>) - Specialized version of <code>LitellmModel</code> that uses OpenAI's Responses API with native tool calling. Useful for models like GPT-5 and required for models like GPT-5-codex. Maintains conversation state across turns.</p> </li> <li> <p><code>openrouter</code> (<code>OpenRouterModel</code>) - Direct integration with OpenRouter API for accessing various models through a single endpoint.</p> </li> <li> <p><code>portkey</code> (<code>PortkeyModel</code>) - Integration with Portkey for accessing various models with enhanced observability, caching, and routing features. Note that this still uses <code>litellm</code> to calculate costs.</p> </li> </ul> <p>On top, there's a few more exotic model classes that you can use:</p> <ul> <li><code>deterministic</code> (<code>DeterministicModel</code>) - Returns predefined responses for testing and development purposes.</li> <li><code>minisweagent.models.extra.roulette.RouletteModel</code> and <code>minisweagent.models.extra.roulette.InterleavingModel</code> (<code>RouletteModel</code> and <code>InterleavingModel</code>) - Randomly selects or interleaves multiple configured models for each query. See this blog post for more details.</li> </ul> <p>As with the last two, you can also specify any import path to your own custom model class (even if it is not yet part of the mini-SWE-agent package).</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"models/troubleshooting/","title":"Troubleshooting","text":""},{"location":"models/troubleshooting/#model-trouble-shooting","title":"Model trouble shooting","text":"<p>This section has examples of common error messages and how to fix them.</p>"},{"location":"models/troubleshooting/#litellm","title":"Litellm","text":"<p><code>litellm</code> is the default model class and is used to support most models.</p>"},{"location":"models/troubleshooting/#invalid-api-key","title":"Invalid API key","text":"<pre><code>AuthenticationError: litellm.AuthenticationError: geminiException - {\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"API key not valid. Please pass a valid API key.\",\n    \"status\": \"INVALID_ARGUMENT\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n        \"reason\": \"API_KEY_INVALID\",\n        \"domain\": \"googleapis.com\",\n        \"metadata\": {\n          \"service\": \"generativelanguage.googleapis.com\"\n        }\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.LocalizedMessage\",\n        \"locale\": \"en-US\",\n        \"message\": \"API key not valid. Please pass a valid API key.\"\n      }\n    ]\n  }\n}\n You can permanently set your API key with `mini-extra config set KEY VALUE`.\n</code></pre> <p>Double check your API key and make sure it is correct. You can take a look at all your API keys with <code>mini-extra config edit</code>.</p>"},{"location":"models/troubleshooting/#weird-authentication-error","title":"\"Weird\" authentication error","text":"<p>If you fail to authenticate but don't see the previous error message, it might be that you forgot to include the provider in the model name.</p> <p>For example, this:</p> <pre><code>  File \"/Users/.../.virtualenvs/openai/lib/python3.12/site-packages/google/auth/_default.py\", line 685, in default\n    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\ngoogle.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see\nhttps://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n</code></pre> <p>happens if you forgot to prefix your gemini model with <code>gemini/</code>.</p>"},{"location":"models/troubleshooting/#error-during-cost-calculation","title":"Error during cost calculation","text":"<pre><code>Exception: This model isn't mapped yet. model=together_ai/qwen/qwen3-coder-480b-a35b-instruct-fp8, custom_llm_provider=together_ai.\nAdd it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n</code></pre> <p><code>litellm</code> doesn't know about the cost of your model. Take a look at the model registry section of the local models guide to add it.</p> <p>Another common mistake is to not include any or the correct provider in the model name (e.g., <code>gemini-2.0-flash</code> instead of <code>gemini/gemini-2.0-flash</code>).</p>"},{"location":"models/troubleshooting/#temperature-not-supported","title":"Temperature not supported","text":"<p>Some models (like <code>o1</code>, <code>o3</code>, <code>GPT-5</code> etc.) do not support temperature. The default config no longer specifies a temperature value, so this should work out of the box now.</p>"},{"location":"models/troubleshooting/#portkey","title":"Portkey","text":""},{"location":"models/troubleshooting/#error-during-cost-calculation_1","title":"Error during cost calculation","text":"<p>We use <code>litellm</code> to calculate costs for Portkey models because Portkey doesn't seem to provide per-request cost information without very inconvenient APIs.</p> <p>This can lead to errors likethis:</p> <pre><code>  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/minisweagent/models/portkey_model.py\", line 85, in query\n    cost = litellm.cost_calculator.completion_cost(response)\n  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/litellm/cost_calculator.py\", line 973, in completion_cost\n    raise e\n  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/litellm/cost_calculator.py\", line 966, in completion_cost\n    raise e\n  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/litellm/cost_calculator.py\", line 928, in completion_cost\n    ) = cost_per_token(\n  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/litellm/cost_calculator.py\", line 218, in cost_per_token\n    _, custom_llm_provider, _, _ = litellm.get_llm_provider(model=model)\n  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py\", line 395, in get_llm_provider\n    raise e\n  File \"/opt/miniconda3/envs/clash/lib/python3.10/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py\", line 372, in get_llm_provider\n    raise litellm.exceptions.BadRequestError(  # type: ignore\nlitellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=grok-code-fast-1\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n</code></pre> <p>In this case, the issue is simply that the portkey model name doesn't match the litellm model name (and very specifically here doesn't include the provider).</p> <p>To fix this, you can manually set the litellm model name to the portkey model name with the <code>litellm_model_name_override</code> key. For example:</p> <pre><code>model:\n  model_name: \"grok-code-fast-1\"  # the portkey model name\n  model_class: \"portkey\"  # make sure to use the portkey model class\n  litellm_model_name_override: \"xai/grok-code-fast-1\"  # the litellm model name for cost information\n  ...\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#api-reference","title":"API Reference","text":"<p>This section provides detailed documentation for all classes and modules in mini-SWE-agent.</p> <p>Understanding the agent</p> <p>Before diving into the API reference, we recommend reading the control flow documentation to understand how the agent works.</p>"},{"location":"reference/#sections","title":"Sections","text":"<ul> <li>Agents - Agent implementations and control flow</li> <li>Models - Language model interfaces</li> <li>Environments - Command execution environments</li> <li>Run Scripts - Entry points and CLI interfaces</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/agents/default/","title":"DefaultAgent","text":""},{"location":"reference/agents/default/#defaultagent","title":"DefaultAgent","text":"<p>DefaultAgent class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>\"\"\"Basic agent class. See https://mini-swe-agent.com/latest/advanced/control_flow/ for visual explanation\nor https://minimal-agent.com for a tutorial on the basic building principles.\n\"\"\"\n\nimport json\nimport logging\nimport traceback\nfrom pathlib import Path\n\nfrom jinja2 import StrictUndefined, Template\nfrom pydantic import BaseModel\n\nfrom minisweagent import Environment, Model, __version__\nfrom minisweagent.exceptions import InterruptAgentFlow, LimitsExceeded\nfrom minisweagent.utils.serialize import recursive_merge\n\n\nclass AgentConfig(BaseModel):\n    \"\"\"Check the config files in minisweagent/config for example settings.\"\"\"\n\n    system_template: str\n    \"\"\"Template for the system message (the first message).\"\"\"\n    instance_template: str\n    \"\"\"Template for the first user message specifying the task (the second message overall).\"\"\"\n    step_limit: int = 0\n    \"\"\"Maximum number of steps the agent can take.\"\"\"\n    cost_limit: float = 3.0\n    \"\"\"Stop agent after exceeding (!) this cost.\"\"\"\n    output_path: Path | None = None\n    \"\"\"Save the trajectory to this path.\"\"\"\n\n\nclass DefaultAgent:\n    def __init__(self, model: Model, env: Environment, *, config_class: type = AgentConfig, **kwargs):\n        \"\"\"See the `AgentConfig` class for permitted keyword arguments.\"\"\"\n        self.config = config_class(**kwargs)\n        self.messages: list[dict] = []\n        self.model = model\n        self.env = env\n        self.extra_template_vars = {}\n        self.logger = logging.getLogger(\"agent\")\n        self.cost = 0.0\n        self.n_calls = 0\n\n    def get_template_vars(self, **kwargs) -&gt; dict:\n        return recursive_merge(\n            self.config.model_dump(),\n            self.env.get_template_vars(),\n            self.model.get_template_vars(),\n            {\"n_model_calls\": self.n_calls, \"model_cost\": self.cost},\n            self.extra_template_vars,\n            kwargs,\n        )\n\n    def _render_template(self, template: str) -&gt; str:\n        return Template(template, undefined=StrictUndefined).render(**self.get_template_vars())\n\n    def add_messages(self, *messages: dict) -&gt; list[dict]:\n        self.logger.debug(messages)  # set log level to debug to see\n        self.messages.extend(messages)\n        return list(messages)\n\n    def handle_uncaught_exception(self, e: Exception) -&gt; list[dict]:\n        return self.add_messages(\n            self.model.format_message(\n                role=\"exit\",\n                content=str(e),\n                extra={\n                    \"exit_status\": type(e).__name__,\n                    \"submission\": \"\",\n                    \"exception_str\": str(e),\n                    \"traceback\": traceback.format_exc(),\n                },\n            )\n        )\n\n    def run(self, task: str = \"\", **kwargs) -&gt; dict:\n        \"\"\"Run step() until agent is finished. Returns dictionary with exit_status, submission keys.\"\"\"\n        self.extra_template_vars |= {\"task\": task, **kwargs}\n        self.messages = []\n        self.add_messages(\n            self.model.format_message(role=\"system\", content=self._render_template(self.config.system_template)),\n            self.model.format_message(role=\"user\", content=self._render_template(self.config.instance_template)),\n        )\n        while True:\n            try:\n                self.step()\n            except InterruptAgentFlow as e:\n                self.add_messages(*e.messages)\n            except Exception as e:\n                self.handle_uncaught_exception(e)\n                raise\n            finally:\n                self.save(self.config.output_path)\n            if self.messages[-1].get(\"role\") == \"exit\":\n                break\n        return self.messages[-1].get(\"extra\", {})\n\n    def step(self) -&gt; list[dict]:\n        \"\"\"Query the LM, execute actions.\"\"\"\n        return self.execute_actions(self.query())\n\n    def query(self) -&gt; dict:\n        \"\"\"Query the model and return model messages. Override to add hooks.\"\"\"\n        if 0 &lt; self.config.step_limit &lt;= self.n_calls or 0 &lt; self.config.cost_limit &lt;= self.cost:\n            raise LimitsExceeded(\n                {\n                    \"role\": \"exit\",\n                    \"content\": \"LimitsExceeded\",\n                    \"extra\": {\"exit_status\": \"LimitsExceeded\", \"submission\": \"\"},\n                }\n            )\n        self.n_calls += 1\n        message = self.model.query(self.messages)\n        self.cost += message.get(\"extra\", {}).get(\"cost\", 0.0)\n        self.add_messages(message)\n        return message\n\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        \"\"\"Execute actions in message, add observation messages, return them.\"\"\"\n        outputs = [self.env.execute(action) for action in message.get(\"extra\", {}).get(\"actions\", [])]\n        return self.add_messages(*self.model.format_observation_messages(message, outputs, self.get_template_vars()))\n\n    def serialize(self, *extra_dicts) -&gt; dict:\n        \"\"\"Serialize agent state to a json-compatible nested dictionary for saving.\"\"\"\n        last_message = self.messages[-1] if self.messages else {}\n        last_extra = last_message.get(\"extra\", {})\n        agent_data = {\n            \"info\": {\n                \"model_stats\": {\n                    \"instance_cost\": self.cost,\n                    \"api_calls\": self.n_calls,\n                },\n                \"config\": {\n                    \"agent\": self.config.model_dump(mode=\"json\"),\n                    \"agent_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n                \"mini_version\": __version__,\n                \"exit_status\": last_extra.get(\"exit_status\", \"\"),\n                \"submission\": last_extra.get(\"submission\", \"\"),\n            },\n            \"messages\": self.messages,\n            \"trajectory_format\": \"mini-swe-agent-1.1\",\n        }\n        return recursive_merge(agent_data, self.model.serialize(), self.env.serialize(), *extra_dicts)\n\n    def save(self, path: Path | None, *extra_dicts) -&gt; dict:\n        \"\"\"Save the trajectory of the agent to a file if path is given. Returns full serialized data.\n        You can pass additional dictionaries with extra data to be (recursively) merged into the output data.\n        \"\"\"\n        data = self.serialize(*extra_dicts)\n        if path:\n            path.parent.mkdir(parents=True, exist_ok=True)\n            path.write_text(json.dumps(data, indent=2))\n        return data\n</code></pre> <p>Understanding the control flow</p> <p>Check out the control flow guide for a visual explanation of the agent's control flow.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.AgentConfig","title":"minisweagent.agents.default.AgentConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Check the config files in minisweagent/config for example settings.</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.AgentConfig.system_template","title":"system_template  <code>instance-attribute</code>","text":"<pre><code>system_template: str\n</code></pre> <p>Template for the system message (the first message).</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.AgentConfig.instance_template","title":"instance_template  <code>instance-attribute</code>","text":"<pre><code>instance_template: str\n</code></pre> <p>Template for the first user message specifying the task (the second message overall).</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.AgentConfig.step_limit","title":"step_limit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>step_limit: int = 0\n</code></pre> <p>Maximum number of steps the agent can take.</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.AgentConfig.cost_limit","title":"cost_limit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_limit: float = 3.0\n</code></pre> <p>Stop agent after exceeding (!) this cost.</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.AgentConfig.output_path","title":"output_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>output_path: Path | None = None\n</code></pre> <p>Save the trajectory to this path.</p>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent","title":"minisweagent.agents.default.DefaultAgent","text":"<pre><code>DefaultAgent(\n    model: Model,\n    env: Environment,\n    *,\n    config_class: type = AgentConfig,\n    **kwargs,\n)\n</code></pre> <p>See the <code>AgentConfig</code> class for permitted keyword arguments.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def __init__(self, model: Model, env: Environment, *, config_class: type = AgentConfig, **kwargs):\n    \"\"\"See the `AgentConfig` class for permitted keyword arguments.\"\"\"\n    self.config = config_class(**kwargs)\n    self.messages: list[dict] = []\n    self.model = model\n    self.env = env\n    self.extra_template_vars = {}\n    self.logger = logging.getLogger(\"agent\")\n    self.cost = 0.0\n    self.n_calls = 0\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.messages","title":"messages  <code>instance-attribute</code>","text":"<pre><code>messages: list[dict] = []\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.env","title":"env  <code>instance-attribute</code>","text":"<pre><code>env = env\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.extra_template_vars","title":"extra_template_vars  <code>instance-attribute</code>","text":"<pre><code>extra_template_vars = {}\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = getLogger('agent')\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.cost","title":"cost  <code>instance-attribute</code>","text":"<pre><code>cost = 0.0\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.n_calls","title":"n_calls  <code>instance-attribute</code>","text":"<pre><code>n_calls = 0\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict:\n    return recursive_merge(\n        self.config.model_dump(),\n        self.env.get_template_vars(),\n        self.model.get_template_vars(),\n        {\"n_model_calls\": self.n_calls, \"model_cost\": self.cost},\n        self.extra_template_vars,\n        kwargs,\n    )\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.add_messages","title":"add_messages","text":"<pre><code>add_messages(*messages: dict) -&gt; list[dict]\n</code></pre> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def add_messages(self, *messages: dict) -&gt; list[dict]:\n    self.logger.debug(messages)  # set log level to debug to see\n    self.messages.extend(messages)\n    return list(messages)\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.handle_uncaught_exception","title":"handle_uncaught_exception","text":"<pre><code>handle_uncaught_exception(e: Exception) -&gt; list[dict]\n</code></pre> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def handle_uncaught_exception(self, e: Exception) -&gt; list[dict]:\n    return self.add_messages(\n        self.model.format_message(\n            role=\"exit\",\n            content=str(e),\n            extra={\n                \"exit_status\": type(e).__name__,\n                \"submission\": \"\",\n                \"exception_str\": str(e),\n                \"traceback\": traceback.format_exc(),\n            },\n        )\n    )\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.run","title":"run","text":"<pre><code>run(task: str = '', **kwargs) -&gt; dict\n</code></pre> <p>Run step() until agent is finished. Returns dictionary with exit_status, submission keys.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def run(self, task: str = \"\", **kwargs) -&gt; dict:\n    \"\"\"Run step() until agent is finished. Returns dictionary with exit_status, submission keys.\"\"\"\n    self.extra_template_vars |= {\"task\": task, **kwargs}\n    self.messages = []\n    self.add_messages(\n        self.model.format_message(role=\"system\", content=self._render_template(self.config.system_template)),\n        self.model.format_message(role=\"user\", content=self._render_template(self.config.instance_template)),\n    )\n    while True:\n        try:\n            self.step()\n        except InterruptAgentFlow as e:\n            self.add_messages(*e.messages)\n        except Exception as e:\n            self.handle_uncaught_exception(e)\n            raise\n        finally:\n            self.save(self.config.output_path)\n        if self.messages[-1].get(\"role\") == \"exit\":\n            break\n    return self.messages[-1].get(\"extra\", {})\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.step","title":"step","text":"<pre><code>step() -&gt; list[dict]\n</code></pre> <p>Query the LM, execute actions.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def step(self) -&gt; list[dict]:\n    \"\"\"Query the LM, execute actions.\"\"\"\n    return self.execute_actions(self.query())\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.query","title":"query","text":"<pre><code>query() -&gt; dict\n</code></pre> <p>Query the model and return model messages. Override to add hooks.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def query(self) -&gt; dict:\n    \"\"\"Query the model and return model messages. Override to add hooks.\"\"\"\n    if 0 &lt; self.config.step_limit &lt;= self.n_calls or 0 &lt; self.config.cost_limit &lt;= self.cost:\n        raise LimitsExceeded(\n            {\n                \"role\": \"exit\",\n                \"content\": \"LimitsExceeded\",\n                \"extra\": {\"exit_status\": \"LimitsExceeded\", \"submission\": \"\"},\n            }\n        )\n    self.n_calls += 1\n    message = self.model.query(self.messages)\n    self.cost += message.get(\"extra\", {}).get(\"cost\", 0.0)\n    self.add_messages(message)\n    return message\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.execute_actions","title":"execute_actions","text":"<pre><code>execute_actions(message: dict) -&gt; list[dict]\n</code></pre> <p>Execute actions in message, add observation messages, return them.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def execute_actions(self, message: dict) -&gt; list[dict]:\n    \"\"\"Execute actions in message, add observation messages, return them.\"\"\"\n    outputs = [self.env.execute(action) for action in message.get(\"extra\", {}).get(\"actions\", [])]\n    return self.add_messages(*self.model.format_observation_messages(message, outputs, self.get_template_vars()))\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.serialize","title":"serialize","text":"<pre><code>serialize(*extra_dicts) -&gt; dict\n</code></pre> <p>Serialize agent state to a json-compatible nested dictionary for saving.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def serialize(self, *extra_dicts) -&gt; dict:\n    \"\"\"Serialize agent state to a json-compatible nested dictionary for saving.\"\"\"\n    last_message = self.messages[-1] if self.messages else {}\n    last_extra = last_message.get(\"extra\", {})\n    agent_data = {\n        \"info\": {\n            \"model_stats\": {\n                \"instance_cost\": self.cost,\n                \"api_calls\": self.n_calls,\n            },\n            \"config\": {\n                \"agent\": self.config.model_dump(mode=\"json\"),\n                \"agent_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n            \"mini_version\": __version__,\n            \"exit_status\": last_extra.get(\"exit_status\", \"\"),\n            \"submission\": last_extra.get(\"submission\", \"\"),\n        },\n        \"messages\": self.messages,\n        \"trajectory_format\": \"mini-swe-agent-1.1\",\n    }\n    return recursive_merge(agent_data, self.model.serialize(), self.env.serialize(), *extra_dicts)\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.agents.default.DefaultAgent.save","title":"save","text":"<pre><code>save(path: Path | None, *extra_dicts) -&gt; dict\n</code></pre> <p>Save the trajectory of the agent to a file if path is given. Returns full serialized data. You can pass additional dictionaries with extra data to be (recursively) merged into the output data.</p> Source code in <code>src/minisweagent/agents/default.py</code> <pre><code>def save(self, path: Path | None, *extra_dicts) -&gt; dict:\n    \"\"\"Save the trajectory of the agent to a file if path is given. Returns full serialized data.\n    You can pass additional dictionaries with extra data to be (recursively) merged into the output data.\n    \"\"\"\n    data = self.serialize(*extra_dicts)\n    if path:\n        path.parent.mkdir(parents=True, exist_ok=True)\n        path.write_text(json.dumps(data, indent=2))\n    return data\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.exceptions.InterruptAgentFlow","title":"minisweagent.exceptions.InterruptAgentFlow","text":"<pre><code>InterruptAgentFlow(*messages: dict)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Raised to interrupt the agent flow and add messages.</p> Source code in <code>src/minisweagent/exceptions.py</code> <pre><code>def __init__(self, *messages: dict):\n    self.messages = messages\n    super().__init__()\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.exceptions.InterruptAgentFlow.messages","title":"messages  <code>instance-attribute</code>","text":"<pre><code>messages = messages\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.exceptions.Submitted","title":"minisweagent.exceptions.Submitted","text":"<pre><code>Submitted(*messages: dict)\n</code></pre> <p>               Bases: <code>InterruptAgentFlow</code></p> <p>Raised when the agent has completed its task.</p> Source code in <code>src/minisweagent/exceptions.py</code> <pre><code>def __init__(self, *messages: dict):\n    self.messages = messages\n    super().__init__()\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.exceptions.LimitsExceeded","title":"minisweagent.exceptions.LimitsExceeded","text":"<pre><code>LimitsExceeded(*messages: dict)\n</code></pre> <p>               Bases: <code>InterruptAgentFlow</code></p> <p>Raised when the agent has exceeded its cost or step limit.</p> Source code in <code>src/minisweagent/exceptions.py</code> <pre><code>def __init__(self, *messages: dict):\n    self.messages = messages\n    super().__init__()\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.exceptions.FormatError","title":"minisweagent.exceptions.FormatError","text":"<pre><code>FormatError(*messages: dict)\n</code></pre> <p>               Bases: <code>InterruptAgentFlow</code></p> <p>Raised when the LM's output is not in the expected format.</p> Source code in <code>src/minisweagent/exceptions.py</code> <pre><code>def __init__(self, *messages: dict):\n    self.messages = messages\n    super().__init__()\n</code></pre>"},{"location":"reference/agents/default/#minisweagent.exceptions.UserInterruption","title":"minisweagent.exceptions.UserInterruption","text":"<pre><code>UserInterruption(*messages: dict)\n</code></pre> <p>               Bases: <code>InterruptAgentFlow</code></p> <p>Raised when the user interrupts the agent.</p> Source code in <code>src/minisweagent/exceptions.py</code> <pre><code>def __init__(self, *messages: dict):\n    self.messages = messages\n    super().__init__()\n</code></pre>"},{"location":"reference/agents/interactive/","title":"InteractiveAgent","text":""},{"location":"reference/agents/interactive/#interactive","title":"Interactive","text":"<p>InteractiveAgent class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>\"\"\"A small generalization of the default agent that puts the user in the loop.\n\nThere are three modes:\n- human: commands issued by the user are executed immediately\n- confirm: commands issued by the LM but not whitelisted are confirmed by the user\n- yolo: commands issued by the LM are executed immediately without confirmation\n\"\"\"\n\nimport re\nfrom typing import Literal, NoReturn\n\nfrom rich.console import Console\nfrom rich.rule import Rule\n\nfrom minisweagent.agents.default import AgentConfig, DefaultAgent\nfrom minisweagent.agents.utils.prompt_user import _multiline_prompt, prompt_session\nfrom minisweagent.exceptions import LimitsExceeded, Submitted, UserInterruption\nfrom minisweagent.models.utils.content_string import get_content_string\n\nconsole = Console(highlight=False)\n\n\nclass InteractiveAgentConfig(AgentConfig):\n    mode: Literal[\"human\", \"confirm\", \"yolo\"] = \"confirm\"\n    \"\"\"Whether to confirm actions.\"\"\"\n    whitelist_actions: list[str] = []\n    \"\"\"Never confirm actions that match these regular expressions.\"\"\"\n    confirm_exit: bool = True\n    \"\"\"If the agent wants to finish, do we ask for confirmation from user?\"\"\"\n\n\nclass InteractiveAgent(DefaultAgent):\n    _MODE_COMMANDS_MAPPING = {\"/u\": \"human\", \"/c\": \"confirm\", \"/y\": \"yolo\"}\n\n    def __init__(self, *args, config_class=InteractiveAgentConfig, **kwargs):\n        super().__init__(*args, config_class=config_class, **kwargs)\n        self.cost_last_confirmed = 0.0\n\n    def _interrupt(self, content: str, *, itype: str = \"UserInterruption\") -&gt; NoReturn:\n        raise UserInterruption({\"role\": \"user\", \"content\": content, \"extra\": {\"interrupt_type\": itype}})\n\n    def add_messages(self, *messages: dict) -&gt; list[dict]:\n        # Extend supermethod to print messages\n        for msg in messages:\n            role, content = msg.get(\"role\") or msg.get(\"type\", \"unknown\"), get_content_string(msg)\n            if role == \"assistant\":\n                console.print(\n                    f\"\\n[red][bold]mini-swe-agent[/bold] (step [bold]{self.n_calls}[/bold], [bold]${self.cost:.2f}[/bold]):[/red]\\n\",\n                    end=\"\",\n                    highlight=False,\n                )\n            else:\n                console.print(f\"\\n[bold green]{role.capitalize()}[/bold green]:\\n\", end=\"\", highlight=False)\n            console.print(content, highlight=False, markup=False)\n        return super().add_messages(*messages)\n\n    def query(self) -&gt; dict:\n        # Extend supermethod to handle human mode\n        if self.config.mode == \"human\":\n            match command := self._prompt_and_handle_slash_commands(\"[bold yellow]&gt;[/bold yellow] \"):\n                case \"/y\" | \"/c\":\n                    pass\n                case _:\n                    msg = {\n                        \"role\": \"user\",\n                        \"content\": f\"User command: \\n```bash\\n{command}\\n```\",\n                        \"extra\": {\"actions\": [{\"command\": command}]},\n                    }\n                    self.add_messages(msg)\n                    return msg\n        try:\n            with console.status(\"Waiting for the LM to respond...\"):\n                return super().query()\n        except LimitsExceeded:\n            console.print(\n                f\"Limits exceeded. Limits: {self.config.step_limit} steps, ${self.config.cost_limit}.\\n\"\n                f\"Current spend: {self.n_calls} steps, ${self.cost:.2f}.\"\n            )\n            self.config.step_limit = int(input(\"New step limit: \"))\n            self.config.cost_limit = float(input(\"New cost limit: \"))\n            return super().query()\n\n    def step(self) -&gt; list[dict]:\n        # Override the step method to handle user interruption\n        try:\n            console.print(Rule())\n            return super().step()\n        except KeyboardInterrupt:\n            interruption_message = self._prompt_and_handle_slash_commands(\n                \"\\n\\n[bold yellow]Interrupted.[/bold yellow] \"\n                \"[green]Type a comment/command[/green] (/h for available commands)\"\n                \"\\n[bold yellow]&gt;[/bold yellow] \"\n            ).strip()\n            if not interruption_message or interruption_message in self._MODE_COMMANDS_MAPPING:\n                interruption_message = \"Temporary interruption caught.\"\n            self._interrupt(f\"Interrupted by user: {interruption_message}\")\n\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        # Override to handle user confirmation and confirm_exit, with try/finally to preserve partial outputs\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        commands = [action[\"command\"] for action in actions]\n        outputs = []\n        try:\n            self._ask_confirmation_or_interrupt(commands)\n            for action in actions:\n                outputs.append(self.env.execute(action))\n        except Submitted as e:\n            self._check_for_new_task_or_submit(e)\n        finally:\n            result = self.add_messages(\n                *self.model.format_observation_messages(message, outputs, self.get_template_vars())\n            )\n        return result\n\n    def _add_observation_messages(self, message: dict, outputs: list[dict]) -&gt; list[dict]:\n        return self.add_messages(*self.model.format_observation_messages(message, outputs, self.get_template_vars()))\n\n    def _check_for_new_task_or_submit(self, e: Submitted) -&gt; NoReturn:\n        \"\"\"Check if user wants to add a new task or submit.\"\"\"\n        if self.config.confirm_exit:\n            message = (\n                \"[bold yellow]Agent wants to finish.[/bold yellow] \"\n                \"[bold green]Type new task[/bold green] or [bold]Enter[/bold] to quit \"\n                \"([bold]/h[/bold] for commands)\\n\"\n                \"[bold yellow]&gt;[/bold yellow] \"\n            )\n            user_input = self._prompt_and_handle_slash_commands(message).strip()\n            if user_input == \"/u\":  # directly continue\n                self._interrupt(\"Switched to human mode.\")\n            elif user_input in self._MODE_COMMANDS_MAPPING:  # ask again\n                return self._check_for_new_task_or_submit(e)\n            elif user_input:\n                self._interrupt(f\"The user added a new task: {user_input}\", itype=\"UserNewTask\")\n        raise e\n\n    def _should_ask_confirmation(self, action: str) -&gt; bool:\n        return self.config.mode == \"confirm\" and not any(re.match(r, action) for r in self.config.whitelist_actions)\n\n    def _ask_confirmation_or_interrupt(self, commands: list[str]) -&gt; None:\n        if not any(self._should_ask_confirmation(c) for c in commands):\n            return\n        prompt = (\n            f\"[bold yellow]Execute {len(commands)} action(s)?[/] [green][bold]Enter[/] to confirm[/], \"\n            \"[red]type [bold]comment[/] to reject[/], or [blue][bold]/h[/] to show available commands[/]\\n\"\n            \"[bold yellow]&gt;[/bold yellow] \"\n        )\n        match user_input := self._prompt_and_handle_slash_commands(prompt).strip():\n            case \"\" | \"/y\":\n                pass  # confirmed, do nothing\n            case \"/u\":  # Skip execution action and get back to query\n                self._interrupt(\"Commands not executed. Switching to human mode\", itype=\"UserRejection\")\n            case _:\n                self._interrupt(\n                    f\"Commands not executed. The user rejected your commands with the following message: {user_input}\",\n                    itype=\"UserRejection\",\n                )\n\n    def _prompt_and_handle_slash_commands(self, prompt: str, *, _multiline: bool = False) -&gt; str:\n        \"\"\"Prompts the user, takes care of /h (followed by requery) and sets the mode. Returns the user input.\"\"\"\n        console.print(prompt, end=\"\")\n        if _multiline:\n            return _multiline_prompt()\n        user_input = prompt_session.prompt(\"\")\n        if user_input == \"/m\":\n            return self._prompt_and_handle_slash_commands(prompt, _multiline=True)\n        if user_input == \"/h\":\n            console.print(\n                f\"Current mode: [bold green]{self.config.mode}[/bold green]\\n\"\n                f\"[bold green]/y[/bold green] to switch to [bold yellow]yolo[/bold yellow] mode (execute LM commands without confirmation)\\n\"\n                f\"[bold green]/c[/bold green] to switch to [bold yellow]confirmation[/bold yellow] mode (ask for confirmation before executing LM commands)\\n\"\n                f\"[bold green]/u[/bold green] to switch to [bold yellow]human[/bold yellow] mode (execute commands issued by the user)\\n\"\n                f\"[bold green]/m[/bold green] to enter multiline comment\",\n            )\n            return self._prompt_and_handle_slash_commands(prompt)\n        if user_input in self._MODE_COMMANDS_MAPPING:\n            if self.config.mode == self._MODE_COMMANDS_MAPPING[user_input]:\n                return self._prompt_and_handle_slash_commands(\n                    f\"[bold red]Already in {self.config.mode} mode.[/bold red]\\n{prompt}\"\n                )\n            self.config.mode = self._MODE_COMMANDS_MAPPING[user_input]\n            console.print(f\"Switched to [bold green]{self.config.mode}[/bold green] mode.\")\n            return user_input\n        return user_input\n</code></pre> <p>See also</p> <ul> <li>This agent subclass builds on top of the default agent, make sure to read that first.</li> <li>This class powers the <code>mini</code> command line tool, see usage for more details.</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive","title":"minisweagent.agents.interactive","text":"<p>A small generalization of the default agent that puts the user in the loop.</p> <p>There are three modes: - human: commands issued by the user are executed immediately - confirm: commands issued by the LM but not whitelisted are confirmed by the user - yolo: commands issued by the LM are executed immediately without confirmation</p>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.console","title":"console  <code>module-attribute</code>","text":"<pre><code>console = Console(highlight=False)\n</code></pre>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgentConfig","title":"InteractiveAgentConfig","text":"<p>               Bases: <code>AgentConfig</code></p>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgentConfig.mode","title":"mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mode: Literal['human', 'confirm', 'yolo'] = 'confirm'\n</code></pre> <p>Whether to confirm actions.</p>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgentConfig.whitelist_actions","title":"whitelist_actions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>whitelist_actions: list[str] = []\n</code></pre> <p>Never confirm actions that match these regular expressions.</p>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgentConfig.confirm_exit","title":"confirm_exit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>confirm_exit: bool = True\n</code></pre> <p>If the agent wants to finish, do we ask for confirmation from user?</p>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgent","title":"InteractiveAgent","text":"<pre><code>InteractiveAgent(\n    *args, config_class=InteractiveAgentConfig, **kwargs\n)\n</code></pre> <p>               Bases: <code>DefaultAgent</code></p> Source code in <code>src/minisweagent/agents/interactive.py</code> <pre><code>def __init__(self, *args, config_class=InteractiveAgentConfig, **kwargs):\n    super().__init__(*args, config_class=config_class, **kwargs)\n    self.cost_last_confirmed = 0.0\n</code></pre>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgent.cost_last_confirmed","title":"cost_last_confirmed  <code>instance-attribute</code>","text":"<pre><code>cost_last_confirmed = 0.0\n</code></pre>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgent.add_messages","title":"add_messages","text":"<pre><code>add_messages(*messages: dict) -&gt; list[dict]\n</code></pre> Source code in <code>src/minisweagent/agents/interactive.py</code> <pre><code>def add_messages(self, *messages: dict) -&gt; list[dict]:\n    # Extend supermethod to print messages\n    for msg in messages:\n        role, content = msg.get(\"role\") or msg.get(\"type\", \"unknown\"), get_content_string(msg)\n        if role == \"assistant\":\n            console.print(\n                f\"\\n[red][bold]mini-swe-agent[/bold] (step [bold]{self.n_calls}[/bold], [bold]${self.cost:.2f}[/bold]):[/red]\\n\",\n                end=\"\",\n                highlight=False,\n            )\n        else:\n            console.print(f\"\\n[bold green]{role.capitalize()}[/bold green]:\\n\", end=\"\", highlight=False)\n        console.print(content, highlight=False, markup=False)\n    return super().add_messages(*messages)\n</code></pre>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgent.query","title":"query","text":"<pre><code>query() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/agents/interactive.py</code> <pre><code>def query(self) -&gt; dict:\n    # Extend supermethod to handle human mode\n    if self.config.mode == \"human\":\n        match command := self._prompt_and_handle_slash_commands(\"[bold yellow]&gt;[/bold yellow] \"):\n            case \"/y\" | \"/c\":\n                pass\n            case _:\n                msg = {\n                    \"role\": \"user\",\n                    \"content\": f\"User command: \\n```bash\\n{command}\\n```\",\n                    \"extra\": {\"actions\": [{\"command\": command}]},\n                }\n                self.add_messages(msg)\n                return msg\n    try:\n        with console.status(\"Waiting for the LM to respond...\"):\n            return super().query()\n    except LimitsExceeded:\n        console.print(\n            f\"Limits exceeded. Limits: {self.config.step_limit} steps, ${self.config.cost_limit}.\\n\"\n            f\"Current spend: {self.n_calls} steps, ${self.cost:.2f}.\"\n        )\n        self.config.step_limit = int(input(\"New step limit: \"))\n        self.config.cost_limit = float(input(\"New cost limit: \"))\n        return super().query()\n</code></pre>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgent.step","title":"step","text":"<pre><code>step() -&gt; list[dict]\n</code></pre> Source code in <code>src/minisweagent/agents/interactive.py</code> <pre><code>def step(self) -&gt; list[dict]:\n    # Override the step method to handle user interruption\n    try:\n        console.print(Rule())\n        return super().step()\n    except KeyboardInterrupt:\n        interruption_message = self._prompt_and_handle_slash_commands(\n            \"\\n\\n[bold yellow]Interrupted.[/bold yellow] \"\n            \"[green]Type a comment/command[/green] (/h for available commands)\"\n            \"\\n[bold yellow]&gt;[/bold yellow] \"\n        ).strip()\n        if not interruption_message or interruption_message in self._MODE_COMMANDS_MAPPING:\n            interruption_message = \"Temporary interruption caught.\"\n        self._interrupt(f\"Interrupted by user: {interruption_message}\")\n</code></pre>"},{"location":"reference/agents/interactive/#minisweagent.agents.interactive.InteractiveAgent.execute_actions","title":"execute_actions","text":"<pre><code>execute_actions(message: dict) -&gt; list[dict]\n</code></pre> Source code in <code>src/minisweagent/agents/interactive.py</code> <pre><code>def execute_actions(self, message: dict) -&gt; list[dict]:\n    # Override to handle user confirmation and confirm_exit, with try/finally to preserve partial outputs\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    commands = [action[\"command\"] for action in actions]\n    outputs = []\n    try:\n        self._ask_confirmation_or_interrupt(commands)\n        for action in actions:\n            outputs.append(self.env.execute(action))\n    except Submitted as e:\n        self._check_for_new_task_or_submit(e)\n    finally:\n        result = self.add_messages(\n            *self.model.format_observation_messages(message, outputs, self.get_template_vars())\n        )\n    return result\n</code></pre>"},{"location":"reference/environments/bubblewrap/","title":"BubblewrapEnvironment","text":""},{"location":"reference/environments/bubblewrap/#bubblewrap","title":"Bubblewrap","text":"bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap","title":"minisweagent.environments.extra.bubblewrap","text":"<p>Bubblewrap is a low-level, unprivileged sandboxing tool for Linux that enables running applications in isolated environments with restricted access to the operating system and user data. This environment uses bubblewrap to execute commands in a sandboxed environment.</p> <p>Warning</p> <p>This environment is experimental.</p> <p>Warning</p> <p>This environment is not supported on Windows.</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironmentConfig","title":"BubblewrapEnvironmentConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironmentConfig.cwd","title":"cwd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd: str = ''\n</code></pre> <p>Working directory for the sandbox.</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironmentConfig.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: dict[str, str] = {}\n</code></pre> <p>Dictionary of environment variables to set in the sandbox.</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironmentConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 30\n</code></pre> <p>Timeout for the command in seconds.</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironmentConfig.executable","title":"executable  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>executable: str = getenv(\n    \"MSWEA_BUBBLEWRAP_EXECUTABLE\", \"bwrap\"\n)\n</code></pre> <p>Path to the bubblewrap executable.</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironmentConfig.wrapper_args","title":"wrapper_args  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>wrapper_args: list[str] = [\n    \"--unshare-user-try\",\n    \"--ro-bind\",\n    \"/usr\",\n    \"/usr\",\n    \"--ro-bind\",\n    \"/bin\",\n    \"/bin\",\n    \"--ro-bind\",\n    \"/lib\",\n    \"/lib\",\n    \"--ro-bind\",\n    \"/lib64\",\n    \"/lib64\",\n    \"--ro-bind\",\n    \"/etc\",\n    \"/etc\",\n    \"--tmpfs\",\n    \"/tmp\",\n    \"--proc\",\n    \"/proc\",\n    \"--dev\",\n    \"/dev\",\n    \"--new-session\",\n    \"--setenv\",\n    \"PATH\",\n    \"/usr/local/bin:/usr/sbin:/usr/bin:/bin\",\n]\n</code></pre> <p>Arguments to pass to the bubblewrap executable.</p>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment","title":"BubblewrapEnvironment","text":"<pre><code>BubblewrapEnvironment(\n    *,\n    config_class: type = BubblewrapEnvironmentConfig,\n    logger: Logger | None = None,\n    **kwargs,\n)\n</code></pre> <p>This class executes bash commands in a bubblewrap environment and a separate working directory for each environment. See <code>BubblewrapEnvironmentConfig</code> for kwargs.</p> Source code in <code>src/minisweagent/environments/extra/bubblewrap.py</code> <pre><code>def __init__(\n    self, *, config_class: type = BubblewrapEnvironmentConfig, logger: logging.Logger | None = None, **kwargs\n):\n    \"\"\"This class executes bash commands in a bubblewrap environment and a separate working\n    directory for each environment. See `BubblewrapEnvironmentConfig` for kwargs.\n    \"\"\"\n    self.logger = logger or logging.getLogger(\"minisweagent.environment\")\n    self.config = config_class(**kwargs)\n    self.working_dir = Path(tempfile.gettempdir()) / f\"minisweagent-{uuid.uuid4().hex[:8]}\"\n    self.working_dir.mkdir(parents=True)\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = logger or getLogger('minisweagent.environment')\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.working_dir","title":"working_dir  <code>instance-attribute</code>","text":"<pre><code>working_dir = Path(gettempdir()) / f\"minisweagent-{hex[:8]}\"\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.execute","title":"execute","text":"<pre><code>execute(\n    action: dict,\n    cwd: str = \"\",\n    *,\n    timeout: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Execute a command in the bubblewrap environment and return the result as a dict.</p> Source code in <code>src/minisweagent/environments/extra/bubblewrap.py</code> <pre><code>def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n    \"\"\"Execute a command in the bubblewrap environment and return the result as a dict.\"\"\"\n    command = action.get(\"command\", \"\")\n    cwd = cwd or self.config.cwd or str(self.working_dir)\n\n    cmd = [self.config.executable] + self.config.wrapper_args + [\"--bind\", cwd, cwd, \"--chdir\", cwd]\n\n    # Add environment variables\n    for key, value in self.config.env.items():\n        cmd.extend([\"--setenv\", key, value])\n\n    cmd.extend([\"bash\", \"-c\", command])\n\n    try:\n        result = subprocess.run(\n            cmd,\n            text=True,\n            timeout=timeout or self.config.timeout,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n    except Exception as e:\n        raw_output = getattr(e, \"output\", None)\n        raw_output = (\n            raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n        )\n        output = {\n            \"output\": raw_output,\n            \"returncode\": -1,\n            \"exception_info\": f\"An error occurred while executing the command: {e}\",\n            \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n        }\n    self._check_finished(output)\n    return output\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> Source code in <code>src/minisweagent/environments/extra/bubblewrap.py</code> <pre><code>def cleanup(self):\n    if self.working_dir.exists():\n        shutil.rmtree(self.working_dir)\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/environments/extra/bubblewrap.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), kwargs)\n</code></pre>"},{"location":"reference/environments/bubblewrap/#minisweagent.environments.extra.bubblewrap.BubblewrapEnvironment.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/environments/extra/bubblewrap.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"environment\": self.config.model_dump(mode=\"json\"),\n                \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            }\n        }\n    }\n</code></pre>"},{"location":"reference/environments/contree/","title":"ConTree","text":""},{"location":"reference/environments/contree/#contree","title":"ConTree","text":"<p>ConTree Environment class</p> <ul> <li>Read on GitHub</li> <li>Requires ConTree token</li> </ul> Full source code <pre><code>import logging\nimport platform\nimport shlex\nfrom dataclasses import asdict, is_dataclass, replace\nfrom numbers import Number\nfrom typing import Any, TypedDict\nfrom urllib.parse import urlparse\n\nfrom contree_sdk import ContreeSync\nfrom contree_sdk.config import ContreeConfig\nfrom contree_sdk.sdk.exceptions import NotFoundError\nfrom contree_sdk.sdk.objects.image import ContreeImageSync\nfrom pydantic import BaseModel, Field\n\nfrom minisweagent import Environment\nfrom minisweagent.exceptions import Submitted\nfrom minisweagent.utils.serialize import recursive_merge\n\nlogger = logging.getLogger(__name__)\n\n\nclass ContreeEnvironmentConfig(BaseModel):\n    contree_config: ContreeConfig | dict[str, Any]\n\n    image: str\n    image_tag: str = None\n    \"\"\"If set, used to pull image by tag. If fails, then it imports by `image` and sets `image_tag` value to image tag\"\"\"\n    cwd: str = \"/\"\n    \"\"\"Working directory in which to execute commands.\"\"\"\n    cwd_auto_create: bool = True\n    \"\"\"Create cwd before running any commands.\"\"\"\n    env: dict[str, str] = Field(default_factory=dict)\n    \"\"\"Environment variables to set in the container.\"\"\"\n    forward_env: list[str] = Field(default_factory=list)\n    \"\"\"Environment variables to forward to the container.\n    Variables are only forwarded if they are set in the host environment.\n    In case of conflict with `env`, the `env` variables take precedence.\n    \"\"\"\n    interpreter: list[str] = Field(default_factory=lambda: [\"bash\", \"-c\"])\n    \"\"\"Interpreter to execute commands\"\"\"\n    timeout: int = 30\n    \"\"\"Timeout for executing commands in the container.\"\"\"\n\n\nclass ExecutionResult(TypedDict):\n    output: str\n    returncode: int\n\n\nclass ContreeEnvironment(Environment):\n    def __init__(self, *, config_class: type[ContreeEnvironmentConfig] = ContreeEnvironmentConfig, **kwargs):\n        \"\"\"This class executes bash commands in a [ConTree](https://contree.dev) container\n        using [contree-sdk](https://github.com/nebius/contree-sdk)\"\"\"\n\n        self.config: ContreeEnvironmentConfig = config_class(**kwargs)\n        self.logger = logging.getLogger(\"minisweagent.environment\")\n\n        if isinstance(self.config.contree_config, dict):\n            self.config = replace(self.config, contree_config=ContreeConfig(**self.config.contree_config))\n\n        self.client = ContreeSync(config=self.config.contree_config)\n        self.session = self._pull_image().session()\n        if self.config.cwd_auto_create:\n            self.execute(\n                action={\"command\": f\"mkdir -p {self.config.cwd}\"},\n                cwd=\"/\",\n            )\n\n    def _pull_image(self) -&gt; ContreeImageSync:\n        image_tag = self.config.image_tag or ContreeEnvironment.get_tag_by_image_url(self.config.image)\n        if image_tag:\n            try:\n                self.logger.info(f\"Pulling image by tag: {image_tag}\")\n                image = self.client.images.pull(image_tag)\n                self.logger.info(f\"Pulled image by tag: {image_tag}\")\n                return image\n            except NotFoundError:\n                self.logger.warning(\n                    f\"Failed to pull image by tag: {image_tag}, starting to import from: {self.config.image}\"\n                )\n\n        self.logger.info(f\"Pulling image: {self.config.image}\")\n        return self.client.images.pull(self.config.image, new_tag=image_tag)\n\n    def _shell_command(self, command: str) -&gt; str:\n        shell_cmd = \" \".join(self.config.interpreter)\n        return f\"{shell_cmd} {shlex.quote(command)}\"\n\n    def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n        \"\"\"Execute a command in the environment and return the raw output.\"\"\"\n        command = action.get(\"command\")\n        self.session.run(\n            shell=self._shell_command(command),\n            cwd=cwd or self.config.cwd,\n            timeout=timeout or self.config.timeout,\n            disposable=False,\n        ).wait()\n\n        cwd = cwd or self.config.cwd\n        try:\n            self.session.run(\n                shell=self._shell_command(command),\n                cwd=cwd or self.config.cwd,\n                timeout=timeout or self.config.timeout,\n                disposable=False,\n            ).wait()\n            output = {\n                \"output\": self.session.stdout + self.session.stderr,\n                \"returncode\": self.session.exit_code,\n                \"exception_info\": \"\",\n            }\n        except Exception as e:\n            raw_output = getattr(e, \"output\", None)\n            raw_output = (\n                raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n            )\n            extras = {}\n            if is_dataclass(e):\n                extras = {k: str(v) if not isinstance(v, Number) else v for k, v in asdict(e).items()}\n\n            output = {\n                \"output\": raw_output,\n                \"returncode\": -1,\n                \"exception_info\": f\"An error occurred while executing the command: {e}\",\n                \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e), **extras},\n            }\n        self._check_finished(output)\n        return output\n\n    def _check_finished(self, output: dict):\n        \"\"\"Raises Submitted if the output indicates task completion.\"\"\"\n        lines = output.get(\"output\", \"\").lstrip().splitlines(keepends=True)\n        if lines and lines[0].strip() == \"COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT\" and output[\"returncode\"] == 0:\n            submission = \"\".join(lines[1:])\n            raise Submitted(\n                {\n                    \"role\": \"exit\",\n                    \"content\": submission,\n                    \"extra\": {\"exit_status\": \"Submitted\", \"submission\": submission},\n                }\n            )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), kwargs)\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"environment\": self.config.model_dump(mode=\"json\"),\n                    \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                }\n            }\n        }\n\n    @staticmethod\n    def get_tag_by_image_url(url: str) -&gt; str:\n        url_parsed = urlparse(url)\n        if url_parsed.netloc:\n            url = url_parsed.path\n\n        if \":\" not in url:\n            url += \":latest\"\n        parts = url.split(\"/\", 1)\n        if len(parts) == 1:\n            return parts[0]\n        domain, url_path = parts\n        if \".\" in domain and (\"docker\" in domain or \"io\" in domain):\n            return url_path or domain\n        if domain:\n            return f\"{domain}/{url_path}\"\n        return url_path\n</code></pre> <p>This environment executes commands in ConTree sandboxes using ConTree SDK</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree","title":"minisweagent.environments.extra.contree","text":""},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig","title":"ContreeEnvironmentConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.contree_config","title":"contree_config  <code>instance-attribute</code>","text":"<pre><code>contree_config: ContreeConfig | dict[str, Any]\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: str\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.image_tag","title":"image_tag  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>image_tag: str = None\n</code></pre> <p>If set, used to pull image by tag. If fails, then it imports by <code>image</code> and sets <code>image_tag</code> value to image tag</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.cwd","title":"cwd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd: str = '/'\n</code></pre> <p>Working directory in which to execute commands.</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.cwd_auto_create","title":"cwd_auto_create  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd_auto_create: bool = True\n</code></pre> <p>Create cwd before running any commands.</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: dict[str, str] = Field(default_factory=dict)\n</code></pre> <p>Environment variables to set in the container.</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.forward_env","title":"forward_env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>forward_env: list[str] = Field(default_factory=list)\n</code></pre> <p>Environment variables to forward to the container. Variables are only forwarded if they are set in the host environment. In case of conflict with <code>env</code>, the <code>env</code> variables take precedence.</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.interpreter","title":"interpreter  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>interpreter: list[str] = Field(\n    default_factory=lambda: [\"bash\", \"-c\"]\n)\n</code></pre> <p>Interpreter to execute commands</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironmentConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 30\n</code></pre> <p>Timeout for executing commands in the container.</p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ExecutionResult","title":"ExecutionResult","text":"<p>               Bases: <code>TypedDict</code></p>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ExecutionResult.output","title":"output  <code>instance-attribute</code>","text":"<pre><code>output: str\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ExecutionResult.returncode","title":"returncode  <code>instance-attribute</code>","text":"<pre><code>returncode: int\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment","title":"ContreeEnvironment","text":"<pre><code>ContreeEnvironment(\n    *,\n    config_class: type[\n        ContreeEnvironmentConfig\n    ] = ContreeEnvironmentConfig,\n    **kwargs,\n)\n</code></pre> <p>               Bases: <code>Environment</code></p> <p>This class executes bash commands in a ConTree container using contree-sdk</p> Source code in <code>src/minisweagent/environments/extra/contree.py</code> <pre><code>def __init__(self, *, config_class: type[ContreeEnvironmentConfig] = ContreeEnvironmentConfig, **kwargs):\n    \"\"\"This class executes bash commands in a [ConTree](https://contree.dev) container\n    using [contree-sdk](https://github.com/nebius/contree-sdk)\"\"\"\n\n    self.config: ContreeEnvironmentConfig = config_class(**kwargs)\n    self.logger = logging.getLogger(\"minisweagent.environment\")\n\n    if isinstance(self.config.contree_config, dict):\n        self.config = replace(self.config, contree_config=ContreeConfig(**self.config.contree_config))\n\n    self.client = ContreeSync(config=self.config.contree_config)\n    self.session = self._pull_image().session()\n    if self.config.cwd_auto_create:\n        self.execute(\n            action={\"command\": f\"mkdir -p {self.config.cwd}\"},\n            cwd=\"/\",\n        )\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config: ContreeEnvironmentConfig = config_class(**kwargs)\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = getLogger('minisweagent.environment')\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.client","title":"client  <code>instance-attribute</code>","text":"<pre><code>client = ContreeSync(config=contree_config)\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.session","title":"session  <code>instance-attribute</code>","text":"<pre><code>session = session()\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.execute","title":"execute","text":"<pre><code>execute(\n    action: dict,\n    cwd: str = \"\",\n    *,\n    timeout: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Execute a command in the environment and return the raw output.</p> Source code in <code>src/minisweagent/environments/extra/contree.py</code> <pre><code>def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n    \"\"\"Execute a command in the environment and return the raw output.\"\"\"\n    command = action.get(\"command\")\n    self.session.run(\n        shell=self._shell_command(command),\n        cwd=cwd or self.config.cwd,\n        timeout=timeout or self.config.timeout,\n        disposable=False,\n    ).wait()\n\n    cwd = cwd or self.config.cwd\n    try:\n        self.session.run(\n            shell=self._shell_command(command),\n            cwd=cwd or self.config.cwd,\n            timeout=timeout or self.config.timeout,\n            disposable=False,\n        ).wait()\n        output = {\n            \"output\": self.session.stdout + self.session.stderr,\n            \"returncode\": self.session.exit_code,\n            \"exception_info\": \"\",\n        }\n    except Exception as e:\n        raw_output = getattr(e, \"output\", None)\n        raw_output = (\n            raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n        )\n        extras = {}\n        if is_dataclass(e):\n            extras = {k: str(v) if not isinstance(v, Number) else v for k, v in asdict(e).items()}\n\n        output = {\n            \"output\": raw_output,\n            \"returncode\": -1,\n            \"exception_info\": f\"An error occurred while executing the command: {e}\",\n            \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e), **extras},\n        }\n    self._check_finished(output)\n    return output\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/environments/extra/contree.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), kwargs)\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/environments/extra/contree.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"environment\": self.config.model_dump(mode=\"json\"),\n                \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            }\n        }\n    }\n</code></pre>"},{"location":"reference/environments/contree/#minisweagent.environments.extra.contree.ContreeEnvironment.get_tag_by_image_url","title":"get_tag_by_image_url  <code>staticmethod</code>","text":"<pre><code>get_tag_by_image_url(url: str) -&gt; str\n</code></pre> Source code in <code>src/minisweagent/environments/extra/contree.py</code> <pre><code>@staticmethod\ndef get_tag_by_image_url(url: str) -&gt; str:\n    url_parsed = urlparse(url)\n    if url_parsed.netloc:\n        url = url_parsed.path\n\n    if \":\" not in url:\n        url += \":latest\"\n    parts = url.split(\"/\", 1)\n    if len(parts) == 1:\n        return parts[0]\n    domain, url_path = parts\n    if \".\" in domain and (\"docker\" in domain or \"io\" in domain):\n        return url_path or domain\n    if domain:\n        return f\"{domain}/{url_path}\"\n    return url_path\n</code></pre>"},{"location":"reference/environments/contree/#setup","title":"Setup","text":"<ol> <li> <p>Install the dependencies:    </p><pre><code>pip install \"mini-swe-agent[contree]\"\n</code></pre><p></p> </li> <li> <p>Set up ConTree token and base_url:    </p><pre><code>export CONTREE_TOKEN=\"your-contree-token\"\nexport CONTREE_BASE_URL=\"your-given-base-url-for-contree\"\n</code></pre><p></p> </li> </ol>"},{"location":"reference/environments/contree/#usage","title":"Usage","text":"<p>Run mini-swe-agent like with any other environment: </p><pre><code>mini-extra swebench \\\n    --subset verified \\\n    --split test \\\n    --workers 100\n    --environment-class contree\n</code></pre><p></p> <p>It can be specified both through cli parameter or by setting <code>environment_class</code> to <code>contree</code> in your swebench.yaml config</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/environments/docker/","title":"DockerEnvironment","text":""},{"location":"reference/environments/docker/#docker","title":"Docker","text":"<p>Docker Environment class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import logging\nimport os\nimport platform\nimport shlex\nimport subprocess\nimport uuid\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom minisweagent.exceptions import Submitted\nfrom minisweagent.utils.serialize import recursive_merge\n\n\nclass DockerEnvironmentConfig(BaseModel):\n    image: str\n    cwd: str = \"/\"\n    \"\"\"Working directory in which to execute commands.\"\"\"\n    env: dict[str, str] = {}\n    \"\"\"Environment variables to set in the container.\"\"\"\n    forward_env: list[str] = []\n    \"\"\"Environment variables to forward to the container.\n    Variables are only forwarded if they are set in the host environment.\n    In case of conflict with `env`, the `env` variables take precedence.\n    \"\"\"\n    timeout: int = 30\n    \"\"\"Timeout for executing commands in the container.\"\"\"\n    executable: str = os.getenv(\"MSWEA_DOCKER_EXECUTABLE\", \"docker\")\n    \"\"\"Path to the docker/container executable.\"\"\"\n    run_args: list[str] = [\"--rm\"]\n    \"\"\"Additional arguments to pass to the docker/container executable.\n    Default is [\"--rm\"], which removes the container after it exits.\n    \"\"\"\n    container_timeout: str = \"2h\"\n    \"\"\"Max duration to keep container running. Uses the same format as the sleep command.\"\"\"\n    pull_timeout: int = 120\n    \"\"\"Timeout in seconds for pulling images.\"\"\"\n    interpreter: list[str] = [\"bash\", \"-lc\"]\n    \"\"\"Interpreter to use to execute commands. Default is [\"bash\", \"-lc\"].\n    The actual command will be appended as argument to this. Override this to e.g., modify shell flags\n    (e.g., to remove the `-l` flag to disable login shell) or to use python instead of bash to interpret commands.\n    \"\"\"\n\n\nclass DockerEnvironment:\n    def __init__(\n        self,\n        *,\n        config_class: type = DockerEnvironmentConfig,\n        logger: logging.Logger | None = None,\n        **kwargs,\n    ):\n        \"\"\"This class executes bash commands in a Docker container using direct docker commands.\n        See `DockerEnvironmentConfig` for keyword arguments.\n        \"\"\"\n        self.logger = logger or logging.getLogger(\"minisweagent.environment\")\n        self.container_id: str | None = None\n        self.config = config_class(**kwargs)\n        self._start_container()\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), kwargs)\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"environment\": self.config.model_dump(mode=\"json\"),\n                    \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                }\n            }\n        }\n\n    def _start_container(self):\n        \"\"\"Start the Docker container and return the container ID.\"\"\"\n        container_name = f\"minisweagent-{uuid.uuid4().hex[:8]}\"\n        cmd = [\n            self.config.executable,\n            \"run\",\n            \"-d\",\n            \"--name\",\n            container_name,\n            \"-w\",\n            self.config.cwd,\n            *self.config.run_args,\n            self.config.image,\n            \"sleep\",\n            self.config.container_timeout,\n        ]\n        self.logger.debug(f\"Starting container with command: {shlex.join(cmd)}\")\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            timeout=self.config.pull_timeout,  # docker pull might take a while\n            check=True,\n        )\n        self.logger.info(f\"Started container {container_name} with ID {result.stdout.strip()}\")\n        self.container_id = result.stdout.strip()\n\n    def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n        \"\"\"Execute a command in the Docker container and return the result as a dict.\"\"\"\n        command = action.get(\"command\", \"\")\n        cwd = cwd or self.config.cwd\n        assert self.container_id, \"Container not started\"\n\n        cmd = [self.config.executable, \"exec\", \"-w\", cwd]\n        for key in self.config.forward_env:\n            if (value := os.getenv(key)) is not None:\n                cmd.extend([\"-e\", f\"{key}={value}\"])\n        for key, value in self.config.env.items():\n            cmd.extend([\"-e\", f\"{key}={value}\"])\n        cmd.extend([self.container_id, *self.config.interpreter, command])\n\n        try:\n            result = subprocess.run(\n                cmd,\n                text=True,\n                timeout=timeout or self.config.timeout,\n                encoding=\"utf-8\",\n                errors=\"replace\",\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n            )\n            output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n        except Exception as e:\n            raw_output = getattr(e, \"output\", None)\n            raw_output = (\n                raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n            )\n            output = {\n                \"output\": raw_output,\n                \"returncode\": -1,\n                \"exception_info\": f\"An error occurred while executing the command: {e}\",\n                \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n            }\n        self._check_finished(output)\n        return output\n\n    def _check_finished(self, output: dict):\n        \"\"\"Raises Submitted if the output indicates task completion.\"\"\"\n        lines = output.get(\"output\", \"\").lstrip().splitlines(keepends=True)\n        if lines and lines[0].strip() == \"COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT\" and output[\"returncode\"] == 0:\n            submission = \"\".join(lines[1:])\n            raise Submitted(\n                {\n                    \"role\": \"exit\",\n                    \"content\": submission,\n                    \"extra\": {\"exit_status\": \"Submitted\", \"submission\": submission},\n                }\n            )\n\n    def cleanup(self):\n        \"\"\"Stop and remove the Docker container.\"\"\"\n        if getattr(self, \"container_id\", None) is not None:  # if init fails early, container_id might not be set\n            cmd = f\"(timeout 60 {self.config.executable} stop {self.container_id} || {self.config.executable} rm -f {self.container_id}) &gt;/dev/null 2&gt;&amp;1 &amp;\"\n            subprocess.Popen(cmd, shell=True)\n\n    def __del__(self):\n        \"\"\"Cleanup container when object is destroyed.\"\"\"\n        self.cleanup()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker","title":"minisweagent.environments.docker","text":""},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig","title":"DockerEnvironmentConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: str\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.cwd","title":"cwd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd: str = '/'\n</code></pre> <p>Working directory in which to execute commands.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: dict[str, str] = {}\n</code></pre> <p>Environment variables to set in the container.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.forward_env","title":"forward_env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>forward_env: list[str] = []\n</code></pre> <p>Environment variables to forward to the container. Variables are only forwarded if they are set in the host environment. In case of conflict with <code>env</code>, the <code>env</code> variables take precedence.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 30\n</code></pre> <p>Timeout for executing commands in the container.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.executable","title":"executable  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>executable: str = getenv(\n    \"MSWEA_DOCKER_EXECUTABLE\", \"docker\"\n)\n</code></pre> <p>Path to the docker/container executable.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.run_args","title":"run_args  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_args: list[str] = ['--rm']\n</code></pre> <p>Additional arguments to pass to the docker/container executable. Default is [\"--rm\"], which removes the container after it exits.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.container_timeout","title":"container_timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>container_timeout: str = '2h'\n</code></pre> <p>Max duration to keep container running. Uses the same format as the sleep command.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.pull_timeout","title":"pull_timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pull_timeout: int = 120\n</code></pre> <p>Timeout in seconds for pulling images.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironmentConfig.interpreter","title":"interpreter  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>interpreter: list[str] = ['bash', '-lc']\n</code></pre> <p>Interpreter to use to execute commands. Default is [\"bash\", \"-lc\"]. The actual command will be appended as argument to this. Override this to e.g., modify shell flags (e.g., to remove the <code>-l</code> flag to disable login shell) or to use python instead of bash to interpret commands.</p>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment","title":"DockerEnvironment","text":"<pre><code>DockerEnvironment(\n    *,\n    config_class: type = DockerEnvironmentConfig,\n    logger: Logger | None = None,\n    **kwargs,\n)\n</code></pre> <p>This class executes bash commands in a Docker container using direct docker commands. See <code>DockerEnvironmentConfig</code> for keyword arguments.</p> Source code in <code>src/minisweagent/environments/docker.py</code> <pre><code>def __init__(\n    self,\n    *,\n    config_class: type = DockerEnvironmentConfig,\n    logger: logging.Logger | None = None,\n    **kwargs,\n):\n    \"\"\"This class executes bash commands in a Docker container using direct docker commands.\n    See `DockerEnvironmentConfig` for keyword arguments.\n    \"\"\"\n    self.logger = logger or logging.getLogger(\"minisweagent.environment\")\n    self.container_id: str | None = None\n    self.config = config_class(**kwargs)\n    self._start_container()\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = logger or getLogger('minisweagent.environment')\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.container_id","title":"container_id  <code>instance-attribute</code>","text":"<pre><code>container_id: str | None = None\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/environments/docker.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), kwargs)\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/environments/docker.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"environment\": self.config.model_dump(mode=\"json\"),\n                \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            }\n        }\n    }\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.execute","title":"execute","text":"<pre><code>execute(\n    action: dict,\n    cwd: str = \"\",\n    *,\n    timeout: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Execute a command in the Docker container and return the result as a dict.</p> Source code in <code>src/minisweagent/environments/docker.py</code> <pre><code>def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n    \"\"\"Execute a command in the Docker container and return the result as a dict.\"\"\"\n    command = action.get(\"command\", \"\")\n    cwd = cwd or self.config.cwd\n    assert self.container_id, \"Container not started\"\n\n    cmd = [self.config.executable, \"exec\", \"-w\", cwd]\n    for key in self.config.forward_env:\n        if (value := os.getenv(key)) is not None:\n            cmd.extend([\"-e\", f\"{key}={value}\"])\n    for key, value in self.config.env.items():\n        cmd.extend([\"-e\", f\"{key}={value}\"])\n    cmd.extend([self.container_id, *self.config.interpreter, command])\n\n    try:\n        result = subprocess.run(\n            cmd,\n            text=True,\n            timeout=timeout or self.config.timeout,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n    except Exception as e:\n        raw_output = getattr(e, \"output\", None)\n        raw_output = (\n            raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n        )\n        output = {\n            \"output\": raw_output,\n            \"returncode\": -1,\n            \"exception_info\": f\"An error occurred while executing the command: {e}\",\n            \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n        }\n    self._check_finished(output)\n    return output\n</code></pre>"},{"location":"reference/environments/docker/#minisweagent.environments.docker.DockerEnvironment.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> <p>Stop and remove the Docker container.</p> Source code in <code>src/minisweagent/environments/docker.py</code> <pre><code>def cleanup(self):\n    \"\"\"Stop and remove the Docker container.\"\"\"\n    if getattr(self, \"container_id\", None) is not None:  # if init fails early, container_id might not be set\n        cmd = f\"(timeout 60 {self.config.executable} stop {self.container_id} || {self.config.executable} rm -f {self.container_id}) &gt;/dev/null 2&gt;&amp;1 &amp;\"\n        subprocess.Popen(cmd, shell=True)\n</code></pre>"},{"location":"reference/environments/local/","title":"LocalEnvironment","text":""},{"location":"reference/environments/local/#local","title":"Local","text":"<p>Local Environment class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import os\nimport platform\nimport subprocess\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom minisweagent.exceptions import Submitted\nfrom minisweagent.utils.serialize import recursive_merge\n\n\nclass LocalEnvironmentConfig(BaseModel):\n    cwd: str = \"\"\n    env: dict[str, str] = {}\n    timeout: int = 30\n\n\nclass LocalEnvironment:\n    def __init__(self, *, config_class: type = LocalEnvironmentConfig, **kwargs):\n        \"\"\"This class executes bash commands directly on the local machine.\"\"\"\n        self.config = config_class(**kwargs)\n\n    def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n        \"\"\"Execute a command in the local environment and return the result as a dict.\"\"\"\n        command = action.get(\"command\", \"\")\n        cwd = cwd or self.config.cwd or os.getcwd()\n        try:\n            result = subprocess.run(\n                command,\n                shell=True,\n                text=True,\n                cwd=cwd,\n                env=os.environ | self.config.env,\n                timeout=timeout or self.config.timeout,\n                encoding=\"utf-8\",\n                errors=\"replace\",\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n            )\n            output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n        except Exception as e:\n            raw_output = getattr(e, \"output\", None)\n            raw_output = (\n                raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n            )\n            output = {\n                \"output\": raw_output,\n                \"returncode\": -1,\n                \"exception_info\": f\"An error occurred while executing the command: {e}\",\n                \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n            }\n        self._check_finished(output)\n        return output\n\n    def _check_finished(self, output: dict):\n        \"\"\"Raises Submitted if the output indicates task completion.\"\"\"\n        lines = output.get(\"output\", \"\").lstrip().splitlines(keepends=True)\n        if lines and lines[0].strip() == \"COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT\" and output[\"returncode\"] == 0:\n            submission = \"\".join(lines[1:])\n            raise Submitted(\n                {\n                    \"role\": \"exit\",\n                    \"content\": submission,\n                    \"extra\": {\"exit_status\": \"Submitted\", \"submission\": submission},\n                }\n            )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), os.environ, kwargs)\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"environment\": self.config.model_dump(mode=\"json\"),\n                    \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                }\n            }\n        }\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/environments/local/#minisweagent.environments.local","title":"minisweagent.environments.local","text":""},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironmentConfig","title":"LocalEnvironmentConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironmentConfig.cwd","title":"cwd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd: str = ''\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironmentConfig.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: dict[str, str] = {}\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironmentConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 30\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironment","title":"LocalEnvironment","text":"<pre><code>LocalEnvironment(\n    *, config_class: type = LocalEnvironmentConfig, **kwargs\n)\n</code></pre> <p>This class executes bash commands directly on the local machine.</p> Source code in <code>src/minisweagent/environments/local.py</code> <pre><code>def __init__(self, *, config_class: type = LocalEnvironmentConfig, **kwargs):\n    \"\"\"This class executes bash commands directly on the local machine.\"\"\"\n    self.config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironment.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironment.execute","title":"execute","text":"<pre><code>execute(\n    action: dict,\n    cwd: str = \"\",\n    *,\n    timeout: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Execute a command in the local environment and return the result as a dict.</p> Source code in <code>src/minisweagent/environments/local.py</code> <pre><code>def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n    \"\"\"Execute a command in the local environment and return the result as a dict.\"\"\"\n    command = action.get(\"command\", \"\")\n    cwd = cwd or self.config.cwd or os.getcwd()\n    try:\n        result = subprocess.run(\n            command,\n            shell=True,\n            text=True,\n            cwd=cwd,\n            env=os.environ | self.config.env,\n            timeout=timeout or self.config.timeout,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n    except Exception as e:\n        raw_output = getattr(e, \"output\", None)\n        raw_output = (\n            raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n        )\n        output = {\n            \"output\": raw_output,\n            \"returncode\": -1,\n            \"exception_info\": f\"An error occurred while executing the command: {e}\",\n            \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n        }\n    self._check_finished(output)\n    return output\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironment.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/environments/local.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return recursive_merge(self.config.model_dump(), platform.uname()._asdict(), os.environ, kwargs)\n</code></pre>"},{"location":"reference/environments/local/#minisweagent.environments.local.LocalEnvironment.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/environments/local.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"environment\": self.config.model_dump(mode=\"json\"),\n                \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            }\n        }\n    }\n</code></pre>"},{"location":"reference/environments/singularity/","title":"SingularityEnvironment","text":""},{"location":"reference/environments/singularity/#singularity","title":"Singularity","text":"<p>Singularity Environment class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>#!/usr/bin/env python3\n\nimport logging\nimport os\nimport shutil\nimport subprocess\nimport tempfile\nimport uuid\nfrom pathlib import Path\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom minisweagent.exceptions import Submitted\nfrom minisweagent.utils.serialize import recursive_merge\n\n\nclass SingularityEnvironmentConfig(BaseModel):\n    image: str\n    cwd: str = \"/\"\n    env: dict[str, str] = {}\n    \"\"\"Environment variables to set in the container.\"\"\"\n    forward_env: list[str] = []\n    \"\"\"Environment variables to forward to the container.\"\"\"\n    timeout: int = 30\n    \"\"\"Timeout for executing commands in the container.\"\"\"\n    executable: str = os.getenv(\"MSWEA_SINGULARITY_EXECUTABLE\", \"singularity\")\n    \"\"\"Path to the singularity executable.\"\"\"\n    sandbox_build_retries: int = 3\n    \"\"\"Number of retries for building the sandbox if an error occurs.\"\"\"\n    global_args: list[str] = [\"--quiet\"]\n    \"\"\"Global arguments passed before the subcommand (e.g., --quiet, --debug).\"\"\"\n    exec_args: list[str] = [\"--contain\", \"--cleanenv\", \"--fakeroot\"]\n    \"\"\"Arguments passed to `singularity exec`.\"\"\"\n\n\nclass SingularityEnvironment:\n    def __init__(\n        self, *, config_class: type = SingularityEnvironmentConfig, logger: logging.Logger | None = None, **kwargs\n    ):\n        \"\"\"Singularity environment. See `SingularityEnvironmentConfig` for kwargs.\"\"\"\n        self.logger = logger or logging.getLogger(\"minisweagent.environment\")\n        self.config = config_class(**kwargs)\n        self.sandbox_dir = self._build_sandbox()\n\n    def _build_sandbox(self) -&gt; Path:\n        # Building the sandbox can fail (very rarely), so we retry it\n        max_retries = self.config.sandbox_build_retries\n        for attempt in range(max_retries):\n            sandbox_dir = Path(tempfile.gettempdir()) / f\"minisweagent-{uuid.uuid4().hex[:8]}\"\n            try:\n                subprocess.run(\n                    [self.config.executable, \"build\", \"--sandbox\", sandbox_dir, self.config.image],\n                    check=True,\n                    capture_output=True,\n                )\n                break\n            except subprocess.CalledProcessError as e:\n                shutil.rmtree(sandbox_dir, ignore_errors=True)\n                self.logger.error(\n                    f\"Error building image {self.config.image}, stdout: {e.stdout}, stderr: {e.stderr} (attempt {attempt + 1}/{max_retries})\"\n                )\n                if attempt == max_retries - 1:\n                    raise\n        return sandbox_dir\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return recursive_merge(self.config.model_dump(), kwargs)\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"environment\": self.config.model_dump(mode=\"json\"),\n                    \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                }\n            }\n        }\n\n    def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n        \"\"\"Execute a command in a Singularity container and return the result as a dict.\"\"\"\n        command = action.get(\"command\", \"\")\n        cmd = [self.config.executable, *self.config.global_args, \"exec\", *self.config.exec_args]\n\n        work_dir = cwd or self.config.cwd\n        if work_dir and work_dir != \"/\":\n            cmd.extend([\"--pwd\", work_dir])\n\n        for key in self.config.forward_env:\n            if (value := os.getenv(key)) is not None:\n                cmd.extend([\"--env\", f\"{key}={value}\"])\n        for key, value in self.config.env.items():\n            cmd.extend([\"--env\", f\"{key}={value}\"])\n\n        cmd.extend([\"--writable\", str(self.sandbox_dir), \"bash\", \"-c\", command])\n        try:\n            result = subprocess.run(\n                cmd,\n                text=True,\n                timeout=timeout or self.config.timeout,\n                encoding=\"utf-8\",\n                errors=\"replace\",\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n            )\n            output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n        except Exception as e:\n            raw_output = getattr(e, \"output\", None)\n            raw_output = (\n                raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n            )\n            output = {\n                \"output\": raw_output,\n                \"returncode\": -1,\n                \"exception_info\": f\"An error occurred while executing the command: {e}\",\n                \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n            }\n        self._check_finished(output)\n        return output\n\n    def _check_finished(self, output: dict):\n        \"\"\"Raises Submitted if the output indicates task completion.\"\"\"\n        lines = output.get(\"output\", \"\").lstrip().splitlines(keepends=True)\n        if lines and lines[0].strip() == \"COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT\" and output[\"returncode\"] == 0:\n            submission = \"\".join(lines[1:])\n            raise Submitted(\n                {\n                    \"role\": \"exit\",\n                    \"content\": submission,\n                    \"extra\": {\"exit_status\": \"Submitted\", \"submission\": submission},\n                }\n            )\n\n    def cleanup(self):\n        shutil.rmtree(self.sandbox_dir, ignore_errors=True)\n\n    def __del__(self):\n        \"\"\"Cleanup sandbox when object is destroyed.\"\"\"\n        self.cleanup()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity","title":"minisweagent.environments.singularity","text":""},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig","title":"SingularityEnvironmentConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: str\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.cwd","title":"cwd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd: str = '/'\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.env","title":"env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>env: dict[str, str] = {}\n</code></pre> <p>Environment variables to set in the container.</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.forward_env","title":"forward_env  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>forward_env: list[str] = []\n</code></pre> <p>Environment variables to forward to the container.</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 30\n</code></pre> <p>Timeout for executing commands in the container.</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.executable","title":"executable  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>executable: str = getenv(\n    \"MSWEA_SINGULARITY_EXECUTABLE\", \"singularity\"\n)\n</code></pre> <p>Path to the singularity executable.</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.sandbox_build_retries","title":"sandbox_build_retries  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sandbox_build_retries: int = 3\n</code></pre> <p>Number of retries for building the sandbox if an error occurs.</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.global_args","title":"global_args  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>global_args: list[str] = ['--quiet']\n</code></pre> <p>Global arguments passed before the subcommand (e.g., --quiet, --debug).</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironmentConfig.exec_args","title":"exec_args  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>exec_args: list[str] = [\n    \"--contain\",\n    \"--cleanenv\",\n    \"--fakeroot\",\n]\n</code></pre> <p>Arguments passed to <code>singularity exec</code>.</p>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment","title":"SingularityEnvironment","text":"<pre><code>SingularityEnvironment(\n    *,\n    config_class: type = SingularityEnvironmentConfig,\n    logger: Logger | None = None,\n    **kwargs,\n)\n</code></pre> <p>Singularity environment. See <code>SingularityEnvironmentConfig</code> for kwargs.</p> Source code in <code>src/minisweagent/environments/singularity.py</code> <pre><code>def __init__(\n    self, *, config_class: type = SingularityEnvironmentConfig, logger: logging.Logger | None = None, **kwargs\n):\n    \"\"\"Singularity environment. See `SingularityEnvironmentConfig` for kwargs.\"\"\"\n    self.logger = logger or logging.getLogger(\"minisweagent.environment\")\n    self.config = config_class(**kwargs)\n    self.sandbox_dir = self._build_sandbox()\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = logger or getLogger('minisweagent.environment')\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.sandbox_dir","title":"sandbox_dir  <code>instance-attribute</code>","text":"<pre><code>sandbox_dir = _build_sandbox()\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/environments/singularity.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return recursive_merge(self.config.model_dump(), kwargs)\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/environments/singularity.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"environment\": self.config.model_dump(mode=\"json\"),\n                \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            }\n        }\n    }\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.execute","title":"execute","text":"<pre><code>execute(\n    action: dict,\n    cwd: str = \"\",\n    *,\n    timeout: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Execute a command in a Singularity container and return the result as a dict.</p> Source code in <code>src/minisweagent/environments/singularity.py</code> <pre><code>def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n    \"\"\"Execute a command in a Singularity container and return the result as a dict.\"\"\"\n    command = action.get(\"command\", \"\")\n    cmd = [self.config.executable, *self.config.global_args, \"exec\", *self.config.exec_args]\n\n    work_dir = cwd or self.config.cwd\n    if work_dir and work_dir != \"/\":\n        cmd.extend([\"--pwd\", work_dir])\n\n    for key in self.config.forward_env:\n        if (value := os.getenv(key)) is not None:\n            cmd.extend([\"--env\", f\"{key}={value}\"])\n    for key, value in self.config.env.items():\n        cmd.extend([\"--env\", f\"{key}={value}\"])\n\n    cmd.extend([\"--writable\", str(self.sandbox_dir), \"bash\", \"-c\", command])\n    try:\n        result = subprocess.run(\n            cmd,\n            text=True,\n            timeout=timeout or self.config.timeout,\n            encoding=\"utf-8\",\n            errors=\"replace\",\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        output = {\"output\": result.stdout, \"returncode\": result.returncode, \"exception_info\": \"\"}\n    except Exception as e:\n        raw_output = getattr(e, \"output\", None)\n        raw_output = (\n            raw_output.decode(\"utf-8\", errors=\"replace\") if isinstance(raw_output, bytes) else (raw_output or \"\")\n        )\n        output = {\n            \"output\": raw_output,\n            \"returncode\": -1,\n            \"exception_info\": f\"An error occurred while executing the command: {e}\",\n            \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n        }\n    self._check_finished(output)\n    return output\n</code></pre>"},{"location":"reference/environments/singularity/#minisweagent.environments.singularity.SingularityEnvironment.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> Source code in <code>src/minisweagent/environments/singularity.py</code> <pre><code>def cleanup(self):\n    shutil.rmtree(self.sandbox_dir, ignore_errors=True)\n</code></pre>"},{"location":"reference/environments/swerex_docker/","title":"SwerexDockerEnvironment","text":""},{"location":"reference/environments/swerex_docker/#swe-rex-docker","title":"SWE-rex Docker","text":"<p>SWE-rex Docker Environment class</p> <ul> <li>Read on GitHub</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker","title":"minisweagent.environments.extra.swerex_docker","text":""},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironmentConfig","title":"SwerexDockerEnvironmentConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironmentConfig.image","title":"image  <code>instance-attribute</code>","text":"<pre><code>image: str\n</code></pre>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironmentConfig.cwd","title":"cwd  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cwd: str = '/'\n</code></pre> <p>Working directory in which to execute commands.</p>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironmentConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: int = 30\n</code></pre> <p>Timeout for executing commands in the container.</p>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironmentConfig.deployment_extra_kwargs","title":"deployment_extra_kwargs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>deployment_extra_kwargs: dict[str, Any] = {}\n</code></pre> <p>Extra kwargs to pass to DockerDeployment.</p>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironment","title":"SwerexDockerEnvironment","text":"<pre><code>SwerexDockerEnvironment(**kwargs)\n</code></pre> <p>This class executes bash commands in a Docker container using SWE-ReX for sandboxing.</p> Source code in <code>src/minisweagent/environments/extra/swerex_docker.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"This class executes bash commands in a Docker container using SWE-ReX for sandboxing.\"\"\"\n    self.config = SwerexDockerEnvironmentConfig(**kwargs)\n    self.deployment = DockerDeployment(image=self.config.image, **self.config.deployment_extra_kwargs)\n    asyncio.run(self.deployment.start())\n</code></pre>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironment.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = SwerexDockerEnvironmentConfig(**kwargs)\n</code></pre>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironment.deployment","title":"deployment  <code>instance-attribute</code>","text":"<pre><code>deployment = DockerDeployment(\n    image=image, **(deployment_extra_kwargs)\n)\n</code></pre>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironment.execute","title":"execute","text":"<pre><code>execute(\n    action: dict,\n    cwd: str = \"\",\n    *,\n    timeout: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Execute a command in the environment and return the raw output.</p> Source code in <code>src/minisweagent/environments/extra/swerex_docker.py</code> <pre><code>def execute(self, action: dict, cwd: str = \"\", *, timeout: int | None = None) -&gt; dict[str, Any]:\n    \"\"\"Execute a command in the environment and return the raw output.\"\"\"\n    command = action.get(\"command\", \"\")\n    try:\n        result = asyncio.run(\n            self.deployment.runtime.execute(\n                RexCommand(\n                    command=command,\n                    shell=True,\n                    check=False,\n                    cwd=cwd or self.config.cwd,\n                    timeout=timeout or self.config.timeout,\n                    merge_output_streams=True,\n                )\n            )\n        )\n        output = {\"output\": result.stdout, \"returncode\": result.exit_code, \"exception_info\": \"\"}\n    except Exception as e:\n        output = {\n            \"output\": str(e) if str(e) else \"\",\n            \"returncode\": -1,\n            \"exception_info\": f\"An error occurred while executing the command: {e}\",\n            \"extra\": {\"exception_type\": type(e).__name__, \"exception\": str(e)},\n        }\n    self._check_finished(output)\n    return output\n</code></pre>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironment.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/environments/extra/swerex_docker.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return recursive_merge(self.config.model_dump(), kwargs)\n</code></pre>"},{"location":"reference/environments/swerex_docker/#minisweagent.environments.extra.swerex_docker.SwerexDockerEnvironment.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/environments/extra/swerex_docker.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"environment\": self.config.model_dump(mode=\"json\"),\n                \"environment_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            }\n        }\n    }\n</code></pre>"},{"location":"reference/environments/swerex_modal/","title":"SWE-ReX Modal","text":""},{"location":"reference/environments/swerex_modal/#swe-rex-modal","title":"SWE-ReX Modal","text":"<p>SWE-ReX Modal Environment class</p> <ul> <li>Read on GitHub</li> <li>Requires Modal account and authentication</li> </ul> <p>This environment executes commands in Modal sandboxes using SWE-ReX.</p>"},{"location":"reference/environments/swerex_modal/#setup","title":"Setup","text":"<ol> <li> <p>Install the full dependencies:    </p><pre><code>pip install \"mini-swe-agent[full]\"\n</code></pre><p></p> </li> <li> <p>Set up Modal authentication:    </p><pre><code>modal setup\n</code></pre><p></p> </li> </ol>"},{"location":"reference/environments/swerex_modal/#usage","title":"Usage","text":"<p>Evaluate GPT-5 mini on SWE-bench using Modal: </p><pre><code>mini-extra swebench \\\n    --config src/minisweagent/config/extra/swebench_modal.yaml \\\n    --subset verified \\\n    --split test \\\n    --workers 100 \\\n    -o ./results/gpt5-mini-modal\n</code></pre><p></p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/extra/","title":"Extra Models","text":""},{"location":"reference/models/extra/#extra-models","title":"Extra Models","text":"<p>Extra Models</p> <ul> <li>Read roulette.py on GitHub</li> </ul> <p>These are advanced \"meta-models\" that combine or modify the behavior of other models.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette","title":"minisweagent.models.extra.roulette","text":""},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModelConfig","title":"RouletteModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModelConfig.model_kwargs","title":"model_kwargs  <code>instance-attribute</code>","text":"<pre><code>model_kwargs: list[dict]\n</code></pre> <p>The models to choose from</p>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModelConfig.model_name","title":"model_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_name: str = 'roulette'\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel","title":"RouletteModel","text":"<pre><code>RouletteModel(\n    *, config_class: type = RouletteModelConfig, **kwargs\n)\n</code></pre> <p>This \"meta\"-model randomly selects one of the models at every call</p> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def __init__(self, *, config_class: type = RouletteModelConfig, **kwargs):\n    \"\"\"This \"meta\"-model randomly selects one of the models at every call\"\"\"\n    self.config = config_class(**kwargs)\n    self.models = [get_model(config=config) for config in self.config.model_kwargs]\n    self._n_calls = 0\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel.models","title":"models  <code>instance-attribute</code>","text":"<pre><code>models = [\n    (get_model(config=config)) for config in (model_kwargs)\n]\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel.select_model","title":"select_model","text":"<pre><code>select_model() -&gt; Model\n</code></pre> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def select_model(self) -&gt; Model:\n    return random.choice(self.models)\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel.query","title":"query","text":"<pre><code>query(*args, **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def query(self, *args, **kwargs) -&gt; dict:\n    model = self.select_model()\n    self._n_calls += 1\n    response = model.query(*args, **kwargs)\n    response[\"model_name\"] = model.config.model_name\n    return response\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.RouletteModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.InterleavingModelConfig","title":"InterleavingModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.InterleavingModelConfig.model_kwargs","title":"model_kwargs  <code>instance-attribute</code>","text":"<pre><code>model_kwargs: list[dict]\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.InterleavingModelConfig.sequence","title":"sequence  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sequence: list[int] | None = None\n</code></pre> <p>If set to 0, 0, 1, we will return the first model 2 times, then the second model 1 time, then the first model again, etc.</p>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.InterleavingModelConfig.model_name","title":"model_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_name: str = 'interleaving'\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.InterleavingModel","title":"InterleavingModel","text":"<pre><code>InterleavingModel(\n    *,\n    config_class: type = InterleavingModelConfig,\n    **kwargs,\n)\n</code></pre> <p>               Bases: <code>RouletteModel</code></p> <p>This \"meta\"-model alternates between the models in the sequence for every call</p> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def __init__(self, *, config_class: type = InterleavingModelConfig, **kwargs):\n    \"\"\"This \"meta\"-model alternates between the models in the sequence for every call\"\"\"\n    super().__init__(config_class=config_class, **kwargs)\n</code></pre>"},{"location":"reference/models/extra/#minisweagent.models.extra.roulette.InterleavingModel.select_model","title":"select_model","text":"<pre><code>select_model() -&gt; Model\n</code></pre> Source code in <code>src/minisweagent/models/extra/roulette.py</code> <pre><code>def select_model(self) -&gt; Model:\n    if self.config.sequence is None:\n        i_model = self._n_calls % len(self.models)\n    else:\n        i_model = self.config.sequence[self._n_calls % len(self.config.sequence)]\n    return self.models[i_model]\n</code></pre>"},{"location":"reference/models/litellm/","title":"LitellmModel","text":""},{"location":"reference/models/litellm/#litellm-model","title":"Litellm Model","text":"<p>LiteLLM Model class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import json\nimport logging\nimport os\nimport time\nfrom collections.abc import Callable\nfrom pathlib import Path\nfrom typing import Any, Literal\n\nimport litellm\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_toolcall import (\n    BASH_TOOL,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions,\n)\nfrom minisweagent.models.utils.anthropic_utils import _reorder_anthropic_thinking_blocks\nfrom minisweagent.models.utils.cache_control import set_cache_control\nfrom minisweagent.models.utils.openai_multimodal import expand_multimodal_content\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"litellm_model\")\n\n# Fields from model_dump() that are safe to pass through to the API.\n# Litellm-internal fields (e.g., provider_specific_fields) are stripped.\n_KNOWN_MESSAGE_FIELDS = {\n    \"role\", \"content\", \"name\", \"tool_calls\", \"tool_call_id\", \"function_call\",\n    \"refusal\", \"audio\", \"annotations\",\n}\n\n# Roles accepted by the OpenAI chat completions API.\n# Messages with other roles (e.g., \"exit\") are internal to mini-swe-agent\n# and must be filtered before sending to the API.  The OpenAI SDK's Pydantic\n# Union discriminator serializes unrecognised roles as ``null``, which causes\n# \"Invalid type for 'messages[N]': expected an object, but got null\" errors.\n_VALID_API_ROLES = {\"system\", \"user\", \"assistant\", \"tool\", \"function\", \"developer\"}\n\n\ndef _diagnose_null_messages(messages: list) -&gt; None:\n    \"\"\"Log diagnostic info when a null-message BadRequestError occurs.\"\"\"\n    import json as _json\n\n    logger.error(\"=== NULL MESSAGE DIAGNOSTIC ===\")\n    logger.error(\"Total messages: %d\", len(messages))\n    for i, msg in enumerate(messages):\n        if msg is None:\n            logger.error(\"  messages[%d] = NULL\", i)\n        elif not isinstance(msg, dict):\n            logger.error(\"  messages[%d] = type=%s value=%r\", i, type(msg).__name__, msg)\n        else:\n            role = msg.get(\"role\", \"&lt;missing&gt;\")\n            has_content = \"content\" in msg\n            content_val = msg.get(\"content\")\n            content_repr = repr(content_val)[:80] if content_val is not None else \"null\"\n            keys = sorted(msg.keys())\n            logger.error(\n                \"  messages[%d] = role=%s, has_content=%s, content=%s, keys=%s\",\n                i, role, has_content, content_repr, keys,\n            )\n    # Also dump the raw JSON to a temp file for inspection\n    try:\n        import tempfile\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\"_null_msg_debug.json\", delete=False, prefix=\"litellm_\") as f:\n            _json.dump(messages, f, indent=2, default=str)\n            logger.error(\"Full messages dumped to: %s\", f.name)\n    except Exception:\n        pass\n    logger.error(\"=== END DIAGNOSTIC ===\")\n\n\ndef _sanitize_message(msg: dict) -&gt; dict:\n    \"\"\"Clean a message dict for API submission.\n\n    - Strips the ``extra`` key (internal to mini-swe-agent).\n    - Strips unknown/litellm-internal keys (e.g., ``provider_specific_fields``).\n    - Removes keys whose value is ``None`` **except** ``content`` (which is\n      legitimately ``None`` for assistant messages that only carry tool_calls).\n    - Deep-sanitizes ``tool_calls`` to remove Pydantic artifacts.\n    \"\"\"\n    out: dict = {}\n    for k, v in msg.items():\n        if k == \"extra\":\n            continue\n        if k not in _KNOWN_MESSAGE_FIELDS:\n            continue\n        # Keep content even when None (valid for assistant tool_call messages)\n        if v is None and k != \"content\":\n            continue\n        out[k] = v\n    # Deep-sanitize tool_calls: strip None values and Pydantic internals\n    if \"tool_calls\" in out and isinstance(out[\"tool_calls\"], list):\n        out[\"tool_calls\"] = _sanitize_tool_calls(out[\"tool_calls\"])\n    return out\n\n\ndef _sanitize_tool_calls(tool_calls: list) -&gt; list:\n    \"\"\"Deep-clean tool_calls list for API submission.\n\n    Ensures each tool call is a plain dict with only known fields,\n    preventing Pydantic serialization artifacts from causing API errors.\n    \"\"\"\n    _KNOWN_TC_FIELDS = {\"id\", \"type\", \"function\", \"index\"}\n    _KNOWN_FN_FIELDS = {\"name\", \"arguments\"}\n    cleaned = []\n    for tc in tool_calls:\n        if tc is None:\n            continue\n        if not isinstance(tc, dict):\n            # Convert Pydantic models to dicts\n            tc = tc.model_dump() if hasattr(tc, \"model_dump\") else dict(tc)\n        out = {k: v for k, v in tc.items() if k in _KNOWN_TC_FIELDS and v is not None}\n        # Ensure function sub-dict is also clean\n        fn = out.get(\"function\")\n        if isinstance(fn, dict):\n            out[\"function\"] = {k: v for k, v in fn.items() if k in _KNOWN_FN_FIELDS}\n        cleaned.append(out)\n    return cleaned\n\n\nclass LitellmModelConfig(BaseModel):\n    model_name: str\n    \"\"\"Model name. Highly recommended to include the provider in the model name, e.g., `anthropic/claude-sonnet-4-5-20250929`.\"\"\"\n    model_kwargs: dict[str, Any] = {}\n    \"\"\"Additional arguments passed to the API.\"\"\"\n    litellm_model_registry: Path | str | None = os.getenv(\"LITELLM_MODEL_REGISTRY_PATH\")\n    \"\"\"Model registry for cost tracking and model metadata. See the local model guide (https://mini-swe-agent.com/latest/models/local_models/) for more details.\"\"\"\n    set_cache_control: Literal[\"default_end\"] | None = None\n    \"\"\"Set explicit cache control markers, for example for Anthropic models\"\"\"\n    cost_tracking: Literal[\"default\", \"ignore_errors\"] = os.getenv(\"MSWEA_COST_TRACKING\", \"default\")\n    \"\"\"Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)\"\"\"\n    format_error_template: str = \"{{ error }}\"\n    \"\"\"Template used when the LM's output is not in the expected format.\"\"\"\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass LitellmModel:\n    abort_exceptions: list[type[Exception]] = [\n        litellm.exceptions.UnsupportedParamsError,\n        litellm.exceptions.NotFoundError,\n        litellm.exceptions.PermissionDeniedError,\n        litellm.exceptions.ContextWindowExceededError,\n        litellm.exceptions.AuthenticationError,\n        litellm.exceptions.BadRequestError,\n        KeyboardInterrupt,\n    ]\n\n    def __init__(self, *, config_class: Callable = LitellmModelConfig, **kwargs):\n        self.config = config_class(**kwargs)\n        if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n            litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        # Final defense: filter any null entries that slipped through\n        n_before = len(messages)\n        messages = [m for m in messages if m is not None and isinstance(m, dict)]\n        if len(messages) != n_before:\n            logger.warning(\n                \"Filtered %d invalid entries from %d messages before API call\",\n                n_before - len(messages), n_before,\n            )\n        try:\n            return litellm.completion(\n                model=self.config.model_name,\n                messages=messages,\n                tools=[BASH_TOOL],\n                **(self.config.model_kwargs | kwargs),\n            )\n        except litellm.exceptions.AuthenticationError as e:\n            e.message += \" You can permanently set your API key with `mini-extra config set KEY VALUE`.\"\n            raise e\n        except litellm.exceptions.BadRequestError as e:\n            if \"got null\" in str(e):\n                _diagnose_null_messages(messages)\n            raise\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        prepared = []\n        for msg in messages:\n            if msg is None:\n                continue\n            # Skip messages with non-API roles (e.g., \"exit\") \u2014 the OpenAI SDK\n            # serializes unrecognised roles as null, causing API errors.\n            if msg.get(\"role\") not in _VALID_API_ROLES:\n                continue\n            prepared.append(_sanitize_message(msg))\n        prepared = _reorder_anthropic_thinking_blocks(prepared)\n        return set_cache_control(prepared, mode=self.config.set_cache_control)\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = response.choices[0].message.model_dump()\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            \"response\": response.model_dump(),\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _calculate_cost(self, response) -&gt; dict[str, float]:\n        try:\n            cost = litellm.cost_calculator.completion_cost(response, model=self.config.model_name)\n            if cost &lt;= 0.0:\n                raise ValueError(f\"Cost must be &gt; 0.0, got {cost}\")\n        except Exception as e:\n            cost = 0.0\n            if self.config.cost_tracking != \"ignore_errors\":\n                msg = (\n                    f\"Error calculating cost for model {self.config.model_name}: {e}, perhaps it's not registered? \"\n                    \"You can ignore this issue from your config file with cost_tracking: 'ignore_errors' or \"\n                    \"globally with export MSWEA_COST_TRACKING='ignore_errors'. \"\n                    \"Alternatively check the 'Cost tracking' section in the documentation at \"\n                    \"https://klieret.short.gy/mini-local-models. \"\n                    \" Still stuck? Please open a github issue at https://github.com/SWE-agent/mini-swe-agent/issues/new/choose!\"\n                )\n                logger.critical(msg)\n                raise RuntimeError(msg) from e\n        return {\"cost\": cost}\n\n    def _parse_actions(self, response) -&gt; list[dict]:\n        \"\"\"Parse tool calls from the response. Raises FormatError if unknown tool.\"\"\"\n        tool_calls = response.choices[0].message.tool_calls or []\n        return parse_toolcall_actions(tool_calls, format_error_template=self.config.format_error_template)\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n</code></pre> <p>Guides</p> <ul> <li>Setting up most models is covered in the quickstart guide.</li> <li>If you want to use local models, please check this guide.</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model","title":"minisweagent.models.litellm_model","text":""},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('litellm_model')\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig","title":"LitellmModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name: str\n</code></pre> <p>Model name. Highly recommended to include the provider in the model name, e.g., <code>anthropic/claude-sonnet-4-5-20250929</code>.</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.model_kwargs","title":"model_kwargs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_kwargs: dict[str, Any] = {}\n</code></pre> <p>Additional arguments passed to the API.</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.litellm_model_registry","title":"litellm_model_registry  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_model_registry: Path | str | None = getenv(\n    \"LITELLM_MODEL_REGISTRY_PATH\"\n)\n</code></pre> <p>Model registry for cost tracking and model metadata. See the local model guide (https://mini-swe-agent.com/latest/models/local_models/) for more details.</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.set_cache_control","title":"set_cache_control  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_cache_control: Literal['default_end'] | None = None\n</code></pre> <p>Set explicit cache control markers, for example for Anthropic models</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.cost_tracking","title":"cost_tracking  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_tracking: Literal[\"default\", \"ignore_errors\"] = getenv(\n    \"MSWEA_COST_TRACKING\", \"default\"\n)\n</code></pre> <p>Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.format_error_template","title":"format_error_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>format_error_template: str = '{{ error }}'\n</code></pre> <p>Template used when the LM's output is not in the expected format.</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel","title":"LitellmModel","text":"<pre><code>LitellmModel(\n    *, config_class: Callable = LitellmModelConfig, **kwargs\n)\n</code></pre> Source code in <code>src/minisweagent/models/litellm_model.py</code> <pre><code>def __init__(self, *, config_class: Callable = LitellmModelConfig, **kwargs):\n    self.config = config_class(**kwargs)\n    if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n        litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.abort_exceptions","title":"abort_exceptions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>abort_exceptions: list[type[Exception]] = [\n    UnsupportedParamsError,\n    NotFoundError,\n    PermissionDeniedError,\n    ContextWindowExceededError,\n    AuthenticationError,\n    BadRequestError,\n    KeyboardInterrupt,\n]\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/litellm_model.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n        with attempt:\n            response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n    cost_output = self._calculate_cost(response)\n    GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n    message = response.choices[0].message.model_dump()\n    message[\"extra\"] = {\n        \"actions\": self._parse_actions(response),\n        \"response\": response.model_dump(),\n        **cost_output,\n        \"timestamp\": time.time(),\n    }\n    return message\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/litellm_model.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/litellm_model.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/litellm_model.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/litellm/#minisweagent.models.litellm_model.LitellmModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/litellm_model.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/litellm_response_toolcall/","title":"LitellmResponseModel","text":""},{"location":"reference/models/litellm_response_toolcall/#litellm-response-model","title":"Litellm Response Model","text":"<p>LiteLLM Response API Model class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import logging\nimport time\nfrom collections.abc import Callable\n\nimport litellm\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.litellm_model import LitellmModel, LitellmModelConfig\nfrom minisweagent.models.utils.actions_toolcall_response import (\n    BASH_TOOL_RESPONSE_API,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions_response,\n)\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"litellm_response_model\")\n\n\nclass LitellmResponseModelConfig(LitellmModelConfig):\n    pass\n\n\nclass LitellmResponseModel(LitellmModel):\n    def __init__(self, *, config_class: Callable = LitellmResponseModelConfig, **kwargs):\n        super().__init__(config_class=config_class, **kwargs)\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        \"\"\"Flatten response objects into their output items for stateless API calls.\"\"\"\n        result = []\n        for msg in messages:\n            if msg is None:\n                continue\n            if msg.get(\"object\") == \"response\":\n                for item in msg.get(\"output\", []):\n                    if item is not None:\n                        result.append({k: v for k, v in item.items() if k != \"extra\"})\n            else:\n                result.append({k: v for k, v in msg.items() if k != \"extra\"})\n        return result\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        # Final defense: filter any null/invalid entries\n        messages = [m for m in messages if m is not None and isinstance(m, dict)]\n        try:\n            return litellm.responses(\n                model=self.config.model_name,\n                input=messages,\n                tools=[BASH_TOOL_RESPONSE_API],\n                **(self.config.model_kwargs | kwargs),\n            )\n        except litellm.exceptions.AuthenticationError as e:\n            e.message += \" You can permanently set your API key with `mini-extra config set KEY VALUE`.\"\n            raise e\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = response.model_dump() if hasattr(response, \"model_dump\") else dict(response)\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _parse_actions(self, response) -&gt; list[dict]:\n        return parse_toolcall_actions_response(\n            getattr(response, \"output\", []), format_error_template=self.config.format_error_template\n        )\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n</code></pre> <p>When to use this model</p> <ul> <li>Use this model class when you want to use OpenAI's Responses API with native tool calling.</li> <li>This is particularly useful for models like GPT-5 that benefit from the extended thinking/reasoning capabilities provided by the Responses API.</li> <li>This model maintains conversation state across turns using <code>previous_response_id</code>.</li> </ul>"},{"location":"reference/models/litellm_response_toolcall/#usage","title":"Usage","text":"<p>To use the Response API model, specify <code>model_class: \"litellm_response\"</code> in your agent config:</p> <pre><code>model:\n  model_class: \"litellm_response\"\n  model_name: \"openai/gpt-5.2\"\n  model_kwargs:\n    drop_params: true\n    reasoning:\n      effort: \"high\"\n</code></pre> <p>Or via command line:</p> <pre><code>mini -m \"openai/gpt-5.2\" --model-class litellm_response\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/litellm_response_toolcall/#minisweagent.models.litellm_response_model","title":"minisweagent.models.litellm_response_model","text":""},{"location":"reference/models/litellm_response_toolcall/#minisweagent.models.litellm_response_model.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('litellm_response_model')\n</code></pre>"},{"location":"reference/models/litellm_response_toolcall/#minisweagent.models.litellm_response_model.LitellmResponseModelConfig","title":"LitellmResponseModelConfig","text":"<p>               Bases: <code>LitellmModelConfig</code></p>"},{"location":"reference/models/litellm_response_toolcall/#minisweagent.models.litellm_response_model.LitellmResponseModel","title":"LitellmResponseModel","text":"<pre><code>LitellmResponseModel(\n    *,\n    config_class: Callable = LitellmResponseModelConfig,\n    **kwargs,\n)\n</code></pre> <p>               Bases: <code>LitellmModel</code></p> Source code in <code>src/minisweagent/models/litellm_response_model.py</code> <pre><code>def __init__(self, *, config_class: Callable = LitellmResponseModelConfig, **kwargs):\n    super().__init__(config_class=config_class, **kwargs)\n</code></pre>"},{"location":"reference/models/litellm_response_toolcall/#minisweagent.models.litellm_response_model.LitellmResponseModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/litellm_response_model.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n        with attempt:\n            response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n    cost_output = self._calculate_cost(response)\n    GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n    message = response.model_dump() if hasattr(response, \"model_dump\") else dict(response)\n    message[\"extra\"] = {\n        \"actions\": self._parse_actions(response),\n        **cost_output,\n        \"timestamp\": time.time(),\n    }\n    return message\n</code></pre>"},{"location":"reference/models/litellm_response_toolcall/#minisweagent.models.litellm_response_model.LitellmResponseModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/litellm_response_model.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/openrouter/","title":"OpenRouterModel","text":""},{"location":"reference/models/openrouter/#openrouter-model","title":"OpenRouter Model","text":"<p>OpenRouter Model class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import json\nimport logging\nimport os\nimport time\nfrom typing import Any, Literal\n\nimport requests\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_toolcall import (\n    BASH_TOOL,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions,\n)\nfrom minisweagent.models.utils.anthropic_utils import _reorder_anthropic_thinking_blocks\nfrom minisweagent.models.utils.cache_control import set_cache_control\nfrom minisweagent.models.utils.openai_multimodal import expand_multimodal_content\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"openrouter_model\")\n\n\nclass OpenRouterModelConfig(BaseModel):\n    model_name: str\n    model_kwargs: dict[str, Any] = {}\n    set_cache_control: Literal[\"default_end\"] | None = None\n    \"\"\"Set explicit cache control markers, for example for Anthropic models\"\"\"\n    cost_tracking: Literal[\"default\", \"ignore_errors\"] = os.getenv(\"MSWEA_COST_TRACKING\", \"default\")\n    \"\"\"Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)\"\"\"\n    format_error_template: str = \"{{ error }}\"\n    \"\"\"Template used when the LM's output is not in the expected format.\"\"\"\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass OpenRouterAPIError(Exception):\n    \"\"\"Custom exception for OpenRouter API errors.\"\"\"\n\n\nclass OpenRouterAuthenticationError(Exception):\n    \"\"\"Custom exception for OpenRouter authentication errors.\"\"\"\n\n\nclass OpenRouterRateLimitError(Exception):\n    \"\"\"Custom exception for OpenRouter rate limit errors.\"\"\"\n\n\nclass OpenRouterModel:\n    abort_exceptions: list[type[Exception]] = [OpenRouterAuthenticationError, KeyboardInterrupt]\n\n    def __init__(self, **kwargs):\n        self.config = OpenRouterModelConfig(**kwargs)\n        self._api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n        self._api_key = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        headers = {\n            \"Authorization\": f\"Bearer {self._api_key}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        payload = {\n            \"model\": self.config.model_name,\n            \"messages\": messages,\n            \"tools\": [BASH_TOOL],\n            \"usage\": {\"include\": True},\n            **(self.config.model_kwargs | kwargs),\n        }\n\n        try:\n            response = requests.post(self._api_url, headers=headers, data=json.dumps(payload), timeout=60)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.HTTPError as e:\n            if response.status_code == 401:\n                error_msg = \"Authentication failed. You can permanently set your API key with `mini-extra config set OPENROUTER_API_KEY YOUR_KEY`.\"\n                raise OpenRouterAuthenticationError(error_msg) from e\n            elif response.status_code == 429:\n                raise OpenRouterRateLimitError(\"Rate limit exceeded\") from e\n            else:\n                raise OpenRouterAPIError(f\"HTTP {response.status_code}: {response.text}\") from e\n        except requests.exceptions.RequestException as e:\n            raise OpenRouterAPIError(f\"Request failed: {e}\") from e\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        prepared = [{k: v for k, v in msg.items() if k != \"extra\"} for msg in messages]\n        prepared = _reorder_anthropic_thinking_blocks(prepared)\n        return set_cache_control(prepared, mode=self.config.set_cache_control)\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = dict(response[\"choices\"][0][\"message\"])\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            \"response\": response,\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _calculate_cost(self, response) -&gt; dict[str, float]:\n        usage = response.get(\"usage\", {})\n        cost = usage.get(\"cost\", 0.0)\n        if cost &lt;= 0.0 and self.config.cost_tracking != \"ignore_errors\":\n            raise RuntimeError(\n                f\"No valid cost information available from OpenRouter API for model {self.config.model_name}: \"\n                f\"Usage {usage}, cost {cost}. Cost must be &gt; 0.0. Set cost_tracking: 'ignore_errors' in your config file or \"\n                \"export MSWEA_COST_TRACKING='ignore_errors' to ignore cost tracking errors \"\n                \"(for example for free/local models), more information at https://klieret.short.gy/mini-local-models \"\n                \"for more details. Still stuck? Please open a github issue at https://github.com/SWE-agent/mini-swe-agent/issues/new/choose!\"\n            )\n        return {\"cost\": cost}\n\n    def _parse_actions(self, response: dict) -&gt; list[dict]:\n        \"\"\"Parse tool calls from the response. Raises FormatError if unknown tool.\"\"\"\n        tool_calls = response[\"choices\"][0][\"message\"].get(\"tool_calls\") or []\n        tool_calls = [_DictToObj(tc) for tc in tool_calls]\n        return parse_toolcall_actions(tool_calls, format_error_template=self.config.format_error_template)\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n\n\nclass _DictToObj:\n    \"\"\"Simple wrapper to convert dict to object with attribute access.\"\"\"\n\n    def __init__(self, d: dict):\n        self._d = d\n        self.id = d.get(\"id\")\n        self.function = _DictToObj(d.get(\"function\", {})) if \"function\" in d else None\n        self.name = d.get(\"name\")\n        self.arguments = d.get(\"arguments\")\n</code></pre> <p>Guide</p> <p>Setting up OpenRouter models is covered in the quickstart guide.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model","title":"minisweagent.models.openrouter_model","text":""},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('openrouter_model')\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig","title":"OpenRouterModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name: str\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.model_kwargs","title":"model_kwargs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_kwargs: dict[str, Any] = {}\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.set_cache_control","title":"set_cache_control  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_cache_control: Literal['default_end'] | None = None\n</code></pre> <p>Set explicit cache control markers, for example for Anthropic models</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.cost_tracking","title":"cost_tracking  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_tracking: Literal[\"default\", \"ignore_errors\"] = getenv(\n    \"MSWEA_COST_TRACKING\", \"default\"\n)\n</code></pre> <p>Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.format_error_template","title":"format_error_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>format_error_template: str = '{{ error }}'\n</code></pre> <p>Template used when the LM's output is not in the expected format.</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterAPIError","title":"OpenRouterAPIError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for OpenRouter API errors.</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterAuthenticationError","title":"OpenRouterAuthenticationError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for OpenRouter authentication errors.</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterRateLimitError","title":"OpenRouterRateLimitError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for OpenRouter rate limit errors.</p>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel","title":"OpenRouterModel","text":"<pre><code>OpenRouterModel(**kwargs)\n</code></pre> Source code in <code>src/minisweagent/models/openrouter_model.py</code> <pre><code>def __init__(self, **kwargs):\n    self.config = OpenRouterModelConfig(**kwargs)\n    self._api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n    self._api_key = os.getenv(\"OPENROUTER_API_KEY\", \"\")\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.abort_exceptions","title":"abort_exceptions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>abort_exceptions: list[type[Exception]] = [\n    OpenRouterAuthenticationError,\n    KeyboardInterrupt,\n]\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = OpenRouterModelConfig(**kwargs)\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/openrouter_model.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n        with attempt:\n            response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n    cost_output = self._calculate_cost(response)\n    GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n    message = dict(response[\"choices\"][0][\"message\"])\n    message[\"extra\"] = {\n        \"actions\": self._parse_actions(response),\n        \"response\": response,\n        **cost_output,\n        \"timestamp\": time.time(),\n    }\n    return message\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/openrouter_model.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/openrouter_model.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/openrouter_model.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/openrouter/#minisweagent.models.openrouter_model.OpenRouterModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/openrouter_model.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/overview/","title":"Overview","text":""},{"location":"reference/models/overview/#models-overview","title":"Models Overview","text":"<p>This page provides an overview of all available model classes in mini-SWE-agent.</p>"},{"location":"reference/models/overview/#model-classes","title":"Model Classes","text":"Class Shortcut Endpoint Toolcalls Description <code>LitellmModel</code> <code>litellm</code> <code>/completion</code> \u2705 Default model using LiteLLM for broad provider support (OpenAI, Anthropic, 100+ providers) <code>LitellmTextbasedModel</code> <code>litellm_textbased</code> <code>/completion</code> \u274c LiteLLM with text-based actions (no native tool calling) <code>LitellmResponseModel</code> <code>litellm_response</code> <code>/response</code> \u2705 LiteLLM with OpenAI Responses API and native tool calling <code>OpenRouterModel</code> <code>openrouter</code> <code>/completion</code> \u2705 OpenRouter API integration <code>OpenRouterTextbasedModel</code> <code>openrouter_textbased</code> <code>/completion</code> \u274c OpenRouter with text-based actions <code>OpenRouterResponseModel</code> <code>openrouter_response</code> <code>/response</code> \u2705 OpenRouter Responses API with native tool calling <code>PortkeyModel</code> <code>portkey</code> <code>/completion</code> \u2705 Portkey AI gateway integration <code>PortkeyResponseAPIModel</code> <code>portkey_response</code> <code>/response</code> \u2705 Portkey with Responses API support <code>RequestyModel</code> <code>requesty</code> <code>/completion</code> \u2705 Requesty API integration <code>DeterministicModel</code> <code>deterministic</code> N/A \u274c Returns predefined outputs (for testing) <code>RouletteModel</code> \u2014 Meta \u274c Randomly selects from multiple models <code>InterleavingModel</code> \u2014 Meta \u274c Alternates between models in sequence bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/portkey/","title":"Portkey Model","text":""},{"location":"reference/models/portkey/#portkey-model","title":"Portkey Model","text":"<p>Portkey Model class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import json\nimport logging\nimport os\nimport time\nfrom pathlib import Path\nfrom typing import Any, Literal\n\nimport litellm\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_toolcall import (\n    BASH_TOOL,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions,\n)\nfrom minisweagent.models.utils.anthropic_utils import _reorder_anthropic_thinking_blocks\nfrom minisweagent.models.utils.cache_control import set_cache_control\nfrom minisweagent.models.utils.openai_multimodal import expand_multimodal_content\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"portkey_model\")\n\ntry:\n    from portkey_ai import Portkey\nexcept ImportError:\n    raise ImportError(\n        \"The portkey-ai package is required to use PortkeyModel. Please install it with: pip install portkey-ai\"\n    )\n\n\nclass PortkeyModelConfig(BaseModel):\n    model_name: str\n    model_kwargs: dict[str, Any] = {}\n    provider: str = \"\"\n    \"\"\"The LLM provider to use (e.g., 'openai', 'anthropic', 'google').\n    If not specified, will be auto-detected from model_name.\n    Required by Portkey when not using a virtual key.\n    \"\"\"\n    litellm_model_registry: Path | str | None = os.getenv(\"LITELLM_MODEL_REGISTRY_PATH\")\n    \"\"\"We currently use litellm to calculate costs. Here you can register additional models to litellm's model registry.\n    Note that this might change if we get better support for Portkey and change how we calculate costs.\n    \"\"\"\n    litellm_model_name_override: str = \"\"\n    \"\"\"We currently use litellm to calculate costs. Here you can override the model name to use for litellm in case it\n    doesn't match the Portkey model name.\n    Note that this might change if we get better support for Portkey and change how we calculate costs.\n    \"\"\"\n    set_cache_control: Literal[\"default_end\"] | None = None\n    \"\"\"Set explicit cache control markers, for example for Anthropic models\"\"\"\n    cost_tracking: Literal[\"default\", \"ignore_errors\"] = os.getenv(\"MSWEA_COST_TRACKING\", \"default\")\n    \"\"\"Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)\"\"\"\n    format_error_template: str = \"{{ error }}\"\n    \"\"\"Template used when the LM's output is not in the expected format.\"\"\"\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass PortkeyModel:\n    abort_exceptions: list[type[Exception]] = [KeyboardInterrupt, TypeError, ValueError]\n\n    def __init__(self, *, config_class: type = PortkeyModelConfig, **kwargs):\n        self.config = config_class(**kwargs)\n        if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n            litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n\n        self._api_key = os.getenv(\"PORTKEY_API_KEY\")\n        if not self._api_key:\n            raise ValueError(\n                \"Portkey API key is required. Set it via the \"\n                \"PORTKEY_API_KEY environment variable. You can permanently set it with \"\n                \"`mini-extra config set PORTKEY_API_KEY YOUR_KEY`.\"\n            )\n\n        virtual_key = os.getenv(\"PORTKEY_VIRTUAL_KEY\")\n        client_kwargs = {\"api_key\": self._api_key}\n        if virtual_key:\n            client_kwargs[\"virtual_key\"] = virtual_key\n        elif self.config.provider:\n            # If no virtual key but provider is specified, pass it\n            client_kwargs[\"provider\"] = self.config.provider\n\n        self.client = Portkey(**client_kwargs)\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        return self.client.chat.completions.create(\n            model=self.config.model_name,\n            messages=messages,\n            tools=[BASH_TOOL],\n            **(self.config.model_kwargs | kwargs),\n        )\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        prepared = [{k: v for k, v in msg.items() if k != \"extra\"} for msg in messages]\n        prepared = _reorder_anthropic_thinking_blocks(prepared)\n        return set_cache_control(prepared, mode=self.config.set_cache_control)\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = response.choices[0].message.model_dump()\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            \"response\": response.model_dump(),\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _parse_actions(self, response) -&gt; list[dict]:\n        \"\"\"Parse tool calls from the response. Raises FormatError if unknown tool.\"\"\"\n        tool_calls = response.choices[0].message.tool_calls or []\n        return parse_toolcall_actions(tool_calls, format_error_template=self.config.format_error_template)\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n\n    def _calculate_cost(self, response) -&gt; dict[str, float]:\n        response_for_cost_calc = response.model_copy()\n        if self.config.litellm_model_name_override:\n            if response_for_cost_calc.model:\n                response_for_cost_calc.model = self.config.litellm_model_name_override\n        prompt_tokens = response_for_cost_calc.usage.prompt_tokens\n        if prompt_tokens is None:\n            logger.warning(\n                f\"Prompt tokens are None for model {self.config.model_name}. Setting to 0. Full response: {response_for_cost_calc.model_dump()}\"\n            )\n            prompt_tokens = 0\n        total_tokens = response_for_cost_calc.usage.total_tokens\n        completion_tokens = response_for_cost_calc.usage.completion_tokens\n        if completion_tokens is None:\n            logger.warning(\n                f\"Completion tokens are None for model {self.config.model_name}. Setting to 0. Full response: {response_for_cost_calc.model_dump()}\"\n            )\n            completion_tokens = 0\n        if total_tokens - prompt_tokens - completion_tokens != 0:\n            # This is most likely related to how portkey treats cached tokens: It doesn't count them towards the prompt tokens (?)\n            logger.warning(\n                f\"WARNING: Total tokens - prompt tokens - completion tokens != 0: {response_for_cost_calc.model_dump()}.\"\n                \" This is probably a portkey bug or incompatibility with litellm cost tracking. \"\n                \"Setting prompt tokens based on total tokens and completion tokens. You might want to double check your costs. \"\n                f\"Full response: {response_for_cost_calc.model_dump()}\"\n            )\n            response_for_cost_calc.usage.prompt_tokens = total_tokens - completion_tokens\n        try:\n            cost = litellm.cost_calculator.completion_cost(\n                response_for_cost_calc, model=self.config.litellm_model_name_override or None\n            )\n            assert cost &gt;= 0.0, f\"Cost is negative: {cost}\"\n        except Exception as e:\n            cost = 0.0\n            if self.config.cost_tracking != \"ignore_errors\":\n                msg = (\n                    f\"Error calculating cost for model {self.config.model_name} based on {response_for_cost_calc.model_dump()}: {e}. \"\n                    \"You can ignore this issue from your config file with cost_tracking: 'ignore_errors' or \"\n                    \"globally with export MSWEA_COST_TRACKING='ignore_errors' to ignore this error. \"\n                    \"Alternatively check the 'Cost tracking' section in the documentation at \"\n                    \"https://klieret.short.gy/mini-local-models. \"\n                    \"Still stuck? Please open a github issue at https://github.com/SWE-agent/mini-swe-agent/issues/new/choose!\"\n                )\n                logger.critical(msg)\n                raise RuntimeError(msg) from e\n        return {\"cost\": cost}\n</code></pre> <p>Guide</p> <p>Setting up Portkey models is covered in the quickstart guide.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model","title":"minisweagent.models.portkey_model","text":""},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('portkey_model')\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig","title":"PortkeyModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name: str\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.model_kwargs","title":"model_kwargs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_kwargs: dict[str, Any] = {}\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.provider","title":"provider  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>provider: str = ''\n</code></pre> <p>The LLM provider to use (e.g., 'openai', 'anthropic', 'google'). If not specified, will be auto-detected from model_name. Required by Portkey when not using a virtual key.</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.litellm_model_registry","title":"litellm_model_registry  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_model_registry: Path | str | None = getenv(\n    \"LITELLM_MODEL_REGISTRY_PATH\"\n)\n</code></pre> <p>We currently use litellm to calculate costs. Here you can register additional models to litellm's model registry. Note that this might change if we get better support for Portkey and change how we calculate costs.</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.litellm_model_name_override","title":"litellm_model_name_override  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_model_name_override: str = ''\n</code></pre> <p>We currently use litellm to calculate costs. Here you can override the model name to use for litellm in case it doesn't match the Portkey model name. Note that this might change if we get better support for Portkey and change how we calculate costs.</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.set_cache_control","title":"set_cache_control  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_cache_control: Literal['default_end'] | None = None\n</code></pre> <p>Set explicit cache control markers, for example for Anthropic models</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.cost_tracking","title":"cost_tracking  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_tracking: Literal[\"default\", \"ignore_errors\"] = getenv(\n    \"MSWEA_COST_TRACKING\", \"default\"\n)\n</code></pre> <p>Cost tracking mode for this model. Can be \"default\" or \"ignore_errors\" (ignore errors/missing cost info)</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.format_error_template","title":"format_error_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>format_error_template: str = '{{ error }}'\n</code></pre> <p>Template used when the LM's output is not in the expected format.</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel","title":"PortkeyModel","text":"<pre><code>PortkeyModel(\n    *, config_class: type = PortkeyModelConfig, **kwargs\n)\n</code></pre> Source code in <code>src/minisweagent/models/portkey_model.py</code> <pre><code>def __init__(self, *, config_class: type = PortkeyModelConfig, **kwargs):\n    self.config = config_class(**kwargs)\n    if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n        litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n\n    self._api_key = os.getenv(\"PORTKEY_API_KEY\")\n    if not self._api_key:\n        raise ValueError(\n            \"Portkey API key is required. Set it via the \"\n            \"PORTKEY_API_KEY environment variable. You can permanently set it with \"\n            \"`mini-extra config set PORTKEY_API_KEY YOUR_KEY`.\"\n        )\n\n    virtual_key = os.getenv(\"PORTKEY_VIRTUAL_KEY\")\n    client_kwargs = {\"api_key\": self._api_key}\n    if virtual_key:\n        client_kwargs[\"virtual_key\"] = virtual_key\n    elif self.config.provider:\n        # If no virtual key but provider is specified, pass it\n        client_kwargs[\"provider\"] = self.config.provider\n\n    self.client = Portkey(**client_kwargs)\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.abort_exceptions","title":"abort_exceptions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>abort_exceptions: list[type[Exception]] = [\n    KeyboardInterrupt,\n    TypeError,\n    ValueError,\n]\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config_class(**kwargs)\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.client","title":"client  <code>instance-attribute</code>","text":"<pre><code>client = Portkey(**client_kwargs)\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_model.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n        with attempt:\n            response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n    cost_output = self._calculate_cost(response)\n    GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n    message = response.choices[0].message.model_dump()\n    message[\"extra\"] = {\n        \"actions\": self._parse_actions(response),\n        \"response\": response.model_dump(),\n        **cost_output,\n        \"timestamp\": time.time(),\n    }\n    return message\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_model.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/portkey_model.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/portkey_model.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/portkey/#minisweagent.models.portkey_model.PortkeyModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_model.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/portkey_response/","title":"Portkey Response API Model","text":""},{"location":"reference/models/portkey_response/#portkey-response-api-model","title":"Portkey Response API Model","text":"<p>This model is used to use portkey with the OpenAI Responses API.</p> <p>Portkey Response API Model class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import json\nimport logging\nimport os\nimport time\nfrom pathlib import Path\nfrom typing import Any, Literal\n\nimport litellm\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_toolcall_response import (\n    BASH_TOOL_RESPONSE_API,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions_response,\n)\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"portkey_response_model\")\n\ntry:\n    from portkey_ai import Portkey\nexcept ImportError:\n    raise ImportError(\n        \"The portkey-ai package is required to use PortkeyResponseAPIModel. Please install it with: pip install portkey-ai\"\n    )\n\n\nclass PortkeyResponseAPIModelConfig(BaseModel):\n    model_name: str\n    model_kwargs: dict[str, Any] = {}\n    litellm_model_registry: Path | str | None = os.getenv(\"LITELLM_MODEL_REGISTRY_PATH\")\n    litellm_model_name_override: str = \"\"\n    cost_tracking: Literal[\"default\", \"ignore_errors\"] = os.getenv(\"MSWEA_COST_TRACKING\", \"default\")\n    format_error_template: str = \"{{ error }}\"\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    multimodal_regex: str = \"\"\n\n\nclass PortkeyResponseAPIModel:\n    \"\"\"Portkey model using the Responses API with native tool calling.\n\n    Note: This implementation is stateless - each request must include\n    the full conversation history. previous_response_id is not used.\n    \"\"\"\n\n    abort_exceptions: list[type[Exception]] = [KeyboardInterrupt, TypeError, ValueError]\n\n    def __init__(self, **kwargs):\n        self.config = PortkeyResponseAPIModelConfig(**kwargs)\n        if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n            litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n\n        self._api_key = os.getenv(\"PORTKEY_API_KEY\")\n        if not self._api_key:\n            raise ValueError(\n                \"Portkey API key is required. Set it via the \"\n                \"PORTKEY_API_KEY environment variable. You can permanently set it with \"\n                \"`mini-extra config set PORTKEY_API_KEY YOUR_KEY`.\"\n            )\n\n        virtual_key = os.getenv(\"PORTKEY_VIRTUAL_KEY\")\n        client_kwargs = {\"api_key\": self._api_key}\n        if virtual_key:\n            client_kwargs[\"virtual_key\"] = virtual_key\n\n        self.client = Portkey(**client_kwargs)\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        return self.client.responses.create(\n            model=self.config.model_name,\n            input=messages,\n            tools=[BASH_TOOL_RESPONSE_API],\n            **(self.config.model_kwargs | kwargs),\n        )\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        \"\"\"Prepare messages for Portkey's stateless Responses API.\n\n        Flattens response objects into their output items.\n        \"\"\"\n        result = []\n        for msg in messages:\n            if msg.get(\"object\") == \"response\":\n                for item in msg.get(\"output\", []):\n                    result.append({k: v for k, v in item.items() if k != \"extra\"})\n            else:\n                result.append({k: v for k, v in msg.items() if k != \"extra\"})\n        return result\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = response.model_dump() if hasattr(response, \"model_dump\") else dict(response)\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _parse_actions(self, response) -&gt; list[dict]:\n        \"\"\"Parse tool calls from the response API response.\"\"\"\n        output = response.output if hasattr(response, \"output\") else response.get(\"output\", [])\n        return parse_toolcall_actions_response(output, format_error_template=self.config.format_error_template)\n\n    def _calculate_cost(self, response) -&gt; dict[str, float]:\n        try:\n            cost = litellm.cost_calculator.completion_cost(\n                response, model=self.config.litellm_model_name_override or self.config.model_name\n            )\n            assert cost &gt; 0.0, f\"Cost is not positive: {cost}\"\n        except Exception as e:\n            if self.config.cost_tracking != \"ignore_errors\":\n                raise RuntimeError(\n                    f\"Error calculating cost for model {self.config.model_name}: {e}. \"\n                    \"You can ignore this issue from your config file with cost_tracking: 'ignore_errors' or \"\n                    \"globally with export MSWEA_COST_TRACKING='ignore_errors' to ignore this error. \"\n                ) from e\n            cost = 0.0\n        return {\"cost\": cost}\n\n    def format_message(self, **kwargs) -&gt; dict:\n        role = kwargs.get(\"role\", \"user\")\n        content = kwargs.get(\"content\", \"\")\n        extra = kwargs.get(\"extra\")\n        content_items = [{\"type\": \"input_text\", \"text\": content}] if isinstance(content, str) else content\n        msg = {\"type\": \"message\", \"role\": role, \"content\": content_items}\n        if extra:\n            msg[\"extra\"] = extra\n        return msg\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n</code></pre> <p>Guide</p> <p>Setting up Portkey models is covered in the quickstart guide.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model","title":"minisweagent.models.portkey_response_model","text":""},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('portkey_response_model')\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig","title":"PortkeyResponseAPIModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name: str\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.model_kwargs","title":"model_kwargs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_kwargs: dict[str, Any] = {}\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.litellm_model_registry","title":"litellm_model_registry  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_model_registry: Path | str | None = getenv(\n    \"LITELLM_MODEL_REGISTRY_PATH\"\n)\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.litellm_model_name_override","title":"litellm_model_name_override  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_model_name_override: str = ''\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.cost_tracking","title":"cost_tracking  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_tracking: Literal[\"default\", \"ignore_errors\"] = getenv(\n    \"MSWEA_COST_TRACKING\", \"default\"\n)\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.format_error_template","title":"format_error_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>format_error_template: str = '{{ error }}'\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel","title":"PortkeyResponseAPIModel","text":"<pre><code>PortkeyResponseAPIModel(**kwargs)\n</code></pre> <p>Portkey model using the Responses API with native tool calling.</p> <p>Note: This implementation is stateless - each request must include the full conversation history. previous_response_id is not used.</p> Source code in <code>src/minisweagent/models/portkey_response_model.py</code> <pre><code>def __init__(self, **kwargs):\n    self.config = PortkeyResponseAPIModelConfig(**kwargs)\n    if self.config.litellm_model_registry and Path(self.config.litellm_model_registry).is_file():\n        litellm.utils.register_model(json.loads(Path(self.config.litellm_model_registry).read_text()))\n\n    self._api_key = os.getenv(\"PORTKEY_API_KEY\")\n    if not self._api_key:\n        raise ValueError(\n            \"Portkey API key is required. Set it via the \"\n            \"PORTKEY_API_KEY environment variable. You can permanently set it with \"\n            \"`mini-extra config set PORTKEY_API_KEY YOUR_KEY`.\"\n        )\n\n    virtual_key = os.getenv(\"PORTKEY_VIRTUAL_KEY\")\n    client_kwargs = {\"api_key\": self._api_key}\n    if virtual_key:\n        client_kwargs[\"virtual_key\"] = virtual_key\n\n    self.client = Portkey(**client_kwargs)\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.abort_exceptions","title":"abort_exceptions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>abort_exceptions: list[type[Exception]] = [\n    KeyboardInterrupt,\n    TypeError,\n    ValueError,\n]\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = PortkeyResponseAPIModelConfig(**kwargs)\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.client","title":"client  <code>instance-attribute</code>","text":"<pre><code>client = Portkey(**client_kwargs)\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_response_model.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n        with attempt:\n            response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n    cost_output = self._calculate_cost(response)\n    GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n    message = response.model_dump() if hasattr(response, \"model_dump\") else dict(response)\n    message[\"extra\"] = {\n        \"actions\": self._parse_actions(response),\n        **cost_output,\n        \"timestamp\": time.time(),\n    }\n    return message\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_response_model.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    role = kwargs.get(\"role\", \"user\")\n    content = kwargs.get(\"content\", \"\")\n    extra = kwargs.get(\"extra\")\n    content_items = [{\"type\": \"input_text\", \"text\": content}] if isinstance(content, str) else content\n    msg = {\"type\": \"message\", \"role\": role, \"content\": content_items}\n    if extra:\n        msg[\"extra\"] = extra\n    return msg\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/portkey_response_model.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_response_model.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/portkey_response/#minisweagent.models.portkey_response_model.PortkeyResponseAPIModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/portkey_response_model.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/requesty/","title":"RequestyModel","text":""},{"location":"reference/models/requesty/#requesty-model","title":"Requesty Model","text":"<p>Requesty Model class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import json\nimport logging\nimport os\nimport time\nfrom typing import Any, Literal\n\nimport requests\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_toolcall import (\n    BASH_TOOL,\n    format_toolcall_observation_messages,\n    parse_toolcall_actions,\n)\nfrom minisweagent.models.utils.anthropic_utils import _reorder_anthropic_thinking_blocks\nfrom minisweagent.models.utils.cache_control import set_cache_control\nfrom minisweagent.models.utils.openai_multimodal import expand_multimodal_content\nfrom minisweagent.models.utils.retry import retry\n\nlogger = logging.getLogger(\"requesty_model\")\n\n\nclass RequestyModelConfig(BaseModel):\n    model_name: str\n    model_kwargs: dict[str, Any] = {}\n    set_cache_control: Literal[\"default_end\"] | None = None\n    \"\"\"Set explicit cache control markers, for example for Anthropic models\"\"\"\n    format_error_template: str = \"{{ error }}\"\n    \"\"\"Template used when the LM's output is not in the expected format.\"\"\"\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass RequestyAPIError(Exception):\n    \"\"\"Custom exception for Requesty API errors.\"\"\"\n\n    pass\n\n\nclass RequestyAuthenticationError(Exception):\n    \"\"\"Custom exception for Requesty authentication errors.\"\"\"\n\n    pass\n\n\nclass RequestyRateLimitError(Exception):\n    \"\"\"Custom exception for Requesty rate limit errors.\"\"\"\n\n    pass\n\n\nclass RequestyModel:\n    abort_exceptions: list[type[Exception]] = [RequestyAuthenticationError, KeyboardInterrupt]\n\n    def __init__(self, **kwargs):\n        self.config = RequestyModelConfig(**kwargs)\n        self._api_url = \"https://router.requesty.ai/v1/chat/completions\"\n        self._api_key = os.getenv(\"REQUESTY_API_KEY\", \"\")\n\n    def _query(self, messages: list[dict[str, str]], **kwargs):\n        headers = {\n            \"Authorization\": f\"Bearer {self._api_key}\",\n            \"Content-Type\": \"application/json\",\n            \"HTTP-Referer\": \"https://github.com/SWE-agent/mini-swe-agent\",\n            \"X-Title\": \"mini-swe-agent\",\n        }\n\n        payload = {\n            \"model\": self.config.model_name,\n            \"messages\": messages,\n            \"tools\": [BASH_TOOL],\n            **(self.config.model_kwargs | kwargs),\n        }\n\n        try:\n            response = requests.post(self._api_url, headers=headers, data=json.dumps(payload), timeout=60)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.HTTPError as e:\n            if response.status_code == 401:\n                error_msg = \"Authentication failed. You can permanently set your API key with `mini-extra config set REQUESTY_API_KEY YOUR_KEY`.\"\n                raise RequestyAuthenticationError(error_msg) from e\n            elif response.status_code == 429:\n                raise RequestyRateLimitError(\"Rate limit exceeded\") from e\n            else:\n                raise RequestyAPIError(f\"HTTP {response.status_code}: {response.text}\") from e\n        except requests.exceptions.RequestException as e:\n            raise RequestyAPIError(f\"Request failed: {e}\") from e\n\n    def _prepare_messages_for_api(self, messages: list[dict]) -&gt; list[dict]:\n        prepared = [{k: v for k, v in msg.items() if k != \"extra\"} for msg in messages]\n        prepared = _reorder_anthropic_thinking_blocks(prepared)\n        return set_cache_control(prepared, mode=self.config.set_cache_control)\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n            with attempt:\n                response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n        cost_output = self._calculate_cost(response)\n        GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n        message = dict(response[\"choices\"][0][\"message\"])\n        message[\"extra\"] = {\n            \"actions\": self._parse_actions(response),\n            \"response\": response,\n            **cost_output,\n            \"timestamp\": time.time(),\n        }\n        return message\n\n    def _calculate_cost(self, response) -&gt; dict[str, float]:\n        usage = response.get(\"usage\", {})\n        cost = usage.get(\"cost\", 0.0)\n        if cost == 0.0:\n            raise RequestyAPIError(\n                f\"No cost information available from Requesty API for model {self.config.model_name}. \"\n                \"Cost tracking is required but not provided by the API response.\"\n            )\n        return {\"cost\": cost}\n\n    def _parse_actions(self, response: dict) -&gt; list[dict]:\n        \"\"\"Parse tool calls from the response. Raises FormatError if unknown tool.\"\"\"\n        tool_calls = response[\"choices\"][0][\"message\"].get(\"tool_calls\") or []\n        tool_calls = [_DictToObj(tc) for tc in tool_calls]\n        return parse_toolcall_actions(tool_calls, format_error_template=self.config.format_error_template)\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n\n\nclass _DictToObj:\n    \"\"\"Simple wrapper to convert dict to object with attribute access.\"\"\"\n\n    def __init__(self, d: dict):\n        self._d = d\n        self.id = d.get(\"id\")\n        self.function = _DictToObj(d.get(\"function\", {})) if \"function\" in d else None\n        self.name = d.get(\"name\")\n        self.arguments = d.get(\"arguments\")\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model","title":"minisweagent.models.requesty_model","text":""},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('requesty_model')\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig","title":"RequestyModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name: str\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig.model_kwargs","title":"model_kwargs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_kwargs: dict[str, Any] = {}\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig.set_cache_control","title":"set_cache_control  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>set_cache_control: Literal['default_end'] | None = None\n</code></pre> <p>Set explicit cache control markers, for example for Anthropic models</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig.format_error_template","title":"format_error_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>format_error_template: str = '{{ error }}'\n</code></pre> <p>Template used when the LM's output is not in the expected format.</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyAPIError","title":"RequestyAPIError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for Requesty API errors.</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyAuthenticationError","title":"RequestyAuthenticationError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for Requesty authentication errors.</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyRateLimitError","title":"RequestyRateLimitError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for Requesty rate limit errors.</p>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel","title":"RequestyModel","text":"<pre><code>RequestyModel(**kwargs)\n</code></pre> Source code in <code>src/minisweagent/models/requesty_model.py</code> <pre><code>def __init__(self, **kwargs):\n    self.config = RequestyModelConfig(**kwargs)\n    self._api_url = \"https://router.requesty.ai/v1/chat/completions\"\n    self._api_key = os.getenv(\"REQUESTY_API_KEY\", \"\")\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.abort_exceptions","title":"abort_exceptions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>abort_exceptions: list[type[Exception]] = [\n    RequestyAuthenticationError,\n    KeyboardInterrupt,\n]\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = RequestyModelConfig(**kwargs)\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/requesty_model.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    for attempt in retry(logger=logger, abort_exceptions=self.abort_exceptions):\n        with attempt:\n            response = self._query(self._prepare_messages_for_api(messages), **kwargs)\n    cost_output = self._calculate_cost(response)\n    GLOBAL_MODEL_STATS.add(cost_output[\"cost\"])\n    message = dict(response[\"choices\"][0][\"message\"])\n    message[\"extra\"] = {\n        \"actions\": self._parse_actions(response),\n        \"response\": response,\n        **cost_output,\n        \"timestamp\": time.time(),\n    }\n    return message\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/requesty_model.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/requesty_model.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/requesty_model.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/requesty/#minisweagent.models.requesty_model.RequestyModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/requesty_model.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/test_models/","title":"DeterministicModel","text":""},{"location":"reference/models/test_models/#test-models","title":"Test Models","text":"<p>Test Models class</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>import logging\nimport time\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom minisweagent.models import GLOBAL_MODEL_STATS\nfrom minisweagent.models.utils.actions_text import format_observation_messages\nfrom minisweagent.models.utils.actions_toolcall import format_toolcall_observation_messages\nfrom minisweagent.models.utils.actions_toolcall_response import (\n    format_toolcall_observation_messages as format_response_api_observation_messages,\n)\nfrom minisweagent.models.utils.openai_multimodal import expand_multimodal_content\n\n\ndef make_output(content: str, actions: list[dict], cost: float = 1.0) -&gt; dict:\n    \"\"\"Helper to create an output dict for DeterministicModel.\n\n    Args:\n        content: The response content string\n        actions: List of action dicts, e.g., [{\"command\": \"echo hello\"}]\n        cost: Cost to report for this output (default 1.0)\n    \"\"\"\n    return {\n        \"role\": \"assistant\",\n        \"content\": content,\n        \"extra\": {\"actions\": actions, \"cost\": cost, \"timestamp\": time.time()},\n    }\n\n\ndef make_toolcall_output(content: str | None, tool_calls: list[dict], actions: list[dict]) -&gt; dict:\n    \"\"\"Helper to create a toolcall output dict for DeterministicToolcallModel.\n\n    Args:\n        content: Optional text content (can be None for tool-only responses)\n        tool_calls: List of tool call dicts in OpenAI format\n        actions: List of parsed action dicts, e.g., [{\"command\": \"echo hello\", \"tool_call_id\": \"call_123\"}]\n    \"\"\"\n    return {\n        \"role\": \"assistant\",\n        \"content\": content,\n        \"tool_calls\": tool_calls,\n        \"extra\": {\"actions\": actions, \"cost\": 1.0, \"timestamp\": time.time()},\n    }\n\n\ndef make_response_api_output(content: str | None, actions: list[dict]) -&gt; dict:\n    \"\"\"Helper to create an output dict for DeterministicResponseAPIToolcallModel.\n\n    Args:\n        content: Optional text content (can be None for tool-only responses)\n        actions: List of action dicts with 'command' and 'tool_call_id' keys\n    \"\"\"\n    output_items = []\n    if content:\n        output_items.append(\n            {\"type\": \"message\", \"role\": \"assistant\", \"content\": [{\"type\": \"output_text\", \"text\": content}]}\n        )\n    for action in actions:\n        output_items.append(\n            {\n                \"type\": \"function_call\",\n                \"call_id\": action[\"tool_call_id\"],\n                \"name\": \"bash\",\n                \"arguments\": f'{{\"command\": \"{action[\"command\"]}\"}}',\n            }\n        )\n    return {\n        \"object\": \"response\",\n        \"output\": output_items,\n        \"extra\": {\"actions\": actions, \"cost\": 1.0, \"timestamp\": time.time()},\n    }\n\n\ndef _process_test_actions(actions: list[dict]) -&gt; bool:\n    \"\"\"Process special test actions. Returns True if the query should be retried.\"\"\"\n    for action in actions:\n        if \"raise\" in action:\n            raise action[\"raise\"]\n        cmd = action.get(\"command\", \"\")\n        if cmd.startswith(\"/sleep \"):\n            time.sleep(float(cmd.split(\"/sleep \")[1]))\n            return True\n        if cmd.startswith(\"/warning\"):\n            logging.warning(cmd.split(\"/warning\")[1])\n            return True\n    return False\n\n\nclass DeterministicModelConfig(BaseModel):\n    outputs: list[dict]\n    \"\"\"List of exact output messages to return in sequence. Each dict should have 'role', 'content', and 'extra' (with 'actions').\"\"\"\n    model_name: str = \"deterministic\"\n    cost_per_call: float = 1.0\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass DeterministicModel:\n    def __init__(self, **kwargs):\n        \"\"\"Initialize with a list of output messages to return in sequence.\"\"\"\n        self.config = DeterministicModelConfig(**kwargs)\n        self.current_index = -1\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        self.current_index += 1\n        output = self.config.outputs[self.current_index]\n        if _process_test_actions(output.get(\"extra\", {}).get(\"actions\", [])):\n            return self.query(messages, **kwargs)\n        GLOBAL_MODEL_STATS.add(self.config.cost_per_call)\n        return output\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into observation messages.\"\"\"\n        return format_observation_messages(\n            outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n\n\nclass DeterministicToolcallModelConfig(BaseModel):\n    outputs: list[dict]\n    \"\"\"List of exact output messages with tool_calls to return in sequence.\"\"\"\n    model_name: str = \"deterministic_toolcall\"\n    cost_per_call: float = 1.0\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass DeterministicToolcallModel:\n    def __init__(self, **kwargs):\n        \"\"\"Initialize with a list of toolcall output messages to return in sequence.\"\"\"\n        self.config = DeterministicToolcallModelConfig(**kwargs)\n        self.current_index = -1\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        self.current_index += 1\n        output = self.config.outputs[self.current_index]\n        if _process_test_actions(output.get(\"extra\", {}).get(\"actions\", [])):\n            return self.query(messages, **kwargs)\n        GLOBAL_MODEL_STATS.add(self.config.cost_per_call)\n        return output\n\n    def format_message(self, **kwargs) -&gt; dict:\n        return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into tool result messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_toolcall_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n\n\nclass DeterministicResponseAPIToolcallModelConfig(BaseModel):\n    outputs: list[dict]\n    \"\"\"List of exact Response API output messages to return in sequence.\"\"\"\n    model_name: str = \"deterministic_response_api_toolcall\"\n    cost_per_call: float = 1.0\n    observation_template: str = (\n        \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}\"\n        \"&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n    )\n    \"\"\"Template used to render the observation after executing an action.\"\"\"\n    multimodal_regex: str = \"\"\n    \"\"\"Regex to extract multimodal content. Empty string disables multimodal processing.\"\"\"\n\n\nclass DeterministicResponseAPIToolcallModel:\n    \"\"\"Deterministic test model using OpenAI Responses API format.\"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize with a list of Response API output messages to return in sequence.\"\"\"\n        self.config = DeterministicResponseAPIToolcallModelConfig(**kwargs)\n        self.current_index = -1\n\n    def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n        self.current_index += 1\n        output = self.config.outputs[self.current_index]\n        if _process_test_actions(output.get(\"extra\", {}).get(\"actions\", [])):\n            return self.query(messages, **kwargs)\n        GLOBAL_MODEL_STATS.add(self.config.cost_per_call)\n        return output\n\n    def format_message(self, **kwargs) -&gt; dict:\n        \"\"\"Format message in Responses API format.\"\"\"\n        role = kwargs.get(\"role\", \"user\")\n        content = kwargs.get(\"content\", \"\")\n        extra = kwargs.get(\"extra\")\n        content_items = [{\"type\": \"input_text\", \"text\": content}] if isinstance(content, str) else content\n        msg: dict = {\"type\": \"message\", \"role\": role, \"content\": content_items}\n        if extra:\n            msg[\"extra\"] = extra\n        return msg\n\n    def format_observation_messages(\n        self, message: dict, outputs: list[dict], template_vars: dict | None = None\n    ) -&gt; list[dict]:\n        \"\"\"Format execution outputs into function_call_output messages.\"\"\"\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        return format_response_api_observation_messages(\n            actions=actions,\n            outputs=outputs,\n            observation_template=self.config.observation_template,\n            template_vars=template_vars,\n            multimodal_regex=self.config.multimodal_regex,\n        )\n\n    def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n        return self.config.model_dump()\n\n    def serialize(self) -&gt; dict:\n        return {\n            \"info\": {\n                \"config\": {\n                    \"model\": self.config.model_dump(mode=\"json\"),\n                    \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n                },\n            }\n        }\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models","title":"minisweagent.models.test_models","text":""},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModelConfig","title":"DeterministicModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModelConfig.outputs","title":"outputs  <code>instance-attribute</code>","text":"<pre><code>outputs: list[dict]\n</code></pre> <p>List of exact output messages to return in sequence. Each dict should have 'role', 'content', and 'extra' (with 'actions').</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModelConfig.model_name","title":"model_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_name: str = 'deterministic'\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModelConfig.cost_per_call","title":"cost_per_call  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_per_call: float = 1.0\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel","title":"DeterministicModel","text":"<pre><code>DeterministicModel(**kwargs)\n</code></pre> <p>Initialize with a list of output messages to return in sequence.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize with a list of output messages to return in sequence.\"\"\"\n    self.config = DeterministicModelConfig(**kwargs)\n    self.current_index = -1\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = DeterministicModelConfig(**kwargs)\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.current_index","title":"current_index  <code>instance-attribute</code>","text":"<pre><code>current_index = -1\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    self.current_index += 1\n    output = self.config.outputs[self.current_index]\n    if _process_test_actions(output.get(\"extra\", {}).get(\"actions\", [])):\n        return self.query(messages, **kwargs)\n    GLOBAL_MODEL_STATS.add(self.config.cost_per_call)\n    return output\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into observation messages.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into observation messages.\"\"\"\n    return format_observation_messages(\n        outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModelConfig","title":"DeterministicToolcallModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModelConfig.outputs","title":"outputs  <code>instance-attribute</code>","text":"<pre><code>outputs: list[dict]\n</code></pre> <p>List of exact output messages with tool_calls to return in sequence.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModelConfig.model_name","title":"model_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_name: str = 'deterministic_toolcall'\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModelConfig.cost_per_call","title":"cost_per_call  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_per_call: float = 1.0\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel","title":"DeterministicToolcallModel","text":"<pre><code>DeterministicToolcallModel(**kwargs)\n</code></pre> <p>Initialize with a list of toolcall output messages to return in sequence.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize with a list of toolcall output messages to return in sequence.\"\"\"\n    self.config = DeterministicToolcallModelConfig(**kwargs)\n    self.current_index = -1\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = DeterministicToolcallModelConfig(**kwargs)\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.current_index","title":"current_index  <code>instance-attribute</code>","text":"<pre><code>current_index = -1\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    self.current_index += 1\n    output = self.config.outputs[self.current_index]\n    if _process_test_actions(output.get(\"extra\", {}).get(\"actions\", [])):\n        return self.query(messages, **kwargs)\n    GLOBAL_MODEL_STATS.add(self.config.cost_per_call)\n    return output\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    return expand_multimodal_content(kwargs, pattern=self.config.multimodal_regex)\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into tool result messages.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into tool result messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_toolcall_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicToolcallModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModelConfig","title":"DeterministicResponseAPIToolcallModelConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModelConfig.outputs","title":"outputs  <code>instance-attribute</code>","text":"<pre><code>outputs: list[dict]\n</code></pre> <p>List of exact Response API output messages to return in sequence.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModelConfig.model_name","title":"model_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_name: str = 'deterministic_response_api_toolcall'\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModelConfig.cost_per_call","title":"cost_per_call  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cost_per_call: float = 1.0\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModelConfig.observation_template","title":"observation_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>observation_template: str = \"{% if output.exception_info %}&lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\\n{% endif %}&lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\\n&lt;output&gt;\\n{{output.output}}&lt;/output&gt;\"\n</code></pre> <p>Template used to render the observation after executing an action.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModelConfig.multimodal_regex","title":"multimodal_regex  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>multimodal_regex: str = ''\n</code></pre> <p>Regex to extract multimodal content. Empty string disables multimodal processing.</p>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel","title":"DeterministicResponseAPIToolcallModel","text":"<pre><code>DeterministicResponseAPIToolcallModel(**kwargs)\n</code></pre> <p>Deterministic test model using OpenAI Responses API format.</p> <p>Initialize with a list of Response API output messages to return in sequence.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize with a list of Response API output messages to return in sequence.\"\"\"\n    self.config = DeterministicResponseAPIToolcallModelConfig(**kwargs)\n    self.current_index = -1\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = DeterministicResponseAPIToolcallModelConfig(\n    **kwargs\n)\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.current_index","title":"current_index  <code>instance-attribute</code>","text":"<pre><code>current_index = -1\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.query","title":"query","text":"<pre><code>query(messages: list[dict[str, str]], **kwargs) -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def query(self, messages: list[dict[str, str]], **kwargs) -&gt; dict:\n    self.current_index += 1\n    output = self.config.outputs[self.current_index]\n    if _process_test_actions(output.get(\"extra\", {}).get(\"actions\", [])):\n        return self.query(messages, **kwargs)\n    GLOBAL_MODEL_STATS.add(self.config.cost_per_call)\n    return output\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.format_message","title":"format_message","text":"<pre><code>format_message(**kwargs) -&gt; dict\n</code></pre> <p>Format message in Responses API format.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def format_message(self, **kwargs) -&gt; dict:\n    \"\"\"Format message in Responses API format.\"\"\"\n    role = kwargs.get(\"role\", \"user\")\n    content = kwargs.get(\"content\", \"\")\n    extra = kwargs.get(\"extra\")\n    content_items = [{\"type\": \"input_text\", \"text\": content}] if isinstance(content, str) else content\n    msg: dict = {\"type\": \"message\", \"role\": role, \"content\": content_items}\n    if extra:\n        msg[\"extra\"] = extra\n    return msg\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.format_observation_messages","title":"format_observation_messages","text":"<pre><code>format_observation_messages(\n    message: dict,\n    outputs: list[dict],\n    template_vars: dict | None = None,\n) -&gt; list[dict]\n</code></pre> <p>Format execution outputs into function_call_output messages.</p> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def format_observation_messages(\n    self, message: dict, outputs: list[dict], template_vars: dict | None = None\n) -&gt; list[dict]:\n    \"\"\"Format execution outputs into function_call_output messages.\"\"\"\n    actions = message.get(\"extra\", {}).get(\"actions\", [])\n    return format_response_api_observation_messages(\n        actions=actions,\n        outputs=outputs,\n        observation_template=self.config.observation_template,\n        template_vars=template_vars,\n        multimodal_regex=self.config.multimodal_regex,\n    )\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.get_template_vars","title":"get_template_vars","text":"<pre><code>get_template_vars(**kwargs) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def get_template_vars(self, **kwargs) -&gt; dict[str, Any]:\n    return self.config.model_dump()\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.DeterministicResponseAPIToolcallModel.serialize","title":"serialize","text":"<pre><code>serialize() -&gt; dict\n</code></pre> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def serialize(self) -&gt; dict:\n    return {\n        \"info\": {\n            \"config\": {\n                \"model\": self.config.model_dump(mode=\"json\"),\n                \"model_type\": f\"{self.__class__.__module__}.{self.__class__.__name__}\",\n            },\n        }\n    }\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.make_output","title":"make_output","text":"<pre><code>make_output(\n    content: str, actions: list[dict], cost: float = 1.0\n) -&gt; dict\n</code></pre> <p>Helper to create an output dict for DeterministicModel.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The response content string</p> required <code>actions</code> <code>list[dict]</code> <p>List of action dicts, e.g., [{\"command\": \"echo hello\"}]</p> required <code>cost</code> <code>float</code> <p>Cost to report for this output (default 1.0)</p> <code>1.0</code> Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def make_output(content: str, actions: list[dict], cost: float = 1.0) -&gt; dict:\n    \"\"\"Helper to create an output dict for DeterministicModel.\n\n    Args:\n        content: The response content string\n        actions: List of action dicts, e.g., [{\"command\": \"echo hello\"}]\n        cost: Cost to report for this output (default 1.0)\n    \"\"\"\n    return {\n        \"role\": \"assistant\",\n        \"content\": content,\n        \"extra\": {\"actions\": actions, \"cost\": cost, \"timestamp\": time.time()},\n    }\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.make_toolcall_output","title":"make_toolcall_output","text":"<pre><code>make_toolcall_output(\n    content: str | None,\n    tool_calls: list[dict],\n    actions: list[dict],\n) -&gt; dict\n</code></pre> <p>Helper to create a toolcall output dict for DeterministicToolcallModel.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str | None</code> <p>Optional text content (can be None for tool-only responses)</p> required <code>tool_calls</code> <code>list[dict]</code> <p>List of tool call dicts in OpenAI format</p> required <code>actions</code> <code>list[dict]</code> <p>List of parsed action dicts, e.g., [{\"command\": \"echo hello\", \"tool_call_id\": \"call_123\"}]</p> required Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def make_toolcall_output(content: str | None, tool_calls: list[dict], actions: list[dict]) -&gt; dict:\n    \"\"\"Helper to create a toolcall output dict for DeterministicToolcallModel.\n\n    Args:\n        content: Optional text content (can be None for tool-only responses)\n        tool_calls: List of tool call dicts in OpenAI format\n        actions: List of parsed action dicts, e.g., [{\"command\": \"echo hello\", \"tool_call_id\": \"call_123\"}]\n    \"\"\"\n    return {\n        \"role\": \"assistant\",\n        \"content\": content,\n        \"tool_calls\": tool_calls,\n        \"extra\": {\"actions\": actions, \"cost\": 1.0, \"timestamp\": time.time()},\n    }\n</code></pre>"},{"location":"reference/models/test_models/#minisweagent.models.test_models.make_response_api_output","title":"make_response_api_output","text":"<pre><code>make_response_api_output(\n    content: str | None, actions: list[dict]\n) -&gt; dict\n</code></pre> <p>Helper to create an output dict for DeterministicResponseAPIToolcallModel.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str | None</code> <p>Optional text content (can be None for tool-only responses)</p> required <code>actions</code> <code>list[dict]</code> <p>List of action dicts with 'command' and 'tool_call_id' keys</p> required Source code in <code>src/minisweagent/models/test_models.py</code> <pre><code>def make_response_api_output(content: str | None, actions: list[dict]) -&gt; dict:\n    \"\"\"Helper to create an output dict for DeterministicResponseAPIToolcallModel.\n\n    Args:\n        content: Optional text content (can be None for tool-only responses)\n        actions: List of action dicts with 'command' and 'tool_call_id' keys\n    \"\"\"\n    output_items = []\n    if content:\n        output_items.append(\n            {\"type\": \"message\", \"role\": \"assistant\", \"content\": [{\"type\": \"output_text\", \"text\": content}]}\n        )\n    for action in actions:\n        output_items.append(\n            {\n                \"type\": \"function_call\",\n                \"call_id\": action[\"tool_call_id\"],\n                \"name\": \"bash\",\n                \"arguments\": f'{{\"command\": \"{action[\"command\"]}\"}}',\n            }\n        )\n    return {\n        \"object\": \"response\",\n        \"output\": output_items,\n        \"extra\": {\"actions\": actions, \"cost\": 1.0, \"timestamp\": time.time()},\n    }\n</code></pre>"},{"location":"reference/models/utils/","title":"Model Utilities","text":""},{"location":"reference/models/utils/#model-utilities","title":"Model Utilities","text":"<p>Model Utilities</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>\"\"\"This file provides convenience functions for selecting models.\nYou can ignore this file completely if you explicitly set your model in your run script.\n\"\"\"\n\nimport copy\nimport importlib\nimport os\nimport threading\n\nfrom minisweagent import Model\n\n\nclass GlobalModelStats:\n    \"\"\"Global model statistics tracker with optional limits.\"\"\"\n\n    def __init__(self):\n        self._cost = 0.0\n        self._n_calls = 0\n        self._lock = threading.Lock()\n        self.cost_limit = float(os.getenv(\"MSWEA_GLOBAL_COST_LIMIT\", \"0\"))\n        self.call_limit = int(os.getenv(\"MSWEA_GLOBAL_CALL_LIMIT\", \"0\"))\n        if (self.cost_limit &gt; 0 or self.call_limit &gt; 0) and not os.getenv(\"MSWEA_SILENT_STARTUP\"):\n            print(f\"Global cost/call limit: ${self.cost_limit:.4f} / {self.call_limit}\")\n\n    def add(self, cost: float) -&gt; None:\n        \"\"\"Add a model call with its cost, checking limits.\"\"\"\n        with self._lock:\n            self._cost += cost\n            self._n_calls += 1\n        if 0 &lt; self.cost_limit &lt; self._cost or 0 &lt; self.call_limit &lt; self._n_calls + 1:\n            raise RuntimeError(f\"Global cost/call limit exceeded: ${self._cost:.4f} / {self._n_calls}\")\n\n    @property\n    def cost(self) -&gt; float:\n        return self._cost\n\n    @property\n    def n_calls(self) -&gt; int:\n        return self._n_calls\n\n\nGLOBAL_MODEL_STATS = GlobalModelStats()\n\n\ndef get_model(input_model_name: str | None = None, config: dict | None = None) -&gt; Model:\n    \"\"\"Get an initialized model object from any kind of user input or settings.\"\"\"\n    resolved_model_name = get_model_name(input_model_name, config)\n    if config is None:\n        config = {}\n    config = copy.deepcopy(config)\n    config[\"model_name\"] = resolved_model_name\n\n    model_class = get_model_class(resolved_model_name, config.pop(\"model_class\", \"\"))\n\n    if (\n        any(s in resolved_model_name.lower() for s in [\"anthropic\", \"sonnet\", \"opus\", \"claude\"])\n        and \"set_cache_control\" not in config\n    ):\n        # Select cache control for Anthropic models by default\n        config[\"set_cache_control\"] = \"default_end\"\n\n    return model_class(**config)\n\n\ndef get_model_name(input_model_name: str | None = None, config: dict | None = None) -&gt; str:\n    \"\"\"Get a model name from any kind of user input or settings.\"\"\"\n    if config is None:\n        config = {}\n    if input_model_name:\n        return input_model_name\n    if from_config := config.get(\"model_name\"):\n        return from_config\n    if from_env := os.getenv(\"MSWEA_MODEL_NAME\"):\n        return from_env\n    raise ValueError(\"No default model set. Please run `mini-extra config setup` to set one.\")\n\n\n_MODEL_CLASS_MAPPING = {\n    \"litellm\": \"minisweagent.models.litellm_model.LitellmModel\",\n    \"litellm_textbased\": \"minisweagent.models.litellm_textbased_model.LitellmTextbasedModel\",\n    \"litellm_response\": \"minisweagent.models.litellm_response_model.LitellmResponseModel\",\n    \"openrouter\": \"minisweagent.models.openrouter_model.OpenRouterModel\",\n    \"openrouter_textbased\": \"minisweagent.models.openrouter_textbased_model.OpenRouterTextbasedModel\",\n    \"openrouter_response\": \"minisweagent.models.openrouter_response_model.OpenRouterResponseModel\",\n    \"portkey\": \"minisweagent.models.portkey_model.PortkeyModel\",\n    \"portkey_response\": \"minisweagent.models.portkey_response_model.PortkeyResponseAPIModel\",\n    \"requesty\": \"minisweagent.models.requesty_model.RequestyModel\",\n    \"deterministic\": \"minisweagent.models.test_models.DeterministicModel\",\n}\n\n\ndef get_model_class(model_name: str, model_class: str = \"\") -&gt; type:\n    \"\"\"Select the best model class.\n\n    If a model_class is provided (as shortcut name, or as full import path,\n    e.g., \"anthropic\" or \"minisweagent.models.anthropic.AnthropicModel\"),\n    it takes precedence over the `model_name`.\n    Otherwise, the model_name is used to select the best model class.\n    \"\"\"\n    if model_class:\n        full_path = _MODEL_CLASS_MAPPING.get(model_class, model_class)\n        try:\n            module_name, class_name = full_path.rsplit(\".\", 1)\n            module = importlib.import_module(module_name)\n            return getattr(module, class_name)\n        except (ValueError, ImportError, AttributeError):\n            msg = f\"Unknown model class: {model_class} (resolved to {full_path}, available: {_MODEL_CLASS_MAPPING})\"\n            raise ValueError(msg)\n\n    # Default to LitellmModel\n    from minisweagent.models.litellm_model import LitellmModel\n\n    return LitellmModel\n</code></pre> <p>Convenience functions for selecting and configuring models.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/models/utils/#minisweagent.models.get_model","title":"minisweagent.models.get_model","text":"<pre><code>get_model(\n    input_model_name: str | None = None,\n    config: dict | None = None,\n) -&gt; Model\n</code></pre> <p>Get an initialized model object from any kind of user input or settings.</p> Source code in <code>src/minisweagent/models/__init__.py</code> <pre><code>def get_model(input_model_name: str | None = None, config: dict | None = None) -&gt; Model:\n    \"\"\"Get an initialized model object from any kind of user input or settings.\"\"\"\n    resolved_model_name = get_model_name(input_model_name, config)\n    if config is None:\n        config = {}\n    config = copy.deepcopy(config)\n    config[\"model_name\"] = resolved_model_name\n\n    model_class = get_model_class(resolved_model_name, config.pop(\"model_class\", \"\"))\n\n    if (\n        any(s in resolved_model_name.lower() for s in [\"anthropic\", \"sonnet\", \"opus\", \"claude\"])\n        and \"set_cache_control\" not in config\n    ):\n        # Select cache control for Anthropic models by default\n        config[\"set_cache_control\"] = \"default_end\"\n\n    return model_class(**config)\n</code></pre>"},{"location":"reference/models/utils/#minisweagent.models.get_model_name","title":"minisweagent.models.get_model_name","text":"<pre><code>get_model_name(\n    input_model_name: str | None = None,\n    config: dict | None = None,\n) -&gt; str\n</code></pre> <p>Get a model name from any kind of user input or settings.</p> Source code in <code>src/minisweagent/models/__init__.py</code> <pre><code>def get_model_name(input_model_name: str | None = None, config: dict | None = None) -&gt; str:\n    \"\"\"Get a model name from any kind of user input or settings.\"\"\"\n    if config is None:\n        config = {}\n    if input_model_name:\n        return input_model_name\n    if from_config := config.get(\"model_name\"):\n        return from_config\n    if from_env := os.getenv(\"MSWEA_MODEL_NAME\"):\n        return from_env\n    raise ValueError(\"No default model set. Please run `mini-extra config setup` to set one.\")\n</code></pre>"},{"location":"reference/models/utils/#minisweagent.models.get_model_class","title":"minisweagent.models.get_model_class","text":"<pre><code>get_model_class(\n    model_name: str, model_class: str = \"\"\n) -&gt; type\n</code></pre> <p>Select the best model class.</p> <p>If a model_class is provided (as shortcut name, or as full import path, e.g., \"anthropic\" or \"minisweagent.models.anthropic.AnthropicModel\"), it takes precedence over the <code>model_name</code>. Otherwise, the model_name is used to select the best model class.</p> Source code in <code>src/minisweagent/models/__init__.py</code> <pre><code>def get_model_class(model_name: str, model_class: str = \"\") -&gt; type:\n    \"\"\"Select the best model class.\n\n    If a model_class is provided (as shortcut name, or as full import path,\n    e.g., \"anthropic\" or \"minisweagent.models.anthropic.AnthropicModel\"),\n    it takes precedence over the `model_name`.\n    Otherwise, the model_name is used to select the best model class.\n    \"\"\"\n    if model_class:\n        full_path = _MODEL_CLASS_MAPPING.get(model_class, model_class)\n        try:\n            module_name, class_name = full_path.rsplit(\".\", 1)\n            module = importlib.import_module(module_name)\n            return getattr(module, class_name)\n        except (ValueError, ImportError, AttributeError):\n            msg = f\"Unknown model class: {model_class} (resolved to {full_path}, available: {_MODEL_CLASS_MAPPING})\"\n            raise ValueError(msg)\n\n    # Default to LitellmModel\n    from minisweagent.models.litellm_model import LitellmModel\n\n    return LitellmModel\n</code></pre>"},{"location":"reference/run/config/","title":"Config","text":""},{"location":"reference/run/config/#config","title":"Config","text":"<p>Global Config Manager</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>#!/usr/bin/env python3\n\n\"\"\"Utility to manage the global config file.\n\nYou can also directly edit the `.env` file in the config directory.\n\nIt is located at [bold green]{global_config_file}[/bold green].\n\"\"\"\n\nimport os\nimport subprocess\n\nfrom dotenv import set_key, unset_key\nfrom rich.console import Console\nfrom rich.rule import Rule\nfrom typer import Argument, Typer\n\nfrom minisweagent import global_config_file\n\napp = Typer(\n    help=__doc__.format(global_config_file=global_config_file),  # type: ignore\n    no_args_is_help=True,\n    rich_markup_mode=\"rich\",\n    add_completion=False,\n)\nconsole = Console(highlight=False)\n\n\n_SETUP_HELP = \"\"\"To get started, we need to set up your global config file.\n\nYou can edit it manually or use the [bold green]mini-extra config set[/bold green] or [bold green]mini-extra config edit[/bold green] commands.\n\nThis setup will ask you for your model and an API key.\n\nHere's a few popular models and the required API keys:\n\n[bold green]anthropic/claude-sonnet-4-5-20250929[/bold green] ([bold green]ANTHROPIC_API_KEY[/bold green])\n[bold green]openai/gpt-5[/bold green] or [bold green]openai/gpt-5-mini[/bold green] ([bold green]OPENAI_API_KEY[/bold green])\n[bold green]gemini/gemini-3-pro-preview[/bold green] ([bold green]GEMINI_API_KEY[/bold green])\n\n[bold]Note: Please always include the provider (e.g., \"openai/\") in the model name.[/bold]\n\n[bold yellow]You can leave any setting blank to skip it.[/bold yellow]\n\nMore information at https://mini-swe-agent.com/latest/quickstart/\nTo find the best model, check the leaderboard at https://swebench.com/\n\"\"\"\n\n\ndef prompt(*args, **kwargs):\n    # Defer import to avoid slow import module\n    from prompt_toolkit.shortcuts.prompt import prompt as _prompt\n\n    return _prompt(*args, **kwargs)\n\n\ndef configure_if_first_time():\n    if not os.getenv(\"MSWEA_CONFIGURED\"):\n        console.print(Rule())\n        setup()\n        console.print(Rule())\n\n\n@app.command()\ndef setup():\n    \"\"\"Setup the global config file.\"\"\"\n    console.print(_SETUP_HELP.format(global_config_file=global_config_file))\n    default_model = prompt(\n        \"Enter your default model (e.g., anthropic/claude-sonnet-4-5-20250929): \",\n        default=os.getenv(\"MSWEA_MODEL_NAME\", \"\"),\n    ).strip()\n    if default_model:\n        set_key(global_config_file, \"MSWEA_MODEL_NAME\", default_model)\n    console.print(\n        \"[bold yellow]If you already have your API keys set as environment variables, you can ignore the next question.[/bold yellow]\"\n    )\n    key_name = prompt(\"Enter your API key name (e.g., ANTHROPIC_API_KEY): \").strip()\n    key_value = None\n    if key_name:\n        key_value = prompt(\"Enter your API key value (e.g., sk-1234567890): \", default=os.getenv(key_name, \"\")).strip()\n        if key_value:\n            set_key(global_config_file, key_name, key_value)\n    if not key_value:\n        console.print(\n            \"[bold red]API key setup not completed.[/bold red] Totally fine if you have your keys as environment variables.\"\n        )\n    set_key(global_config_file, \"MSWEA_CONFIGURED\", \"true\")\n    console.print(\n        \"\\n[bold yellow]Config finished.[/bold yellow] If you want to revisit it, run [bold green]mini-extra config setup[/bold green].\"\n    )\n\n\n@app.command()\ndef set(\n    key: str | None = Argument(None, help=\"The key to set\"),\n    value: str | None = Argument(None, help=\"The value to set\"),\n):\n    \"\"\"Set a key in the global config file.\"\"\"\n    if key is None:\n        key = prompt(\"Enter the key to set: \")\n    if value is None:\n        value = prompt(f\"Enter the value for {key}: \")\n    set_key(global_config_file, key, value)\n\n\n@app.command()\ndef unset(key: str | None = Argument(None, help=\"The key to unset\")):\n    \"\"\"Unset a key in the global config file.\"\"\"\n    if key is None:\n        key = prompt(\"Enter the key to unset: \")\n    unset_key(global_config_file, key)\n\n\n@app.command()\ndef edit():\n    \"\"\"Edit the global config file.\"\"\"\n    editor = os.getenv(\"EDITOR\", \"nano\")\n    subprocess.run([editor, global_config_file])\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> <p>Utility to manage the global config file via <code>mini-extra config</code>.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/config/#minisweagent.run.utilities.config","title":"minisweagent.run.utilities.config","text":"<p>Utility to manage the global config file.</p> <p>You can also directly edit the <code>.env</code> file in the config directory.</p> <p>It is located at [bold green]{global_config_file}[/bold green].</p>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.app","title":"app  <code>module-attribute</code>","text":"<pre><code>app = Typer(\n    help=format(global_config_file=global_config_file),\n    no_args_is_help=True,\n    rich_markup_mode=\"rich\",\n    add_completion=False,\n)\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.console","title":"console  <code>module-attribute</code>","text":"<pre><code>console = Console(highlight=False)\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.prompt","title":"prompt","text":"<pre><code>prompt(*args, **kwargs)\n</code></pre> Source code in <code>src/minisweagent/run/utilities/config.py</code> <pre><code>def prompt(*args, **kwargs):\n    # Defer import to avoid slow import module\n    from prompt_toolkit.shortcuts.prompt import prompt as _prompt\n\n    return _prompt(*args, **kwargs)\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.configure_if_first_time","title":"configure_if_first_time","text":"<pre><code>configure_if_first_time()\n</code></pre> Source code in <code>src/minisweagent/run/utilities/config.py</code> <pre><code>def configure_if_first_time():\n    if not os.getenv(\"MSWEA_CONFIGURED\"):\n        console.print(Rule())\n        setup()\n        console.print(Rule())\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.setup","title":"setup","text":"<pre><code>setup()\n</code></pre> <p>Setup the global config file.</p> Source code in <code>src/minisweagent/run/utilities/config.py</code> <pre><code>@app.command()\ndef setup():\n    \"\"\"Setup the global config file.\"\"\"\n    console.print(_SETUP_HELP.format(global_config_file=global_config_file))\n    default_model = prompt(\n        \"Enter your default model (e.g., anthropic/claude-sonnet-4-5-20250929): \",\n        default=os.getenv(\"MSWEA_MODEL_NAME\", \"\"),\n    ).strip()\n    if default_model:\n        set_key(global_config_file, \"MSWEA_MODEL_NAME\", default_model)\n    console.print(\n        \"[bold yellow]If you already have your API keys set as environment variables, you can ignore the next question.[/bold yellow]\"\n    )\n    key_name = prompt(\"Enter your API key name (e.g., ANTHROPIC_API_KEY): \").strip()\n    key_value = None\n    if key_name:\n        key_value = prompt(\"Enter your API key value (e.g., sk-1234567890): \", default=os.getenv(key_name, \"\")).strip()\n        if key_value:\n            set_key(global_config_file, key_name, key_value)\n    if not key_value:\n        console.print(\n            \"[bold red]API key setup not completed.[/bold red] Totally fine if you have your keys as environment variables.\"\n        )\n    set_key(global_config_file, \"MSWEA_CONFIGURED\", \"true\")\n    console.print(\n        \"\\n[bold yellow]Config finished.[/bold yellow] If you want to revisit it, run [bold green]mini-extra config setup[/bold green].\"\n    )\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.set","title":"set","text":"<pre><code>set(\n    key: str | None = Argument(None, help=\"The key to set\"),\n    value: str | None = Argument(\n        None, help=\"The value to set\"\n    ),\n)\n</code></pre> <p>Set a key in the global config file.</p> Source code in <code>src/minisweagent/run/utilities/config.py</code> <pre><code>@app.command()\ndef set(\n    key: str | None = Argument(None, help=\"The key to set\"),\n    value: str | None = Argument(None, help=\"The value to set\"),\n):\n    \"\"\"Set a key in the global config file.\"\"\"\n    if key is None:\n        key = prompt(\"Enter the key to set: \")\n    if value is None:\n        value = prompt(f\"Enter the value for {key}: \")\n    set_key(global_config_file, key, value)\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.unset","title":"unset","text":"<pre><code>unset(\n    key: str | None = Argument(\n        None, help=\"The key to unset\"\n    ),\n)\n</code></pre> <p>Unset a key in the global config file.</p> Source code in <code>src/minisweagent/run/utilities/config.py</code> <pre><code>@app.command()\ndef unset(key: str | None = Argument(None, help=\"The key to unset\")):\n    \"\"\"Unset a key in the global config file.\"\"\"\n    if key is None:\n        key = prompt(\"Enter the key to unset: \")\n    unset_key(global_config_file, key)\n</code></pre>"},{"location":"reference/run/config/#minisweagent.run.utilities.config.edit","title":"edit","text":"<pre><code>edit()\n</code></pre> <p>Edit the global config file.</p> Source code in <code>src/minisweagent/run/utilities/config.py</code> <pre><code>@app.command()\ndef edit():\n    \"\"\"Edit the global config file.\"\"\"\n    editor = os.getenv(\"EDITOR\", \"nano\")\n    subprocess.run([editor, global_config_file])\n</code></pre>"},{"location":"reference/run/hello_world/","title":"Hello World","text":""},{"location":"reference/run/hello_world/#hello-world","title":"Hello World","text":"<p>Hello World run script</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>\"\"\"This is the simplest possible example of how to use mini-SWE-agent with python bindings.\nFor a more complete example, see mini.py\n\"\"\"\n\nimport logging\nimport os\nfrom pathlib import Path\n\nimport typer\nimport yaml\n\nfrom minisweagent import package_dir\nfrom minisweagent.agents.default import DefaultAgent\nfrom minisweagent.environments.local import LocalEnvironment\nfrom minisweagent.models.litellm_model import LitellmModel\n\napp = typer.Typer()\n\n\n@app.command()\ndef main(\n    task: str = typer.Option(..., \"-t\", \"--task\", help=\"Task/problem statement\", show_default=False, prompt=True),\n    model_name: str = typer.Option(\n        os.getenv(\"MSWEA_MODEL_NAME\"),\n        \"-m\",\n        \"--model\",\n        help=\"Model name (defaults to MSWEA_MODEL_NAME env var)\",\n        prompt=\"What model do you want to use?\",\n    ),\n) -&gt; DefaultAgent:\n    logging.basicConfig(level=logging.DEBUG)\n    agent = DefaultAgent(\n        LitellmModel(model_name=model_name),\n        LocalEnvironment(),\n        **yaml.safe_load(Path(package_dir / \"config\" / \"default.yaml\").read_text())[\"agent\"],\n    )\n    agent.run(task)\n    return agent\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/hello_world/#minisweagent.run.hello_world","title":"minisweagent.run.hello_world","text":"<p>This is the simplest possible example of how to use mini-SWE-agent with python bindings. For a more complete example, see mini.py</p>"},{"location":"reference/run/hello_world/#minisweagent.run.hello_world.app","title":"app  <code>module-attribute</code>","text":"<pre><code>app = Typer()\n</code></pre>"},{"location":"reference/run/hello_world/#minisweagent.run.hello_world.main","title":"main","text":"<pre><code>main(\n    task: str = Option(\n        ...,\n        \"-t\",\n        \"--task\",\n        help=\"Task/problem statement\",\n        show_default=False,\n        prompt=True,\n    ),\n    model_name: str = Option(\n        getenv(\"MSWEA_MODEL_NAME\"),\n        \"-m\",\n        \"--model\",\n        help=\"Model name (defaults to MSWEA_MODEL_NAME env var)\",\n        prompt=\"What model do you want to use?\",\n    ),\n) -&gt; DefaultAgent\n</code></pre> Source code in <code>src/minisweagent/run/hello_world.py</code> <pre><code>@app.command()\ndef main(\n    task: str = typer.Option(..., \"-t\", \"--task\", help=\"Task/problem statement\", show_default=False, prompt=True),\n    model_name: str = typer.Option(\n        os.getenv(\"MSWEA_MODEL_NAME\"),\n        \"-m\",\n        \"--model\",\n        help=\"Model name (defaults to MSWEA_MODEL_NAME env var)\",\n        prompt=\"What model do you want to use?\",\n    ),\n) -&gt; DefaultAgent:\n    logging.basicConfig(level=logging.DEBUG)\n    agent = DefaultAgent(\n        LitellmModel(model_name=model_name),\n        LocalEnvironment(),\n        **yaml.safe_load(Path(package_dir / \"config\" / \"default.yaml\").read_text())[\"agent\"],\n    )\n    agent.run(task)\n    return agent\n</code></pre>"},{"location":"reference/run/inspector/","title":"Inspector","text":""},{"location":"reference/run/inspector/#inspector","title":"Inspector","text":"<p>Trajectory Inspector</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>#!/usr/bin/env python3\n\"\"\"\nSimple trajectory inspector for browsing agent conversation trajectories.\n\nMore information about the usage: [bold green] https://mini-swe-agent.com/latest/usage/inspector/ [/bold green].\n\"\"\"\n\nimport json\nimport os\nimport subprocess\nimport tempfile\nfrom pathlib import Path\n\nimport typer\nfrom rich.text import Text\nfrom textual.app import App, ComposeResult\nfrom textual.binding import Binding\nfrom textual.command import DiscoveryHit, Hit, Hits, Provider\nfrom textual.containers import Container, Vertical, VerticalScroll\nfrom textual.widgets import Footer, Header, Static\n\nfrom minisweagent.models.utils.content_string import get_content_string\n\n\ndef _messages_to_steps(messages: list[dict]) -&gt; list[list[dict]]:\n    \"\"\"Group messages into \"pages\" as shown by the UI.\"\"\"\n    steps = []\n    current_step = []\n    for message in messages:\n        # Start new step with new tool uses\n        if message.get(\"extra\", {}).get(\"actions\") or message.get(\"role\") == \"assistant\":\n            steps.append(current_step)\n            current_step = [message]\n        else:\n            current_step.append(message)\n    if current_step:\n        steps.append(current_step)\n    return steps\n\n\napp = typer.Typer(rich_markup_mode=\"rich\", add_completion=False)\n\n\nclass BindingCommandProvider(Provider):\n    \"\"\"Provide bindings as commands in the palette.\"\"\"\n\n    COMMAND_DESCRIPTIONS = {\n        \"next_step\": \"Next step in the current trajectory\",\n        \"previous_step\": \"Previous step in the current trajectory\",\n        \"first_step\": \"First step in the current trajectory\",\n        \"last_step\": \"Last step in the current trajectory\",\n        \"scroll_down\": \"Scroll down\",\n        \"scroll_up\": \"Scroll up\",\n        \"next_trajectory\": \"Next trajectory\",\n        \"previous_trajectory\": \"Previous trajectory\",\n        \"open_in_jless\": \"Open the current step in jless\",\n        \"open_in_jless_all\": \"Open the entire trajectory in jless\",\n        \"quit\": \"Quit the inspector\",\n    }\n\n    async def discover(self) -&gt; Hits:\n        app = self.app\n        for binding in app.BINDINGS:\n            desc = self.COMMAND_DESCRIPTIONS.get(binding.action, binding.description)\n            yield DiscoveryHit(desc, lambda b=binding: app.run_action(b.action))\n\n    async def search(self, query: str) -&gt; Hits:\n        matcher = self.matcher(query)\n        app = self.app\n        for binding in app.BINDINGS:\n            desc = self.COMMAND_DESCRIPTIONS.get(binding.action, binding.description)\n            score = matcher.match(desc)\n            if score &gt; 0:\n                yield Hit(score, matcher.highlight(desc), lambda b=binding: app.run_action(b.action))\n\n\nclass TrajectoryInspector(App):\n    COMMANDS = {BindingCommandProvider}\n    BINDINGS = [\n        Binding(\"right,l\", \"next_step\", \"Step++\"),\n        Binding(\"left,h\", \"previous_step\", \"Step--\"),\n        Binding(\"0\", \"first_step\", \"Step=0\"),\n        Binding(\"$\", \"last_step\", \"Step=-1\"),\n        Binding(\"j,down\", \"scroll_down\", \"\u2193\"),\n        Binding(\"k,up\", \"scroll_up\", \"\u2191\"),\n        Binding(\"L\", \"next_trajectory\", \"Traj++\"),\n        Binding(\"H\", \"previous_trajectory\", \"Traj--\"),\n        Binding(\"e\", \"open_in_jless\", \"Jless\"),\n        Binding(\"E\", \"open_in_jless_all\", \"Jless (all)\"),\n        Binding(\"q\", \"quit\", \"Quit\"),\n    ]\n\n    def __init__(self, trajectory_files: list[Path]):\n        css_path = os.environ.get(\n            \"MSWEA_INSPECTOR_STYLE_PATH\", str(Path(__file__).parent.parent.parent / \"config\" / \"inspector.tcss\")\n        )\n        self.__class__.CSS = Path(css_path).read_text()\n\n        super().__init__()\n        self.trajectory_files = trajectory_files\n        self._i_trajectory = 0\n        self._i_step = 0\n        self.messages = []\n        self.steps = []\n\n        if trajectory_files:\n            self._load_current_trajectory()\n\n    # --- Basics ---\n\n    @property\n    def i_step(self) -&gt; int:\n        \"\"\"Current step index.\"\"\"\n        return self._i_step\n\n    @i_step.setter\n    def i_step(self, value: int) -&gt; None:\n        \"\"\"Set current step index, automatically clamping to valid bounds.\"\"\"\n        if value != self._i_step and self.n_steps &gt; 0:\n            self._i_step = max(0, min(value, self.n_steps - 1))\n            self.query_one(VerticalScroll).scroll_to(y=0, animate=False)\n            self.update_content()\n\n    @property\n    def n_steps(self) -&gt; int:\n        \"\"\"Number of steps in current trajectory.\"\"\"\n        return len(self.steps)\n\n    @property\n    def i_trajectory(self) -&gt; int:\n        \"\"\"Current trajectory index.\"\"\"\n        return self._i_trajectory\n\n    @i_trajectory.setter\n    def i_trajectory(self, value: int) -&gt; None:\n        \"\"\"Set current trajectory index, automatically clamping to valid bounds.\"\"\"\n        if value != self._i_trajectory and self.n_trajectories &gt; 0:\n            self._i_trajectory = max(0, min(value, self.n_trajectories - 1))\n            self._load_current_trajectory()\n            self.query_one(VerticalScroll).scroll_to(y=0, animate=False)\n            self.update_content()\n\n    @property\n    def n_trajectories(self) -&gt; int:\n        \"\"\"Number of trajectory files.\"\"\"\n        return len(self.trajectory_files)\n\n    def _load_current_trajectory(self) -&gt; None:\n        \"\"\"Load the currently selected trajectory file.\"\"\"\n        if not self.trajectory_files:\n            self.messages = []\n            self.steps = []\n            return\n\n        trajectory_file = self.trajectory_files[self.i_trajectory]\n        try:\n            data = json.loads(trajectory_file.read_text())\n\n            if isinstance(data, list):\n                self.messages = data\n            elif isinstance(data, dict) and \"messages\" in data:\n                self.messages = data[\"messages\"]\n            else:\n                raise ValueError(\"Unrecognized trajectory format\")\n\n            self.steps = _messages_to_steps(self.messages)\n            self._i_step = 0\n        except (json.JSONDecodeError, FileNotFoundError, ValueError) as e:\n            self.messages = []\n            self.steps = []\n            self.notify(f\"Error loading {trajectory_file.name}: {e}\", severity=\"error\")\n\n    @property\n    def current_trajectory_name(self) -&gt; str:\n        \"\"\"Get the name of the current trajectory file.\"\"\"\n        if not self.trajectory_files:\n            return \"No trajectories\"\n        return self.trajectory_files[self.i_trajectory].name\n\n    def compose(self) -&gt; ComposeResult:\n        yield Header()\n        with Container(id=\"main\"):\n            with VerticalScroll():\n                yield Vertical(id=\"content\")\n        yield Footer()\n\n    def on_mount(self) -&gt; None:\n        self.update_content()\n\n    def update_content(self) -&gt; None:\n        \"\"\"Update the displayed content.\"\"\"\n        container = self.query_one(\"#content\", Vertical)\n        container.remove_children()\n\n        if not self.steps:\n            container.mount(Static(\"No trajectory loaded or empty trajectory\"))\n            self.title = \"Trajectory Inspector - No Data\"\n            return\n\n        for message in self.steps[self.i_step]:\n            content_str = get_content_string(message)\n            message_container = Vertical(classes=\"message-container\")\n            container.mount(message_container)\n            role = message.get(\"role\") or message.get(\"type\") or \"unknown\"\n            message_container.mount(Static(role.upper(), classes=\"message-header\"))\n            message_container.mount(Static(Text(content_str, no_wrap=False), classes=\"message-content\"))\n\n        self.title = (\n            f\"Trajectory {self.i_trajectory + 1}/{self.n_trajectories} - \"\n            f\"{self.current_trajectory_name} - \"\n            f\"Step {self.i_step + 1}/{self.n_steps}\"\n        )\n\n    # --- Navigation actions ---\n\n    def action_next_step(self) -&gt; None:\n        self.i_step += 1\n\n    def action_previous_step(self) -&gt; None:\n        self.i_step -= 1\n\n    def action_first_step(self) -&gt; None:\n        self.i_step = 0\n\n    def action_last_step(self) -&gt; None:\n        self.i_step = self.n_steps - 1\n\n    def action_next_trajectory(self) -&gt; None:\n        self.i_trajectory += 1\n\n    def action_previous_trajectory(self) -&gt; None:\n        self.i_trajectory -= 1\n\n    def action_scroll_down(self) -&gt; None:\n        vs = self.query_one(VerticalScroll)\n        vs.scroll_to(y=vs.scroll_target_y + 15)\n\n    def action_scroll_up(self) -&gt; None:\n        vs = self.query_one(VerticalScroll)\n        vs.scroll_to(y=vs.scroll_target_y - 15)\n\n    def _open_in_jless(self, path: Path) -&gt; None:\n        \"\"\"Open file in jless.\"\"\"\n        with self.suspend():\n            try:\n                subprocess.run([\"jless\", path])\n            except FileNotFoundError:\n                self.notify(\"jless not found. Install with: `brew install jless`\", severity=\"error\")\n\n    def action_open_in_jless(self) -&gt; None:\n        \"\"\"Open the current step's messages in jless.\"\"\"\n        if not self.steps:\n            self.notify(\"No messages to display\", severity=\"warning\")\n            return\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n            json.dump(self.steps[self.i_step], f, indent=2)\n            temp_path = Path(f.name)\n        self._open_in_jless(temp_path)\n        temp_path.unlink()\n\n    def action_open_in_jless_all(self) -&gt; None:\n        \"\"\"Open the entire trajectory in jless.\"\"\"\n        if not self.trajectory_files:\n            self.notify(\"No trajectory to display\", severity=\"warning\")\n            return\n        self._open_in_jless(self.trajectory_files[self.i_trajectory])\n\n\n@app.command(help=__doc__)\ndef main(\n    path: str = typer.Argument(\".\", help=\"Directory to search for trajectory files or specific trajectory file\"),\n) -&gt; None:\n    path_obj = Path(path)\n\n    if path_obj.is_file():\n        trajectory_files = [path_obj]\n    elif path_obj.is_dir():\n        trajectory_files = sorted(path_obj.rglob(\"*.traj.json\"))\n        if not trajectory_files:\n            raise typer.BadParameter(f\"No trajectory files found in '{path}'\")\n    else:\n        raise typer.BadParameter(f\"Error: Path '{path}' does not exist\")\n\n    inspector = TrajectoryInspector(trajectory_files)\n    inspector.run()\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector","title":"minisweagent.run.utilities.inspector","text":"<p>Simple trajectory inspector for browsing agent conversation trajectories.</p> <p>More information about the usage: [bold green] https://mini-swe-agent.com/latest/usage/inspector/ [/bold green].</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.app","title":"app  <code>module-attribute</code>","text":"<pre><code>app = Typer(rich_markup_mode='rich', add_completion=False)\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.BindingCommandProvider","title":"BindingCommandProvider","text":"<p>               Bases: <code>Provider</code></p> <p>Provide bindings as commands in the palette.</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.BindingCommandProvider.COMMAND_DESCRIPTIONS","title":"COMMAND_DESCRIPTIONS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMMAND_DESCRIPTIONS = {\n    \"next_step\": \"Next step in the current trajectory\",\n    \"previous_step\": \"Previous step in the current trajectory\",\n    \"first_step\": \"First step in the current trajectory\",\n    \"last_step\": \"Last step in the current trajectory\",\n    \"scroll_down\": \"Scroll down\",\n    \"scroll_up\": \"Scroll up\",\n    \"next_trajectory\": \"Next trajectory\",\n    \"previous_trajectory\": \"Previous trajectory\",\n    \"open_in_jless\": \"Open the current step in jless\",\n    \"open_in_jless_all\": \"Open the entire trajectory in jless\",\n    \"quit\": \"Quit the inspector\",\n}\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.BindingCommandProvider.discover","title":"discover  <code>async</code>","text":"<pre><code>discover() -&gt; Hits\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>async def discover(self) -&gt; Hits:\n    app = self.app\n    for binding in app.BINDINGS:\n        desc = self.COMMAND_DESCRIPTIONS.get(binding.action, binding.description)\n        yield DiscoveryHit(desc, lambda b=binding: app.run_action(b.action))\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.BindingCommandProvider.search","title":"search  <code>async</code>","text":"<pre><code>search(query: str) -&gt; Hits\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>async def search(self, query: str) -&gt; Hits:\n    matcher = self.matcher(query)\n    app = self.app\n    for binding in app.BINDINGS:\n        desc = self.COMMAND_DESCRIPTIONS.get(binding.action, binding.description)\n        score = matcher.match(desc)\n        if score &gt; 0:\n            yield Hit(score, matcher.highlight(desc), lambda b=binding: app.run_action(b.action))\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector","title":"TrajectoryInspector","text":"<pre><code>TrajectoryInspector(trajectory_files: list[Path])\n</code></pre> <p>               Bases: <code>App</code></p> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def __init__(self, trajectory_files: list[Path]):\n    css_path = os.environ.get(\n        \"MSWEA_INSPECTOR_STYLE_PATH\", str(Path(__file__).parent.parent.parent / \"config\" / \"inspector.tcss\")\n    )\n    self.__class__.CSS = Path(css_path).read_text()\n\n    super().__init__()\n    self.trajectory_files = trajectory_files\n    self._i_trajectory = 0\n    self._i_step = 0\n    self.messages = []\n    self.steps = []\n\n    if trajectory_files:\n        self._load_current_trajectory()\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.COMMANDS","title":"COMMANDS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMMANDS = {BindingCommandProvider}\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.BINDINGS","title":"BINDINGS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BINDINGS = [\n    Binding(\"right,l\", \"next_step\", \"Step++\"),\n    Binding(\"left,h\", \"previous_step\", \"Step--\"),\n    Binding(\"0\", \"first_step\", \"Step=0\"),\n    Binding(\"$\", \"last_step\", \"Step=-1\"),\n    Binding(\"j,down\", \"scroll_down\", \"\u2193\"),\n    Binding(\"k,up\", \"scroll_up\", \"\u2191\"),\n    Binding(\"L\", \"next_trajectory\", \"Traj++\"),\n    Binding(\"H\", \"previous_trajectory\", \"Traj--\"),\n    Binding(\"e\", \"open_in_jless\", \"Jless\"),\n    Binding(\"E\", \"open_in_jless_all\", \"Jless (all)\"),\n    Binding(\"q\", \"quit\", \"Quit\"),\n]\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.trajectory_files","title":"trajectory_files  <code>instance-attribute</code>","text":"<pre><code>trajectory_files = trajectory_files\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.messages","title":"messages  <code>instance-attribute</code>","text":"<pre><code>messages = []\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.steps","title":"steps  <code>instance-attribute</code>","text":"<pre><code>steps = []\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.i_step","title":"i_step  <code>property</code> <code>writable</code>","text":"<pre><code>i_step: int\n</code></pre> <p>Current step index.</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.n_steps","title":"n_steps  <code>property</code>","text":"<pre><code>n_steps: int\n</code></pre> <p>Number of steps in current trajectory.</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.i_trajectory","title":"i_trajectory  <code>property</code> <code>writable</code>","text":"<pre><code>i_trajectory: int\n</code></pre> <p>Current trajectory index.</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.n_trajectories","title":"n_trajectories  <code>property</code>","text":"<pre><code>n_trajectories: int\n</code></pre> <p>Number of trajectory files.</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.current_trajectory_name","title":"current_trajectory_name  <code>property</code>","text":"<pre><code>current_trajectory_name: str\n</code></pre> <p>Get the name of the current trajectory file.</p>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.compose","title":"compose","text":"<pre><code>compose() -&gt; ComposeResult\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def compose(self) -&gt; ComposeResult:\n    yield Header()\n    with Container(id=\"main\"):\n        with VerticalScroll():\n            yield Vertical(id=\"content\")\n    yield Footer()\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.on_mount","title":"on_mount","text":"<pre><code>on_mount() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def on_mount(self) -&gt; None:\n    self.update_content()\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.update_content","title":"update_content","text":"<pre><code>update_content() -&gt; None\n</code></pre> <p>Update the displayed content.</p> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def update_content(self) -&gt; None:\n    \"\"\"Update the displayed content.\"\"\"\n    container = self.query_one(\"#content\", Vertical)\n    container.remove_children()\n\n    if not self.steps:\n        container.mount(Static(\"No trajectory loaded or empty trajectory\"))\n        self.title = \"Trajectory Inspector - No Data\"\n        return\n\n    for message in self.steps[self.i_step]:\n        content_str = get_content_string(message)\n        message_container = Vertical(classes=\"message-container\")\n        container.mount(message_container)\n        role = message.get(\"role\") or message.get(\"type\") or \"unknown\"\n        message_container.mount(Static(role.upper(), classes=\"message-header\"))\n        message_container.mount(Static(Text(content_str, no_wrap=False), classes=\"message-content\"))\n\n    self.title = (\n        f\"Trajectory {self.i_trajectory + 1}/{self.n_trajectories} - \"\n        f\"{self.current_trajectory_name} - \"\n        f\"Step {self.i_step + 1}/{self.n_steps}\"\n    )\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_next_step","title":"action_next_step","text":"<pre><code>action_next_step() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_next_step(self) -&gt; None:\n    self.i_step += 1\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_previous_step","title":"action_previous_step","text":"<pre><code>action_previous_step() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_previous_step(self) -&gt; None:\n    self.i_step -= 1\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_first_step","title":"action_first_step","text":"<pre><code>action_first_step() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_first_step(self) -&gt; None:\n    self.i_step = 0\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_last_step","title":"action_last_step","text":"<pre><code>action_last_step() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_last_step(self) -&gt; None:\n    self.i_step = self.n_steps - 1\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_next_trajectory","title":"action_next_trajectory","text":"<pre><code>action_next_trajectory() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_next_trajectory(self) -&gt; None:\n    self.i_trajectory += 1\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_previous_trajectory","title":"action_previous_trajectory","text":"<pre><code>action_previous_trajectory() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_previous_trajectory(self) -&gt; None:\n    self.i_trajectory -= 1\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_scroll_down","title":"action_scroll_down","text":"<pre><code>action_scroll_down() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_scroll_down(self) -&gt; None:\n    vs = self.query_one(VerticalScroll)\n    vs.scroll_to(y=vs.scroll_target_y + 15)\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_scroll_up","title":"action_scroll_up","text":"<pre><code>action_scroll_up() -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_scroll_up(self) -&gt; None:\n    vs = self.query_one(VerticalScroll)\n    vs.scroll_to(y=vs.scroll_target_y - 15)\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_open_in_jless","title":"action_open_in_jless","text":"<pre><code>action_open_in_jless() -&gt; None\n</code></pre> <p>Open the current step's messages in jless.</p> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_open_in_jless(self) -&gt; None:\n    \"\"\"Open the current step's messages in jless.\"\"\"\n    if not self.steps:\n        self.notify(\"No messages to display\", severity=\"warning\")\n        return\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n        json.dump(self.steps[self.i_step], f, indent=2)\n        temp_path = Path(f.name)\n    self._open_in_jless(temp_path)\n    temp_path.unlink()\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.TrajectoryInspector.action_open_in_jless_all","title":"action_open_in_jless_all","text":"<pre><code>action_open_in_jless_all() -&gt; None\n</code></pre> <p>Open the entire trajectory in jless.</p> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>def action_open_in_jless_all(self) -&gt; None:\n    \"\"\"Open the entire trajectory in jless.\"\"\"\n    if not self.trajectory_files:\n        self.notify(\"No trajectory to display\", severity=\"warning\")\n        return\n    self._open_in_jless(self.trajectory_files[self.i_trajectory])\n</code></pre>"},{"location":"reference/run/inspector/#minisweagent.run.utilities.inspector.main","title":"main","text":"<pre><code>main(\n    path: str = Argument(\n        \".\",\n        help=\"Directory to search for trajectory files or specific trajectory file\",\n    ),\n) -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/utilities/inspector.py</code> <pre><code>@app.command(help=__doc__)\ndef main(\n    path: str = typer.Argument(\".\", help=\"Directory to search for trajectory files or specific trajectory file\"),\n) -&gt; None:\n    path_obj = Path(path)\n\n    if path_obj.is_file():\n        trajectory_files = [path_obj]\n    elif path_obj.is_dir():\n        trajectory_files = sorted(path_obj.rglob(\"*.traj.json\"))\n        if not trajectory_files:\n            raise typer.BadParameter(f\"No trajectory files found in '{path}'\")\n    else:\n        raise typer.BadParameter(f\"Error: Path '{path}' does not exist\")\n\n    inspector = TrajectoryInspector(trajectory_files)\n    inspector.run()\n</code></pre>"},{"location":"reference/run/mini/","title":"mini","text":""},{"location":"reference/run/mini/#local","title":"Local","text":"<p>Mini run script</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>#!/usr/bin/env python3\n\n\"\"\"Run mini-SWE-agent in your local environment. This is the default executable `mini`.\"\"\"\n# Read this first: https://mini-swe-agent.com/latest/usage/mini/  (usage)\n\nimport os\nfrom pathlib import Path\nfrom typing import Any\n\nimport typer\nfrom rich.console import Console\n\nfrom minisweagent import global_config_dir\nfrom minisweagent.agents import get_agent\nfrom minisweagent.agents.utils.prompt_user import _multiline_prompt\nfrom minisweagent.config import builtin_config_dir, get_config_from_spec\nfrom minisweagent.environments import get_environment\nfrom minisweagent.models import get_model\nfrom minisweagent.run.utilities.config import configure_if_first_time\nfrom minisweagent.utils.serialize import UNSET, recursive_merge\n\nDEFAULT_CONFIG_FILE = Path(os.getenv(\"MSWEA_MINI_CONFIG_PATH\", builtin_config_dir / \"mini.yaml\"))\nDEFAULT_OUTPUT_FILE = global_config_dir / \"last_mini_run.traj.json\"\n\n\n_HELP_TEXT = \"\"\"Run mini-SWE-agent in your local environment.\n\n[not dim]\nMore information about the usage: [bold green]https://mini-swe-agent.com/latest/usage/mini/[/bold green]\n[/not dim]\n\"\"\"\n\n_CONFIG_SPEC_HELP_TEXT = \"\"\"Path to config files, filenames, or key-value pairs.\n\n[bold red]IMPORTANT:[/bold red] [red]If you set this option, the default config file will not be used.[/red]\nSo you need to explicitly set it e.g., with [bold green]-c mini.yaml &lt;other options&gt;[/bold green]\n\nMultiple configs will be recursively merged.\n\nExamples:\n\n[bold red]-c model.model_kwargs.temperature=0[/bold red] [red]You forgot to add the default config file! See above.[/red]\n\n[bold green]-c mini.yaml -c model.model_kwargs.temperature=0.5[/bold green]\n\n[bold green]-c swebench.yaml agent.mode=yolo[/bold green]\n\"\"\"\n\nconsole = Console(highlight=False)\napp = typer.Typer(rich_markup_mode=\"rich\")\n\n\n# fmt: off\n@app.command(help=_HELP_TEXT)\ndef main(\n    model_name: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\",),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'litellm' or 'minisweagent.models.litellm_model.LitellmModel')\", rich_help_panel=\"Advanced\"),\n    agent_class: str | None = typer.Option(None, \"--agent-class\", help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\", rich_help_panel=\"Advanced\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment class to use (e.g., 'local' or 'minisweagent.environments.local.LocalEnvironment')\", rich_help_panel=\"Advanced\"),\n    task: str | None = typer.Option(None, \"-t\", \"--task\", help=\"Task/problem statement\", show_default=False),\n    yolo: bool = typer.Option(False, \"-y\", \"--yolo\", help=\"Run without confirmation\"),\n    cost_limit: float | None = typer.Option(None, \"-l\", \"--cost-limit\", help=\"Cost limit. Set to 0 to disable.\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT),\n    output: Path | None = typer.Option(DEFAULT_OUTPUT_FILE, \"-o\", \"--output\", help=\"Output trajectory file\"),\n    exit_immediately: bool = typer.Option(False, \"--exit-immediately\", help=\"Exit immediately when the agent wants to finish instead of prompting.\", rich_help_panel=\"Advanced\"),\n) -&gt; Any:\n    # fmt: on\n    configure_if_first_time()\n\n    # Build the config from the command line arguments\n    console.print(f\"Building agent config from specs: [bold green]{config_spec}[/bold green]\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"run\": {\n            \"task\": task or UNSET,\n        },\n        \"agent\": {\n            \"agent_class\": agent_class or UNSET,\n            \"mode\": \"yolo\" if yolo else UNSET,\n            \"cost_limit\": cost_limit or UNSET,\n            \"confirm_exit\": False if exit_immediately else UNSET,\n            \"output_path\": output or UNSET,\n        },\n        \"model\": {\n            \"model_class\": model_class or UNSET,\n            \"model_name\": model_name or UNSET,\n        },\n        \"environment\": {\n            \"environment_class\": environment_class or UNSET,\n        },\n    })\n    config = recursive_merge(*configs)\n\n    if (run_task := config.get(\"run\", {}).get(\"task\", UNSET)) is UNSET:\n        console.print(\"[bold yellow]What do you want to do?\")\n        run_task = _multiline_prompt()\n        console.print(\"[bold green]Got that, thanks![/bold green]\")\n\n    model = get_model(config=config.get(\"model\", {}))\n    env = get_environment(config.get(\"environment\", {}), default_type=\"local\")\n    agent = get_agent(model, env, config.get(\"agent\", {}), default_type=\"interactive\")\n    agent.run(run_task)\n    if (output_path := config.get(\"agent\", {}).get(\"output_path\")):\n        console.print(f\"Saved trajectory to [bold green]'{output_path}'[/bold green]\")\n    return agent\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/mini/#minisweagent.run.mini","title":"minisweagent.run.mini","text":"<p>Run mini-SWE-agent in your local environment. This is the default executable <code>mini</code>.</p>"},{"location":"reference/run/mini/#minisweagent.run.mini.DEFAULT_CONFIG_FILE","title":"DEFAULT_CONFIG_FILE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CONFIG_FILE = Path(\n    getenv(\n        \"MSWEA_MINI_CONFIG_PATH\",\n        builtin_config_dir / \"mini.yaml\",\n    )\n)\n</code></pre>"},{"location":"reference/run/mini/#minisweagent.run.mini.DEFAULT_OUTPUT_FILE","title":"DEFAULT_OUTPUT_FILE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_OUTPUT_FILE = (\n    global_config_dir / \"last_mini_run.traj.json\"\n)\n</code></pre>"},{"location":"reference/run/mini/#minisweagent.run.mini.console","title":"console  <code>module-attribute</code>","text":"<pre><code>console = Console(highlight=False)\n</code></pre>"},{"location":"reference/run/mini/#minisweagent.run.mini.app","title":"app  <code>module-attribute</code>","text":"<pre><code>app = Typer(rich_markup_mode='rich')\n</code></pre>"},{"location":"reference/run/mini/#minisweagent.run.mini.main","title":"main","text":"<pre><code>main(\n    model_name: str | None = Option(\n        None, \"-m\", \"--model\", help=\"Model to use\"\n    ),\n    model_class: str | None = Option(\n        None,\n        \"--model-class\",\n        help=\"Model class to use (e.g., 'litellm' or 'minisweagent.models.litellm_model.LitellmModel')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    agent_class: str | None = Option(\n        None,\n        \"--agent-class\",\n        help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    environment_class: str | None = Option(\n        None,\n        \"--environment-class\",\n        help=\"Environment class to use (e.g., 'local' or 'minisweagent.environments.local.LocalEnvironment')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    task: str | None = Option(\n        None,\n        \"-t\",\n        \"--task\",\n        help=\"Task/problem statement\",\n        show_default=False,\n    ),\n    yolo: bool = Option(\n        False,\n        \"-y\",\n        \"--yolo\",\n        help=\"Run without confirmation\",\n    ),\n    cost_limit: float | None = Option(\n        None,\n        \"-l\",\n        \"--cost-limit\",\n        help=\"Cost limit. Set to 0 to disable.\",\n    ),\n    config_spec: list[str] = Option(\n        [str(DEFAULT_CONFIG_FILE)],\n        \"-c\",\n        \"--config\",\n        help=_CONFIG_SPEC_HELP_TEXT,\n    ),\n    output: Path | None = Option(\n        DEFAULT_OUTPUT_FILE,\n        \"-o\",\n        \"--output\",\n        help=\"Output trajectory file\",\n    ),\n    exit_immediately: bool = Option(\n        False,\n        \"--exit-immediately\",\n        help=\"Exit immediately when the agent wants to finish instead of prompting.\",\n        rich_help_panel=\"Advanced\",\n    ),\n) -&gt; Any\n</code></pre> Source code in <code>src/minisweagent/run/mini.py</code> <pre><code>@app.command(help=_HELP_TEXT)\ndef main(\n    model_name: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\",),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'litellm' or 'minisweagent.models.litellm_model.LitellmModel')\", rich_help_panel=\"Advanced\"),\n    agent_class: str | None = typer.Option(None, \"--agent-class\", help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\", rich_help_panel=\"Advanced\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment class to use (e.g., 'local' or 'minisweagent.environments.local.LocalEnvironment')\", rich_help_panel=\"Advanced\"),\n    task: str | None = typer.Option(None, \"-t\", \"--task\", help=\"Task/problem statement\", show_default=False),\n    yolo: bool = typer.Option(False, \"-y\", \"--yolo\", help=\"Run without confirmation\"),\n    cost_limit: float | None = typer.Option(None, \"-l\", \"--cost-limit\", help=\"Cost limit. Set to 0 to disable.\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT),\n    output: Path | None = typer.Option(DEFAULT_OUTPUT_FILE, \"-o\", \"--output\", help=\"Output trajectory file\"),\n    exit_immediately: bool = typer.Option(False, \"--exit-immediately\", help=\"Exit immediately when the agent wants to finish instead of prompting.\", rich_help_panel=\"Advanced\"),\n) -&gt; Any:\n    # fmt: on\n    configure_if_first_time()\n\n    # Build the config from the command line arguments\n    console.print(f\"Building agent config from specs: [bold green]{config_spec}[/bold green]\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"run\": {\n            \"task\": task or UNSET,\n        },\n        \"agent\": {\n            \"agent_class\": agent_class or UNSET,\n            \"mode\": \"yolo\" if yolo else UNSET,\n            \"cost_limit\": cost_limit or UNSET,\n            \"confirm_exit\": False if exit_immediately else UNSET,\n            \"output_path\": output or UNSET,\n        },\n        \"model\": {\n            \"model_class\": model_class or UNSET,\n            \"model_name\": model_name or UNSET,\n        },\n        \"environment\": {\n            \"environment_class\": environment_class or UNSET,\n        },\n    })\n    config = recursive_merge(*configs)\n\n    if (run_task := config.get(\"run\", {}).get(\"task\", UNSET)) is UNSET:\n        console.print(\"[bold yellow]What do you want to do?\")\n        run_task = _multiline_prompt()\n        console.print(\"[bold green]Got that, thanks![/bold green]\")\n\n    model = get_model(config=config.get(\"model\", {}))\n    env = get_environment(config.get(\"environment\", {}), default_type=\"local\")\n    agent = get_agent(model, env, config.get(\"agent\", {}), default_type=\"interactive\")\n    agent.run(run_task)\n    if (output_path := config.get(\"agent\", {}).get(\"output_path\")):\n        console.print(f\"Saved trajectory to [bold green]'{output_path}'[/bold green]\")\n    return agent\n</code></pre>"},{"location":"reference/run/mini_extra/","title":"mini-extra","text":""},{"location":"reference/run/mini_extra/#mini-extra","title":"Mini Extra","text":"<p>Mini Extra CLI</p> <ul> <li>Read on GitHub</li> </ul> Full source code <pre><code>#!/usr/bin/env python3\n\n\"\"\"This is the central entry point to the mini-extra script. Use subcommands\nto invoke other command line utilities like running on benchmarks, editing config,\ninspecting trajectories, etc.\n\"\"\"\n\nimport sys\nfrom importlib import import_module\n\nfrom rich.console import Console\n\nsubcommands = [\n    (\"minisweagent.run.utilities.config\", [\"config\"], \"Manage the global config file\"),\n    (\"minisweagent.run.utilities.inspector\", [\"inspect\", \"i\", \"inspector\"], \"Run inspector (browse trajectories)\"),\n    (\"minisweagent.run.benchmarks.swebench\", [\"swebench\"], \"Evaluate on SWE-bench (batch mode)\"),\n    (\"minisweagent.run.benchmarks.swebench_single\", [\"swebench-single\"], \"Evaluate on SWE-bench (single instance)\"),\n]\n\n\ndef get_docstring() -&gt; str:\n    lines = [\n        \"This is the [yellow]central entry point for all extra commands[/yellow] from mini-swe-agent.\",\n        \"\",\n        \"Available sub-commands:\",\n        \"\",\n    ]\n    for _, aliases, description in subcommands:\n        alias_text = \" or \".join(f\"[bold green]{alias}[/bold green]\" for alias in aliases)\n        lines.append(f\"  {alias_text}: {description}\")\n    return \"\\n\".join(lines)\n\n\ndef main():\n    args = sys.argv[1:]\n\n    if len(args) == 0 or len(args) == 1 and args[0] in [\"-h\", \"--help\"]:\n        return Console().print(get_docstring())\n\n    for module_path, aliases, _ in subcommands:\n        if args[0] in aliases:\n            return import_module(module_path).app(args[1:], prog_name=f\"mini-extra {aliases[0]}\")\n\n    return Console().print(get_docstring())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Central entry point for all extra commands from mini-swe-agent.</p> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/mini_extra/#minisweagent.run.utilities.mini_extra","title":"minisweagent.run.utilities.mini_extra","text":"<p>This is the central entry point to the mini-extra script. Use subcommands to invoke other command line utilities like running on benchmarks, editing config, inspecting trajectories, etc.</p>"},{"location":"reference/run/mini_extra/#minisweagent.run.utilities.mini_extra.subcommands","title":"subcommands  <code>module-attribute</code>","text":"<pre><code>subcommands = [\n    (\n        \"minisweagent.run.utilities.config\",\n        [\"config\"],\n        \"Manage the global config file\",\n    ),\n    (\n        \"minisweagent.run.utilities.inspector\",\n        [\"inspect\", \"i\", \"inspector\"],\n        \"Run inspector (browse trajectories)\",\n    ),\n    (\n        \"minisweagent.run.benchmarks.swebench\",\n        [\"swebench\"],\n        \"Evaluate on SWE-bench (batch mode)\",\n    ),\n    (\n        \"minisweagent.run.benchmarks.swebench_single\",\n        [\"swebench-single\"],\n        \"Evaluate on SWE-bench (single instance)\",\n    ),\n]\n</code></pre>"},{"location":"reference/run/mini_extra/#minisweagent.run.utilities.mini_extra.get_docstring","title":"get_docstring","text":"<pre><code>get_docstring() -&gt; str\n</code></pre> Source code in <code>src/minisweagent/run/utilities/mini_extra.py</code> <pre><code>def get_docstring() -&gt; str:\n    lines = [\n        \"This is the [yellow]central entry point for all extra commands[/yellow] from mini-swe-agent.\",\n        \"\",\n        \"Available sub-commands:\",\n        \"\",\n    ]\n    for _, aliases, description in subcommands:\n        alias_text = \" or \".join(f\"[bold green]{alias}[/bold green]\" for alias in aliases)\n        lines.append(f\"  {alias_text}: {description}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/run/mini_extra/#minisweagent.run.utilities.mini_extra.main","title":"main","text":"<pre><code>main()\n</code></pre> Source code in <code>src/minisweagent/run/utilities/mini_extra.py</code> <pre><code>def main():\n    args = sys.argv[1:]\n\n    if len(args) == 0 or len(args) == 1 and args[0] in [\"-h\", \"--help\"]:\n        return Console().print(get_docstring())\n\n    for module_path, aliases, _ in subcommands:\n        if args[0] in aliases:\n            return import_module(module_path).app(args[1:], prog_name=f\"mini-extra {aliases[0]}\")\n\n    return Console().print(get_docstring())\n</code></pre>"},{"location":"reference/run/swebench/","title":"SWE-bench (batch)","text":""},{"location":"reference/run/swebench/#swe-bench","title":"SWE-bench","text":"<p>SWE-bench run script</p> <ul> <li>Read on GitHub</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench","title":"minisweagent.run.benchmarks.swebench","text":"<p>Run mini-SWE-agent on SWE-bench instances in batch mode.</p>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.DEFAULT_CONFIG_FILE","title":"DEFAULT_CONFIG_FILE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CONFIG_FILE = (\n    builtin_config_dir / \"benchmarks\" / \"swebench.yaml\"\n)\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.DATASET_MAPPING","title":"DATASET_MAPPING  <code>module-attribute</code>","text":"<pre><code>DATASET_MAPPING = {\n    \"full\": \"princeton-nlp/SWE-Bench\",\n    \"verified\": \"princeton-nlp/SWE-Bench_Verified\",\n    \"lite\": \"princeton-nlp/SWE-Bench_Lite\",\n    \"multimodal\": \"princeton-nlp/SWE-Bench_Multimodal\",\n    \"multilingual\": \"swe-bench/SWE-Bench_Multilingual\",\n    \"smith\": \"SWE-bench/SWE-smith\",\n    \"_test\": \"klieret/swe-bench-dummy-test-dataset\",\n    \"rebench\": \"nebius/SWE-rebench\",\n}\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.app","title":"app  <code>module-attribute</code>","text":"<pre><code>app = Typer(rich_markup_mode='rich', add_completion=False)\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.get_swebench_docker_image_name","title":"get_swebench_docker_image_name","text":"<pre><code>get_swebench_docker_image_name(instance: dict) -&gt; str\n</code></pre> <p>Get the image name for a SWEBench instance.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def get_swebench_docker_image_name(instance: dict) -&gt; str:\n    \"\"\"Get the image name for a SWEBench instance.\"\"\"\n    image_name = instance.get(\"image_name\", None) or instance.get(\"docker_image\", None)\n    if image_name is None:\n        # Docker doesn't allow double underscore, so we replace them with a magic token\n        iid = instance[\"instance_id\"]\n        id_docker_compatible = iid.replace(\"__\", \"_1776_\")\n        image_name = f\"docker.io/swebench/sweb.eval.x86_64.{id_docker_compatible}:latest\".lower()\n    return image_name\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.get_sb_environment","title":"get_sb_environment","text":"<pre><code>get_sb_environment(\n    config: dict, instance: dict\n) -&gt; Environment\n</code></pre> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def get_sb_environment(config: dict, instance: dict) -&gt; Environment:\n    env_config = config.setdefault(\"environment\", {})\n    env_config[\"environment_class\"] = env_config.get(\"environment_class\", \"docker\")\n    image_name = get_swebench_docker_image_name(instance)\n    if env_config[\"environment_class\"] in [\"docker\", \"swerex_modal\"]:\n        env_config[\"image\"] = image_name\n    elif env_config[\"environment_class\"] in [\"singularity\", \"contree\"]:\n        env_config[\"image\"] = \"docker://\" + image_name\n\n    env = get_environment(env_config)\n    if startup_command := config.get(\"run\", {}).get(\"env_startup_command\"):\n        startup_command = Template(startup_command, undefined=StrictUndefined).render(**instance)\n        out = env.execute(startup_command)\n        if out[\"returncode\"] != 0:\n            raise RuntimeError(f\"Error executing startup command: {out}\")\n    return env\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.update_preds_file","title":"update_preds_file","text":"<pre><code>update_preds_file(\n    output_path: Path,\n    instance_id: str,\n    model_name: str,\n    result: str,\n)\n</code></pre> <p>Update the output JSON file with results from a single instance.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def update_preds_file(output_path: Path, instance_id: str, model_name: str, result: str):\n    \"\"\"Update the output JSON file with results from a single instance.\"\"\"\n    with _OUTPUT_FILE_LOCK:\n        output_data = {}\n        if output_path.exists():\n            output_data = json.loads(output_path.read_text())\n        output_data[instance_id] = {\n            \"model_name_or_path\": model_name,\n            \"instance_id\": instance_id,\n            \"model_patch\": result,\n        }\n        output_path.write_text(json.dumps(output_data, indent=2))\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.remove_from_preds_file","title":"remove_from_preds_file","text":"<pre><code>remove_from_preds_file(output_path: Path, instance_id: str)\n</code></pre> <p>Remove an instance from the predictions file.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def remove_from_preds_file(output_path: Path, instance_id: str):\n    \"\"\"Remove an instance from the predictions file.\"\"\"\n    if not output_path.exists():\n        return\n    with _OUTPUT_FILE_LOCK:\n        output_data = json.loads(output_path.read_text())\n        if instance_id in output_data:\n            del output_data[instance_id]\n            output_path.write_text(json.dumps(output_data, indent=2))\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.evaluate_submission","title":"evaluate_submission","text":"<pre><code>evaluate_submission(\n    env: Environment, instance: dict, submission: str\n) -&gt; dict | None\n</code></pre> <p>Run FAIL_TO_PASS and PASS_TO_PASS tests after the agent has finished.</p> <p>This is a post-task evaluation only -- results are logged but never fed back to the agent.</p> <p>Returns a results dict or None if tests could not be run.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def evaluate_submission(env: Environment, instance: dict, submission: str) -&gt; dict | None:\n    \"\"\"Run FAIL_TO_PASS and PASS_TO_PASS tests after the agent has finished.\n\n    This is a post-task evaluation only -- results are logged but never fed\n    back to the agent.\n\n    Returns a results dict or None if tests could not be run.\n    \"\"\"\n    fail_to_pass_raw = instance.get(\"FAIL_TO_PASS\", \"[]\")\n    pass_to_pass_raw = instance.get(\"PASS_TO_PASS\", \"[]\")\n\n    try:\n        fail_to_pass = json.loads(fail_to_pass_raw) if isinstance(fail_to_pass_raw, str) else fail_to_pass_raw\n        pass_to_pass = json.loads(pass_to_pass_raw) if isinstance(pass_to_pass_raw, str) else pass_to_pass_raw\n    except json.JSONDecodeError:\n        logger.warning(\"Could not parse test lists for %s\", instance.get(\"instance_id\", \"?\"))\n        return None\n\n    if not fail_to_pass:\n        logger.info(\"No FAIL_TO_PASS tests for %s, skipping evaluation\", instance.get(\"instance_id\", \"?\"))\n        return None\n\n    _console.print(f\"\\n  [bold cyan]POST-TASK TEST EVALUATION[/bold cyan]  \"\n                    f\"({len(fail_to_pass)} fail_to_pass, {len(pass_to_pass)} pass_to_pass)\")\n\n    try:\n        # Reset to clean state and apply the submission patch\n        env.execute({\"command\": \"cd /testbed &amp;&amp; git checkout -- . &amp;&amp; git clean -fd\"})\n        env.execute({\"command\": f\"cat &gt; /tmp/eval_patch.diff &lt;&lt; 'EVAL_EOF'\\n{submission}\\nEVAL_EOF\"})\n        apply_result = env.execute({\"command\": \"cd /testbed &amp;&amp; git apply /tmp/eval_patch.diff 2&gt;&amp;1\"})\n        if apply_result.get(\"returncode\", -1) != 0:\n            _console.print(f\"  [red]FAIL[/red]  Could not apply patch: {apply_result.get('output', '')[:200]}\")\n            return None\n\n        # Apply test_patch if present (some instances need test file changes)\n        test_patch = instance.get(\"test_patch\", \"\")\n        if test_patch:\n            env.execute({\"command\": f\"cat &gt; /tmp/test_patch.diff &lt;&lt; 'TEST_EOF'\\n{test_patch}\\nTEST_EOF\"})\n            tp_result = env.execute({\"command\": \"cd /testbed &amp;&amp; git apply /tmp/test_patch.diff 2&gt;&amp;1\"})\n            if tp_result.get(\"returncode\", -1) != 0:\n                _console.print(f\"  [yellow]WARN[/yellow]  test_patch failed to apply (may already be present)\")\n\n        # Run FAIL_TO_PASS tests\n        _console.print(f\"\\n  [bold]FAIL_TO_PASS tests ({len(fail_to_pass)}):[/bold]\")\n        f2p_passed = 0\n        f2p_failed = []\n        for test_id in fail_to_pass:\n            passed = _run_single_test(env, test_id)\n            if passed:\n                f2p_passed += 1\n                _console.print(f\"    [green]PASS[/green]  {test_id}\")\n            else:\n                f2p_failed.append(test_id)\n                _console.print(f\"    [red]FAIL[/red]  {test_id}\")\n\n        # Run PASS_TO_PASS tests\n        p2p_passed = 0\n        p2p_failed = []\n        p2p_total = len(pass_to_pass)\n        if p2p_total &gt; 0:\n            _console.print(f\"\\n  [bold]PASS_TO_PASS tests ({p2p_total}):[/bold]\")\n            for test_id in pass_to_pass:\n                passed = _run_single_test(env, test_id)\n                if passed:\n                    p2p_passed += 1\n                    _console.print(f\"    [green]PASS[/green]  {test_id}\")\n                else:\n                    p2p_failed.append(test_id)\n                    _console.print(f\"    [red]FAIL[/red]  {test_id}\")\n\n        # Summary\n        f2p_pct = (f2p_passed / len(fail_to_pass) * 100) if fail_to_pass else 0\n        p2p_pct = (p2p_passed / p2p_total * 100) if p2p_total &gt; 0 else 100\n        all_passed = f2p_pct == 100 and p2p_pct == 100\n\n        _console.print()\n        _console.print(f\"  [bold]FAIL_TO_PASS:[/bold] {f2p_passed}/{len(fail_to_pass)} ({f2p_pct:.0f}%)\")\n        _console.print(f\"  [bold]PASS_TO_PASS:[/bold] {p2p_passed}/{p2p_total} ({p2p_pct:.0f}%)\")\n\n        if all_passed:\n            _console.print(f\"\\n  [green bold]RESOLVED[/green bold]  All tests pass!\")\n        elif f2p_pct &gt; 0 and p2p_pct == 100:\n            _console.print(f\"\\n  [yellow bold]PARTIAL[/yellow bold]  Some FAIL_TO_PASS tests still failing\")\n        else:\n            _console.print(f\"\\n  [red bold]NOT RESOLVED[/red bold]  Tests failing\")\n\n        return {\n            \"all_passed\": all_passed,\n            \"f2p_passed\": f2p_passed,\n            \"f2p_total\": len(fail_to_pass),\n            \"f2p_failed\": f2p_failed,\n            \"p2p_passed\": p2p_passed,\n            \"p2p_total\": p2p_total,\n            \"p2p_failed\": p2p_failed,\n        }\n    except Exception as e:\n        logger.warning(\"Test evaluation error for %s: %s\", instance.get(\"instance_id\", \"?\"), e)\n        return None\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.process_instance","title":"process_instance","text":"<pre><code>process_instance(\n    instance: dict,\n    output_dir: Path,\n    config: dict,\n    progress_manager: RunBatchProgressManager,\n) -&gt; None\n</code></pre> <p>Process a single SWEBench instance.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def process_instance(\n    instance: dict,\n    output_dir: Path,\n    config: dict,\n    progress_manager: RunBatchProgressManager,\n) -&gt; None:\n    \"\"\"Process a single SWEBench instance.\"\"\"\n    instance_id = instance[\"instance_id\"]\n    instance_dir = output_dir / instance_id\n    # avoid inconsistent state if something here fails and there's leftover previous files\n    remove_from_preds_file(output_dir / \"preds.json\", instance_id)\n    (instance_dir / f\"{instance_id}.traj.json\").unlink(missing_ok=True)\n    model = get_model(config=config.get(\"model\", {}))\n    task = instance[\"problem_statement\"]\n\n    progress_manager.on_instance_start(instance_id)\n    progress_manager.update_instance_status(instance_id, \"Pulling/starting environment\")\n\n    agent = None\n    exit_status = None\n    result = None\n    extra_info = {}\n\n    try:\n        env = get_sb_environment(config, instance)\n        agent_config = dict(config.get(\"agent\", {}))\n        agent_class_spec = agent_config.pop(\"agent_class\", \"default\")\n        base_class = get_agent_class(agent_class_spec)\n        TrackedClass = _make_progress_tracking_class(base_class)\n        agent = TrackedClass(\n            model,\n            env,\n            progress_manager=progress_manager,\n            instance_id=instance_id,\n            **agent_config,\n        )\n        info = agent.run(task)\n        exit_status = info.get(\"exit_status\")\n        result = info.get(\"submission\")\n        # Post-task test evaluation (agent is done, results are only logged)\n        if result and exit_status == \"Submitted\":\n            progress_manager.update_instance_status(instance_id, \"Evaluating tests\")\n            test_results = evaluate_submission(env, instance, result)\n            if test_results:\n                extra_info[\"test_results\"] = test_results\n    except Exception as e:\n        logger.error(f\"Error processing instance {instance_id}: {e}\", exc_info=True)\n        exit_status, result = type(e).__name__, \"\"\n        extra_info = {\"traceback\": traceback.format_exc(), \"exception_str\": str(e)}\n    finally:\n        if agent is not None:\n            traj_path = instance_dir / f\"{instance_id}.traj.json\"\n            agent.save(\n                traj_path,\n                {\n                    \"info\": {\n                        \"exit_status\": exit_status,\n                        \"submission\": result,\n                        **extra_info,\n                    },\n                    \"instance_id\": instance_id,\n                },\n            )\n            logger.info(f\"Saved trajectory to '{traj_path}'\")\n        update_preds_file(output_dir / \"preds.json\", instance_id, model.config.model_name, result)\n        progress_manager.on_instance_end(instance_id, exit_status)\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.filter_instances","title":"filter_instances","text":"<pre><code>filter_instances(\n    instances: list[dict],\n    *,\n    filter_spec: str,\n    slice_spec: str = \"\",\n    shuffle: bool = False,\n) -&gt; list[dict]\n</code></pre> <p>Filter and slice a list of SWEBench instances.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>def filter_instances(\n    instances: list[dict], *, filter_spec: str, slice_spec: str = \"\", shuffle: bool = False\n) -&gt; list[dict]:\n    \"\"\"Filter and slice a list of SWEBench instances.\"\"\"\n    if shuffle:\n        instances = sorted(instances.copy(), key=lambda x: x[\"instance_id\"])\n        random.seed(42)\n        random.shuffle(instances)\n    before_filter = len(instances)\n    instances = [instance for instance in instances if re.match(filter_spec, instance[\"instance_id\"])]\n    if (after_filter := len(instances)) != before_filter:\n        logger.info(f\"Instance filter: {before_filter} -&gt; {after_filter} instances\")\n    if slice_spec:\n        values = [int(x) if x else None for x in slice_spec.split(\":\")]\n        instances = instances[slice(*values)]\n        if (after_slice := len(instances)) != before_filter:\n            logger.info(f\"Instance slice: {before_filter} -&gt; {after_slice} instances\")\n    return instances\n</code></pre>"},{"location":"reference/run/swebench/#minisweagent.run.benchmarks.swebench.main","title":"main","text":"<pre><code>main(\n    subset: str = Option(\n        \"lite\",\n        \"--subset\",\n        help=\"SWEBench subset to use or path to a dataset\",\n        rich_help_panel=\"Data selection\",\n    ),\n    split: str = Option(\n        \"dev\",\n        \"--split\",\n        help=\"Dataset split\",\n        rich_help_panel=\"Data selection\",\n    ),\n    slice_spec: str = Option(\n        \"\",\n        \"--slice\",\n        help=\"Slice specification (e.g., '0:5' for first 5 instances)\",\n        rich_help_panel=\"Data selection\",\n    ),\n    filter_spec: str = Option(\n        \"\",\n        \"--filter\",\n        help=\"Filter instance IDs by regex\",\n        rich_help_panel=\"Data selection\",\n    ),\n    shuffle: bool = Option(\n        False,\n        \"--shuffle\",\n        help=\"Shuffle instances\",\n        rich_help_panel=\"Data selection\",\n    ),\n    output: str = Option(\n        \"\",\n        \"-o\",\n        \"--output\",\n        help=\"Output directory\",\n        rich_help_panel=\"Basic\",\n    ),\n    workers: int = Option(\n        1,\n        \"-w\",\n        \"--workers\",\n        help=\"Number of worker threads for parallel processing\",\n        rich_help_panel=\"Basic\",\n    ),\n    model: str | None = Option(\n        None,\n        \"-m\",\n        \"--model\",\n        help=\"Model to use\",\n        rich_help_panel=\"Basic\",\n    ),\n    model_class: str | None = Option(\n        None,\n        \"--model-class\",\n        help=\"Model class to use (e.g., 'anthropic' or 'minisweagent.models.anthropic.AnthropicModel')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    redo_existing: bool = Option(\n        False,\n        \"--redo-existing\",\n        help=\"Redo existing instances\",\n        rich_help_panel=\"Data selection\",\n    ),\n    config_spec: list[str] = Option(\n        [str(DEFAULT_CONFIG_FILE)],\n        \"-c\",\n        \"--config\",\n        help=_CONFIG_SPEC_HELP_TEXT,\n        rich_help_panel=\"Basic\",\n    ),\n    environment_class: str | None = Option(\n        None,\n        \"--environment-class\",\n        help=\"Environment type to use. Recommended are docker or singularity\",\n        rich_help_panel=\"Advanced\",\n    ),\n) -&gt; None\n</code></pre> Source code in <code>src/minisweagent/run/benchmarks/swebench.py</code> <pre><code>@app.command(help=_HELP_TEXT)\ndef main(\n    subset: str = typer.Option(\"lite\", \"--subset\", help=\"SWEBench subset to use or path to a dataset\", rich_help_panel=\"Data selection\"),\n    split: str = typer.Option(\"dev\", \"--split\", help=\"Dataset split\", rich_help_panel=\"Data selection\"),\n    slice_spec: str = typer.Option(\"\", \"--slice\", help=\"Slice specification (e.g., '0:5' for first 5 instances)\", rich_help_panel=\"Data selection\"),\n    filter_spec: str = typer.Option(\"\", \"--filter\", help=\"Filter instance IDs by regex\", rich_help_panel=\"Data selection\"),\n    shuffle: bool = typer.Option(False, \"--shuffle\", help=\"Shuffle instances\", rich_help_panel=\"Data selection\"),\n    output: str = typer.Option(\"\", \"-o\", \"--output\", help=\"Output directory\", rich_help_panel=\"Basic\"),\n    workers: int = typer.Option(1, \"-w\", \"--workers\", help=\"Number of worker threads for parallel processing\", rich_help_panel=\"Basic\"),\n    model: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\", rich_help_panel=\"Basic\"),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'anthropic' or 'minisweagent.models.anthropic.AnthropicModel')\", rich_help_panel=\"Advanced\"),\n    redo_existing: bool = typer.Option(False, \"--redo-existing\", help=\"Redo existing instances\", rich_help_panel=\"Data selection\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT, rich_help_panel=\"Basic\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment type to use. Recommended are docker or singularity\", rich_help_panel=\"Advanced\"),\n) -&gt; None:\n    # fmt: on\n    output_path = Path(output)\n    output_path.mkdir(parents=True, exist_ok=True)\n    logger.info(f\"Results will be saved to {output_path}\")\n    add_file_handler(output_path / \"minisweagent.log\")\n\n    from datasets import load_dataset\n\n    dataset_path = DATASET_MAPPING.get(subset, subset)\n    logger.info(f\"Loading dataset {dataset_path}, split {split}...\")\n    instances = list(load_dataset(dataset_path, split=split))\n\n    instances = filter_instances(instances, filter_spec=filter_spec, slice_spec=slice_spec, shuffle=shuffle)\n    if not redo_existing and (output_path / \"preds.json\").exists():\n        existing_instances = list(json.loads((output_path / \"preds.json\").read_text()).keys())\n        logger.info(f\"Skipping {len(existing_instances)} existing instances\")\n        instances = [instance for instance in instances if instance[\"instance_id\"] not in existing_instances]\n    logger.info(f\"Running on {len(instances)} instances...\")\n\n    logger.info(f\"Building agent config from specs: {config_spec}\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"environment\": {\"environment_class\": environment_class or UNSET},\n        \"model\": {\"model_name\": model or UNSET, \"model_class\": model_class or UNSET},\n    })\n    config = recursive_merge(*configs)\n\n    progress_manager = RunBatchProgressManager(len(instances), output_path / f\"exit_statuses_{time.time()}.yaml\")\n\n    def process_futures(futures: dict[concurrent.futures.Future, str]):\n        for future in concurrent.futures.as_completed(futures):\n            try:\n                future.result()\n            except concurrent.futures.CancelledError:\n                pass\n            except Exception as e:\n                instance_id = futures[future]\n                logger.error(f\"Error in future for instance {instance_id}: {e}\", exc_info=True)\n                progress_manager.on_uncaught_exception(instance_id, e)\n\n    with Live(progress_manager.render_group, refresh_per_second=4):\n        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n            futures = {\n                executor.submit(process_instance, instance, output_path, config, progress_manager): instance[\n                    \"instance_id\"\n                ]\n                for instance in instances\n            }\n            try:\n                process_futures(futures)\n            except KeyboardInterrupt:\n                logger.info(\"Cancelling all pending jobs. Press ^C again to exit immediately.\")\n                for future in futures:\n                    if not future.running() and not future.done():\n                        future.cancel()\n                process_futures(futures)\n</code></pre>"},{"location":"reference/run/swebench_single/","title":"SWE-bench (single)","text":""},{"location":"reference/run/swebench_single/#swe-bench-single","title":"SWE-bench Single","text":"<p>SWE-bench Single run script</p> <ul> <li>Read on GitHub</li> </ul> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"reference/run/swebench_single/#minisweagent.run.benchmarks.swebench_single","title":"minisweagent.run.benchmarks.swebench_single","text":"<p>Run on a single SWE-Bench instance.</p>"},{"location":"reference/run/swebench_single/#minisweagent.run.benchmarks.swebench_single.DEFAULT_OUTPUT_FILE","title":"DEFAULT_OUTPUT_FILE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_OUTPUT_FILE = (\n    global_config_dir / \"last_swebench_single_run.traj.json\"\n)\n</code></pre>"},{"location":"reference/run/swebench_single/#minisweagent.run.benchmarks.swebench_single.DEFAULT_CONFIG_FILE","title":"DEFAULT_CONFIG_FILE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_CONFIG_FILE = (\n    builtin_config_dir / \"benchmarks\" / \"swebench.yaml\"\n)\n</code></pre>"},{"location":"reference/run/swebench_single/#minisweagent.run.benchmarks.swebench_single.app","title":"app  <code>module-attribute</code>","text":"<pre><code>app = Typer(rich_markup_mode='rich', add_completion=False)\n</code></pre>"},{"location":"reference/run/swebench_single/#minisweagent.run.benchmarks.swebench_single.main","title":"main","text":"<pre><code>main(\n    subset: str = Option(\n        \"lite\",\n        \"--subset\",\n        help=\"SWEBench subset to use or path to a dataset\",\n        rich_help_panel=\"Data selection\",\n    ),\n    split: str = Option(\n        \"dev\",\n        \"--split\",\n        help=\"Dataset split\",\n        rich_help_panel=\"Data selection\",\n    ),\n    instance_spec: str = Option(\n        0,\n        \"-i\",\n        \"--instance\",\n        help=\"SWE-Bench instance ID or index\",\n        rich_help_panel=\"Data selection\",\n    ),\n    model_name: str | None = Option(\n        None,\n        \"-m\",\n        \"--model\",\n        help=\"Model to use\",\n        rich_help_panel=\"Basic\",\n    ),\n    model_class: str | None = Option(\n        None,\n        \"--model-class\",\n        help=\"Model class to use (e.g., 'anthropic' or 'minisweagent.models.anthropic.AnthropicModel')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    agent_class: str | None = Option(\n        None,\n        \"--agent-class\",\n        help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    environment_class: str | None = Option(\n        None,\n        \"--environment-class\",\n        help=\"Environment class to use (e.g., 'docker' or 'minisweagent.environments.docker.DockerEnvironment')\",\n        rich_help_panel=\"Advanced\",\n    ),\n    yolo: bool = Option(\n        False,\n        \"-y\",\n        \"--yolo\",\n        help=\"Run without confirmation\",\n    ),\n    cost_limit: float | None = Option(\n        None,\n        \"-l\",\n        \"--cost-limit\",\n        help=\"Cost limit. Set to 0 to disable.\",\n    ),\n    config_spec: list[str] = Option(\n        [str(DEFAULT_CONFIG_FILE)],\n        \"-c\",\n        \"--config\",\n        help=_CONFIG_SPEC_HELP_TEXT,\n        rich_help_panel=\"Basic\",\n    ),\n    exit_immediately: bool = Option(\n        False,\n        \"--exit-immediately\",\n        help=\"Exit immediately when the agent wants to finish instead of prompting.\",\n        rich_help_panel=\"Advanced\",\n    ),\n    output: Path | None = Option(\n        DEFAULT_OUTPUT_FILE,\n        \"-o\",\n        \"--output\",\n        help=\"Output trajectory file\",\n        rich_help_panel=\"Basic\",\n    ),\n) -&gt; None\n</code></pre> <p>Run on a single SWE-Bench instance.</p> Source code in <code>src/minisweagent/run/benchmarks/swebench_single.py</code> <pre><code>@app.command()\ndef main(\n    subset: str = typer.Option(\"lite\", \"--subset\", help=\"SWEBench subset to use or path to a dataset\", rich_help_panel=\"Data selection\"),\n    split: str = typer.Option(\"dev\", \"--split\", help=\"Dataset split\", rich_help_panel=\"Data selection\"),\n    instance_spec: str = typer.Option(0, \"-i\", \"--instance\", help=\"SWE-Bench instance ID or index\", rich_help_panel=\"Data selection\"),\n    model_name: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\", rich_help_panel=\"Basic\"),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'anthropic' or 'minisweagent.models.anthropic.AnthropicModel')\", rich_help_panel=\"Advanced\"),\n    agent_class: str | None = typer.Option(None, \"--agent-class\", help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\", rich_help_panel=\"Advanced\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment class to use (e.g., 'docker' or 'minisweagent.environments.docker.DockerEnvironment')\", rich_help_panel=\"Advanced\"),\n    yolo: bool = typer.Option(False, \"-y\", \"--yolo\", help=\"Run without confirmation\"),\n    cost_limit: float | None = typer.Option(None, \"-l\", \"--cost-limit\", help=\"Cost limit. Set to 0 to disable.\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT, rich_help_panel=\"Basic\"),\n    exit_immediately: bool = typer.Option(False, \"--exit-immediately\", help=\"Exit immediately when the agent wants to finish instead of prompting.\", rich_help_panel=\"Advanced\"),\n    output: Path | None = typer.Option(DEFAULT_OUTPUT_FILE, \"-o\", \"--output\", help=\"Output trajectory file\", rich_help_panel=\"Basic\"),\n) -&gt; None:\n    # fmt: on\n    \"\"\"Run on a single SWE-Bench instance.\"\"\"\n    dataset_path = DATASET_MAPPING.get(subset, subset)\n    logger.info(f\"Loading dataset from {dataset_path}, split {split}...\")\n    instances = {\n        inst[\"instance_id\"]: inst  # type: ignore\n        for inst in load_dataset(dataset_path, split=split)\n    }\n    if instance_spec.isnumeric():\n        instance_spec = sorted(instances.keys())[int(instance_spec)]\n    instance: dict = instances[instance_spec]  # type: ignore\n\n    logger.info(f\"Building agent config from specs: {config_spec}\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"agent\": {\n            \"agent_class\": agent_class or UNSET,\n            \"mode\": \"yolo\" if yolo else UNSET,\n            \"cost_limit\": cost_limit or UNSET,\n            \"confirm_exit\": False if exit_immediately else UNSET,\n            \"output_path\": output or UNSET,\n        },\n        \"model\": {\n            \"model_class\": model_class or UNSET,\n            \"model_name\": model_name or UNSET,\n        },\n        \"environment\": {\n            \"environment_class\": environment_class or UNSET,\n        },\n    })\n    config = recursive_merge(*configs)\n\n    env = get_sb_environment(config, instance)\n    agent = get_agent(\n        get_model(config=config.get(\"model\", {})),\n        env,\n        config.get(\"agent\", {}),\n        default_type=\"interactive\",\n    )\n    info = agent.run(instance[\"problem_statement\"])\n    submission = info.get(\"submission\", \"\")\n    if submission and info.get(\"exit_status\") == \"Submitted\":\n        evaluate_submission(env, instance, submission)\n</code></pre>"},{"location":"usage/config/","title":"Config","text":""},{"location":"usage/config/#mini-extra-config","title":"<code>mini-extra config</code>","text":"<p>Overview</p> <ul> <li><code>mini-extra config</code> is a utility to manage the global configuration file.</li> <li>Quickly start the it with <code>mini-extra config</code> or <code>mini-e config</code>.</li> </ul>"},{"location":"usage/config/#commands","title":"Commands","text":""},{"location":"usage/config/#setup","title":"<code>setup</code>","text":"<p>Interactive setup wizard that helps you configure your default model and API keys.</p> <pre><code>mini-extra config setup\n</code></pre> <p>This will prompt you for:</p> <ol> <li>Your default model (e.g., <code>anthropic/claude-sonnet-4-5-20250929</code>)</li> <li>Your API key name and value (e.g., <code>ANTHROPIC_API_KEY</code>)</li> </ol>"},{"location":"usage/config/#set","title":"<code>set</code>","text":"<p>Set a specific key in the global config file.</p> <pre><code># example: set default model\nmini-extra config set MSWEA_MODEL_NAME anthropic/claude-sonnet-4-5-20250929\n# or interactively\nmini-extra config set\n</code></pre>"},{"location":"usage/config/#unset","title":"<code>unset</code>","text":"<p>Remove a key from the global config file.</p> <pre><code>mini-extra config unset MSWEA_MODEL_NAME\n</code></pre>"},{"location":"usage/config/#edit","title":"<code>edit</code>","text":"<p>Open the global config file in your default editor (uses <code>$EDITOR</code> or <code>nano</code>).</p> <pre><code>mini-extra config edit\n</code></pre>"},{"location":"usage/config/#configuration-keys","title":"Configuration keys","text":"<p>For more configuration options, see global configuration.</p>"},{"location":"usage/config/#implementation","title":"Implementation","text":"Run script <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>#!/usr/bin/env python3\n\n\"\"\"Utility to manage the global config file.\n\nYou can also directly edit the `.env` file in the config directory.\n\nIt is located at [bold green]{global_config_file}[/bold green].\n\"\"\"\n\nimport os\nimport subprocess\n\nfrom dotenv import set_key, unset_key\nfrom rich.console import Console\nfrom rich.rule import Rule\nfrom typer import Argument, Typer\n\nfrom minisweagent import global_config_file\n\napp = Typer(\n    help=__doc__.format(global_config_file=global_config_file),  # type: ignore\n    no_args_is_help=True,\n    rich_markup_mode=\"rich\",\n    add_completion=False,\n)\nconsole = Console(highlight=False)\n\n\n_SETUP_HELP = \"\"\"To get started, we need to set up your global config file.\n\nYou can edit it manually or use the [bold green]mini-extra config set[/bold green] or [bold green]mini-extra config edit[/bold green] commands.\n\nThis setup will ask you for your model and an API key.\n\nHere's a few popular models and the required API keys:\n\n[bold green]anthropic/claude-sonnet-4-5-20250929[/bold green] ([bold green]ANTHROPIC_API_KEY[/bold green])\n[bold green]openai/gpt-5[/bold green] or [bold green]openai/gpt-5-mini[/bold green] ([bold green]OPENAI_API_KEY[/bold green])\n[bold green]gemini/gemini-3-pro-preview[/bold green] ([bold green]GEMINI_API_KEY[/bold green])\n\n[bold]Note: Please always include the provider (e.g., \"openai/\") in the model name.[/bold]\n\n[bold yellow]You can leave any setting blank to skip it.[/bold yellow]\n\nMore information at https://mini-swe-agent.com/latest/quickstart/\nTo find the best model, check the leaderboard at https://swebench.com/\n\"\"\"\n\n\ndef prompt(*args, **kwargs):\n    # Defer import to avoid slow import module\n    from prompt_toolkit.shortcuts.prompt import prompt as _prompt\n\n    return _prompt(*args, **kwargs)\n\n\ndef configure_if_first_time():\n    if not os.getenv(\"MSWEA_CONFIGURED\"):\n        console.print(Rule())\n        setup()\n        console.print(Rule())\n\n\n@app.command()\ndef setup():\n    \"\"\"Setup the global config file.\"\"\"\n    console.print(_SETUP_HELP.format(global_config_file=global_config_file))\n    default_model = prompt(\n        \"Enter your default model (e.g., anthropic/claude-sonnet-4-5-20250929): \",\n        default=os.getenv(\"MSWEA_MODEL_NAME\", \"\"),\n    ).strip()\n    if default_model:\n        set_key(global_config_file, \"MSWEA_MODEL_NAME\", default_model)\n    console.print(\n        \"[bold yellow]If you already have your API keys set as environment variables, you can ignore the next question.[/bold yellow]\"\n    )\n    key_name = prompt(\"Enter your API key name (e.g., ANTHROPIC_API_KEY): \").strip()\n    key_value = None\n    if key_name:\n        key_value = prompt(\"Enter your API key value (e.g., sk-1234567890): \", default=os.getenv(key_name, \"\")).strip()\n        if key_value:\n            set_key(global_config_file, key_name, key_value)\n    if not key_value:\n        console.print(\n            \"[bold red]API key setup not completed.[/bold red] Totally fine if you have your keys as environment variables.\"\n        )\n    set_key(global_config_file, \"MSWEA_CONFIGURED\", \"true\")\n    console.print(\n        \"\\n[bold yellow]Config finished.[/bold yellow] If you want to revisit it, run [bold green]mini-extra config setup[/bold green].\"\n    )\n\n\n@app.command()\ndef set(\n    key: str | None = Argument(None, help=\"The key to set\"),\n    value: str | None = Argument(None, help=\"The value to set\"),\n):\n    \"\"\"Set a key in the global config file.\"\"\"\n    if key is None:\n        key = prompt(\"Enter the key to set: \")\n    if value is None:\n        value = prompt(f\"Enter the value for {key}: \")\n    set_key(global_config_file, key, value)\n\n\n@app.command()\ndef unset(key: str | None = Argument(None, help=\"The key to unset\")):\n    \"\"\"Unset a key in the global config file.\"\"\"\n    if key is None:\n        key = prompt(\"Enter the key to unset: \")\n    unset_key(global_config_file, key)\n\n\n@app.command()\ndef edit():\n    \"\"\"Edit the global config file.\"\"\"\n    editor = os.getenv(\"EDITOR\", \"nano\")\n    subprocess.run([editor, global_config_file])\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"usage/inspector/","title":"Inspector","text":""},{"location":"usage/inspector/#inspector-browse-agent-trajectories","title":"Inspector: Browse agent trajectories","text":"<p>Overview</p> <ul> <li>The <code>inspector</code> is a tool that allows you to browse <code>.traj.json</code> files that show the history of a mini-SWE-agent run.</li> <li>Quickly start it with <code>mini-e i</code> or <code>mini-extra inspector</code>.</li> <li>See output files for the trajectory file format.</li> <li>Alternative: jless is a great command-line JSON viewer for browsing trajectories.</li> </ul>"},{"location":"usage/inspector/#usage","title":"Usage","text":"<pre><code># Find all .traj.json files recursively from current directory\nmini-extra inspector\n# or shorter\nmini-e i\n# Open the inspector for a specific file\nmini-e i &lt;path_to_traj.json&gt;\n# Search for trajectory files in a specific directory\nmini-e i &lt;path_to_directory&gt;\n</code></pre>"},{"location":"usage/inspector/#key-bindings","title":"Key bindings","text":"<ul> <li><code>q</code>: Quit the inspector</li> <li><code>h</code>/<code>LEFT</code>: Previous step</li> <li><code>l</code>/<code>RIGHT</code>: Next step</li> <li><code>j</code>/<code>DOWN</code>: Scroll down</li> <li><code>k</code>/<code>UP</code>: Scroll up</li> <li><code>H</code>: Previous trajectory</li> <li><code>L</code>: Next trajectory</li> <li><code>e</code>: Open current step in jless</li> </ul>"},{"location":"usage/inspector/#faq","title":"FAQ","text":"<p>How can I select/copy text on the screen?</p> <p>Hold down the <code>Alt</code>/<code>Option</code> key and use the mouse to select the text.</p>"},{"location":"usage/inspector/#implementation","title":"Implementation","text":"<p>The inspector is implemented with textual.</p> Implementation <ul> <li>Read on GitHub</li> </ul> <pre><code>#!/usr/bin/env python3\n\"\"\"\nSimple trajectory inspector for browsing agent conversation trajectories.\n\nMore information about the usage: [bold green] https://mini-swe-agent.com/latest/usage/inspector/ [/bold green].\n\"\"\"\n\nimport json\nimport os\nimport subprocess\nimport tempfile\nfrom pathlib import Path\n\nimport typer\nfrom rich.text import Text\nfrom textual.app import App, ComposeResult\nfrom textual.binding import Binding\nfrom textual.command import DiscoveryHit, Hit, Hits, Provider\nfrom textual.containers import Container, Vertical, VerticalScroll\nfrom textual.widgets import Footer, Header, Static\n\nfrom minisweagent.models.utils.content_string import get_content_string\n\n\ndef _messages_to_steps(messages: list[dict]) -&gt; list[list[dict]]:\n    \"\"\"Group messages into \"pages\" as shown by the UI.\"\"\"\n    steps = []\n    current_step = []\n    for message in messages:\n        # Start new step with new tool uses\n        if message.get(\"extra\", {}).get(\"actions\") or message.get(\"role\") == \"assistant\":\n            steps.append(current_step)\n            current_step = [message]\n        else:\n            current_step.append(message)\n    if current_step:\n        steps.append(current_step)\n    return steps\n\n\napp = typer.Typer(rich_markup_mode=\"rich\", add_completion=False)\n\n\nclass BindingCommandProvider(Provider):\n    \"\"\"Provide bindings as commands in the palette.\"\"\"\n\n    COMMAND_DESCRIPTIONS = {\n        \"next_step\": \"Next step in the current trajectory\",\n        \"previous_step\": \"Previous step in the current trajectory\",\n        \"first_step\": \"First step in the current trajectory\",\n        \"last_step\": \"Last step in the current trajectory\",\n        \"scroll_down\": \"Scroll down\",\n        \"scroll_up\": \"Scroll up\",\n        \"next_trajectory\": \"Next trajectory\",\n        \"previous_trajectory\": \"Previous trajectory\",\n        \"open_in_jless\": \"Open the current step in jless\",\n        \"open_in_jless_all\": \"Open the entire trajectory in jless\",\n        \"quit\": \"Quit the inspector\",\n    }\n\n    async def discover(self) -&gt; Hits:\n        app = self.app\n        for binding in app.BINDINGS:\n            desc = self.COMMAND_DESCRIPTIONS.get(binding.action, binding.description)\n            yield DiscoveryHit(desc, lambda b=binding: app.run_action(b.action))\n\n    async def search(self, query: str) -&gt; Hits:\n        matcher = self.matcher(query)\n        app = self.app\n        for binding in app.BINDINGS:\n            desc = self.COMMAND_DESCRIPTIONS.get(binding.action, binding.description)\n            score = matcher.match(desc)\n            if score &gt; 0:\n                yield Hit(score, matcher.highlight(desc), lambda b=binding: app.run_action(b.action))\n\n\nclass TrajectoryInspector(App):\n    COMMANDS = {BindingCommandProvider}\n    BINDINGS = [\n        Binding(\"right,l\", \"next_step\", \"Step++\"),\n        Binding(\"left,h\", \"previous_step\", \"Step--\"),\n        Binding(\"0\", \"first_step\", \"Step=0\"),\n        Binding(\"$\", \"last_step\", \"Step=-1\"),\n        Binding(\"j,down\", \"scroll_down\", \"\u2193\"),\n        Binding(\"k,up\", \"scroll_up\", \"\u2191\"),\n        Binding(\"L\", \"next_trajectory\", \"Traj++\"),\n        Binding(\"H\", \"previous_trajectory\", \"Traj--\"),\n        Binding(\"e\", \"open_in_jless\", \"Jless\"),\n        Binding(\"E\", \"open_in_jless_all\", \"Jless (all)\"),\n        Binding(\"q\", \"quit\", \"Quit\"),\n    ]\n\n    def __init__(self, trajectory_files: list[Path]):\n        css_path = os.environ.get(\n            \"MSWEA_INSPECTOR_STYLE_PATH\", str(Path(__file__).parent.parent.parent / \"config\" / \"inspector.tcss\")\n        )\n        self.__class__.CSS = Path(css_path).read_text()\n\n        super().__init__()\n        self.trajectory_files = trajectory_files\n        self._i_trajectory = 0\n        self._i_step = 0\n        self.messages = []\n        self.steps = []\n\n        if trajectory_files:\n            self._load_current_trajectory()\n\n    # --- Basics ---\n\n    @property\n    def i_step(self) -&gt; int:\n        \"\"\"Current step index.\"\"\"\n        return self._i_step\n\n    @i_step.setter\n    def i_step(self, value: int) -&gt; None:\n        \"\"\"Set current step index, automatically clamping to valid bounds.\"\"\"\n        if value != self._i_step and self.n_steps &gt; 0:\n            self._i_step = max(0, min(value, self.n_steps - 1))\n            self.query_one(VerticalScroll).scroll_to(y=0, animate=False)\n            self.update_content()\n\n    @property\n    def n_steps(self) -&gt; int:\n        \"\"\"Number of steps in current trajectory.\"\"\"\n        return len(self.steps)\n\n    @property\n    def i_trajectory(self) -&gt; int:\n        \"\"\"Current trajectory index.\"\"\"\n        return self._i_trajectory\n\n    @i_trajectory.setter\n    def i_trajectory(self, value: int) -&gt; None:\n        \"\"\"Set current trajectory index, automatically clamping to valid bounds.\"\"\"\n        if value != self._i_trajectory and self.n_trajectories &gt; 0:\n            self._i_trajectory = max(0, min(value, self.n_trajectories - 1))\n            self._load_current_trajectory()\n            self.query_one(VerticalScroll).scroll_to(y=0, animate=False)\n            self.update_content()\n\n    @property\n    def n_trajectories(self) -&gt; int:\n        \"\"\"Number of trajectory files.\"\"\"\n        return len(self.trajectory_files)\n\n    def _load_current_trajectory(self) -&gt; None:\n        \"\"\"Load the currently selected trajectory file.\"\"\"\n        if not self.trajectory_files:\n            self.messages = []\n            self.steps = []\n            return\n\n        trajectory_file = self.trajectory_files[self.i_trajectory]\n        try:\n            data = json.loads(trajectory_file.read_text())\n\n            if isinstance(data, list):\n                self.messages = data\n            elif isinstance(data, dict) and \"messages\" in data:\n                self.messages = data[\"messages\"]\n            else:\n                raise ValueError(\"Unrecognized trajectory format\")\n\n            self.steps = _messages_to_steps(self.messages)\n            self._i_step = 0\n        except (json.JSONDecodeError, FileNotFoundError, ValueError) as e:\n            self.messages = []\n            self.steps = []\n            self.notify(f\"Error loading {trajectory_file.name}: {e}\", severity=\"error\")\n\n    @property\n    def current_trajectory_name(self) -&gt; str:\n        \"\"\"Get the name of the current trajectory file.\"\"\"\n        if not self.trajectory_files:\n            return \"No trajectories\"\n        return self.trajectory_files[self.i_trajectory].name\n\n    def compose(self) -&gt; ComposeResult:\n        yield Header()\n        with Container(id=\"main\"):\n            with VerticalScroll():\n                yield Vertical(id=\"content\")\n        yield Footer()\n\n    def on_mount(self) -&gt; None:\n        self.update_content()\n\n    def update_content(self) -&gt; None:\n        \"\"\"Update the displayed content.\"\"\"\n        container = self.query_one(\"#content\", Vertical)\n        container.remove_children()\n\n        if not self.steps:\n            container.mount(Static(\"No trajectory loaded or empty trajectory\"))\n            self.title = \"Trajectory Inspector - No Data\"\n            return\n\n        for message in self.steps[self.i_step]:\n            content_str = get_content_string(message)\n            message_container = Vertical(classes=\"message-container\")\n            container.mount(message_container)\n            role = message.get(\"role\") or message.get(\"type\") or \"unknown\"\n            message_container.mount(Static(role.upper(), classes=\"message-header\"))\n            message_container.mount(Static(Text(content_str, no_wrap=False), classes=\"message-content\"))\n\n        self.title = (\n            f\"Trajectory {self.i_trajectory + 1}/{self.n_trajectories} - \"\n            f\"{self.current_trajectory_name} - \"\n            f\"Step {self.i_step + 1}/{self.n_steps}\"\n        )\n\n    # --- Navigation actions ---\n\n    def action_next_step(self) -&gt; None:\n        self.i_step += 1\n\n    def action_previous_step(self) -&gt; None:\n        self.i_step -= 1\n\n    def action_first_step(self) -&gt; None:\n        self.i_step = 0\n\n    def action_last_step(self) -&gt; None:\n        self.i_step = self.n_steps - 1\n\n    def action_next_trajectory(self) -&gt; None:\n        self.i_trajectory += 1\n\n    def action_previous_trajectory(self) -&gt; None:\n        self.i_trajectory -= 1\n\n    def action_scroll_down(self) -&gt; None:\n        vs = self.query_one(VerticalScroll)\n        vs.scroll_to(y=vs.scroll_target_y + 15)\n\n    def action_scroll_up(self) -&gt; None:\n        vs = self.query_one(VerticalScroll)\n        vs.scroll_to(y=vs.scroll_target_y - 15)\n\n    def _open_in_jless(self, path: Path) -&gt; None:\n        \"\"\"Open file in jless.\"\"\"\n        with self.suspend():\n            try:\n                subprocess.run([\"jless\", path])\n            except FileNotFoundError:\n                self.notify(\"jless not found. Install with: `brew install jless`\", severity=\"error\")\n\n    def action_open_in_jless(self) -&gt; None:\n        \"\"\"Open the current step's messages in jless.\"\"\"\n        if not self.steps:\n            self.notify(\"No messages to display\", severity=\"warning\")\n            return\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n            json.dump(self.steps[self.i_step], f, indent=2)\n            temp_path = Path(f.name)\n        self._open_in_jless(temp_path)\n        temp_path.unlink()\n\n    def action_open_in_jless_all(self) -&gt; None:\n        \"\"\"Open the entire trajectory in jless.\"\"\"\n        if not self.trajectory_files:\n            self.notify(\"No trajectory to display\", severity=\"warning\")\n            return\n        self._open_in_jless(self.trajectory_files[self.i_trajectory])\n\n\n@app.command(help=__doc__)\ndef main(\n    path: str = typer.Argument(\".\", help=\"Directory to search for trajectory files or specific trajectory file\"),\n) -&gt; None:\n    path_obj = Path(path)\n\n    if path_obj.is_file():\n        trajectory_files = [path_obj]\n    elif path_obj.is_dir():\n        trajectory_files = sorted(path_obj.rglob(\"*.traj.json\"))\n        if not trajectory_files:\n            raise typer.BadParameter(f\"No trajectory files found in '{path}'\")\n    else:\n        raise typer.BadParameter(f\"Error: Path '{path}' does not exist\")\n\n    inspector = TrajectoryInspector(trajectory_files)\n    inspector.run()\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"usage/mini/","title":"<code>mini</code>","text":""},{"location":"usage/mini/#mini","title":"<code>mini</code>","text":"<p>Overview</p> <ul> <li><code>mini</code> is a REPL-style interactive command line interface for using mini-SWE-agent in the local environment (as opposed to workflows that require sandboxing or large scale batch processing).</li> </ul>"},{"location":"usage/mini/#command-line-options","title":"Command line options","text":"<p>Useful switches:</p> <ul> <li><code>-h</code>/<code>--help</code>: Show help</li> <li><code>-t</code>/<code>--task</code>: Specify a task to run (else you will be prompted)</li> <li><code>-c</code>/<code>--config</code>: Specify a config file to use, else we will use <code>mini.yaml</code> or the config <code>MSWEA_MINI_CONFIG_PATH</code> environment variable (see global configuration).   It's enough to specify the name of the config file, e.g., <code>-c mini.yaml</code> (see global configuration for how it is resolved).</li> <li><code>-m</code>/<code>--model</code>: Specify a model to use, else we will use the model <code>MSWEA_MODEL_NAME</code> environment variable (see global configuration)</li> <li><code>-y</code>/<code>--yolo</code>: Start in <code>yolo</code> mode (see below)</li> </ul>"},{"location":"usage/mini/#modes-of-operation","title":"Modes of operation","text":"<p><code>mini</code> provides three different modes of operation</p> <ul> <li><code>confirm</code> (<code>/c</code>): The LM proposes an action and the user is prompted to confirm (press Enter) or reject (enter a rejection message)</li> <li><code>yolo</code> (<code>/y</code>): The action from the LM is executed immediately without confirmation</li> <li><code>human</code> (<code>/u</code>): The user takes over to type and execute commands</li> </ul> <p>You can switch between the modes with the <code>/c</code>, <code>/y</code>, and <code>/u</code> commands that you can enter any time the agent is waiting for input. You can also press <code>Ctrl+C</code> to interrupt the agent at any time, allowing you to switch between modes.</p> <p><code>mini</code> starts in <code>confirm</code> mode by default. To start in <code>yolo</code> mode, you can add <code>-y</code>/<code>--yolo</code> to the command line.</p>"},{"location":"usage/mini/#miscellaneous-tips","title":"Miscellaneous tips","text":"<ul> <li><code>mini</code> saves the full history of your last run to your global config directory.   The path to the directory is printed when you start <code>mini</code>.</li> </ul>"},{"location":"usage/mini/#implementation","title":"Implementation","text":"Default config <ul> <li>Read on GitHub</li> </ul> <pre><code>agent:\n  system_template: |\n    You are a helpful assistant that can interact with a computer.\n  instance_template: |\n    Please solve this issue: {{task}}\n\n    You can execute bash commands and edit files to implement the necessary changes.\n\n    ## Recommended Workflow\n\n    This workflows should be done step-by-step so that you can iterate on your changes and any possible problems.\n\n    1. Analyze the codebase by finding and reading relevant files\n    2. Create a script to reproduce the issue\n    3. Edit the source code to resolve the issue\n    4. Verify your fix works by running your script again\n    5. Test edge cases to ensure your fix is robust\n    6. Submit your changes and finish your work by issuing the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`.\n       Do not combine it with any other command. &lt;important&gt;After this command, you cannot continue working on this task.&lt;/important&gt;\n\n    ## Command Execution Rules\n\n    You are operating in an environment where\n\n    1. You issue at least one command\n    2. The system executes the command(s) in a subshell\n    3. You see the result(s)\n    4. You write your next command(s)\n\n    Each response should include:\n\n    1. **Reasoning text** where you explain your analysis and plan\n    2. At least one tool call with your command\n\n    **CRITICAL REQUIREMENTS:**\n\n    - Your response SHOULD include reasoning text explaining what you're doing\n    - Your response MUST include AT LEAST ONE bash tool call\n    - Directory or environment variable changes are not persistent. Every action is executed in a new subshell.\n    - However, you can prefix any action with `MY_ENV_VAR=MY_VALUE cd /path/to/working/dir &amp;&amp; ...` or write/load environment variables from files\n    - Submit your changes and finish your work by issuing the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`.\n      Do not combine it with any other command. &lt;important&gt;After this command, you cannot continue working on this task.&lt;/important&gt;\n\n    Example of a CORRECT response:\n    &lt;example_response&gt;\n    I need to understand the structure of the repository first. Let me check what files are in the current directory to get a better understanding of the codebase.\n\n    [Makes bash tool call with {\"command\": \"ls -la\"} as arguments]\n    &lt;/example_response&gt;\n\n    &lt;system_information&gt;\n    {{system}} {{release}} {{version}} {{machine}}\n    &lt;/system_information&gt;\n\n    ## Useful command examples\n\n    ### Create a new file:\n\n    ```bash\n    cat &lt;&lt;'EOF' &gt; newfile.py\n    import numpy as np\n    hello = \"world\"\n    print(hello)\n    EOF\n    ```\n\n    ### Edit files with sed:\n\n    {%- if system == \"Darwin\" -%}\n    &lt;important&gt;\n    You are on MacOS. For all the below examples, you need to use `sed -i ''` instead of `sed -i`.\n    &lt;/important&gt;\n    {%- endif -%}\n\n    ```bash\n    # Replace all occurrences\n    sed -i 's/old_string/new_string/g' filename.py\n\n    # Replace only first occurrence\n    sed -i 's/old_string/new_string/' filename.py\n\n    # Replace first occurrence on line 1\n    sed -i '1s/old_string/new_string/' filename.py\n\n    # Replace all occurrences in lines 1-10\n    sed -i '1,10s/old_string/new_string/g' filename.py\n    ```\n\n    ### View file content:\n\n    ```bash\n    # View specific lines with numbers\n    nl -ba filename.py | sed -n '10,20p'\n    ```\n\n    ### Any other command you want to run\n\n    ```bash\n    anything\n    ```\n  step_limit: 0\n  cost_limit: 3.\n  mode: confirm\nenvironment:\n  env:\n    PAGER: cat\n    MANPAGER: cat\n    LESS: -R\n    PIP_PROGRESS_BAR: 'off'\n    TQDM_DISABLE: '1'\nmodel:\n  observation_template: |\n    {%- if output.output | length &lt; 10000 -%}\n    {\n      \"returncode\": {{ output.returncode }},\n      \"output\": {{ output.output | tojson }}\n      {%- if output.exception_info %}, \"exception_info\": {{ output.exception_info | tojson }}{% endif %}\n    }\n    {%- else -%}\n    {\n      \"returncode\": {{ output.returncode }},\n      \"output_head\": {{ output.output[:5000] | tojson }},\n      \"output_tail\": {{ output.output[-5000:] | tojson }},\n      \"elided_chars\": {{ output.output | length - 10000 }},\n      \"warning\": \"Output too long.\"\n      {%- if output.exception_info %}, \"exception_info\": {{ output.exception_info | tojson }}{% endif %}\n    }\n    {%- endif -%}\n  format_error_template: |\n    Tool call error:\n\n    &lt;error&gt;\n    {{error}}\n    &lt;/error&gt;\n\n    Here is general guidance on how to submit correct toolcalls:\n\n    Every response needs to use the 'bash' tool at least once to execute commands.\n\n    Call the bash tool with your command as the argument:\n    - Tool: bash\n    - Arguments: {\"command\": \"your_command_here\"}\n\n    If you want to end the task, please issue the following command: `echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT`\n    without any other command.\n  model_kwargs:\n    drop_params: true\n</code></pre> Run script <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>#!/usr/bin/env python3\n\n\"\"\"Run mini-SWE-agent in your local environment. This is the default executable `mini`.\"\"\"\n# Read this first: https://mini-swe-agent.com/latest/usage/mini/  (usage)\n\nimport os\nfrom pathlib import Path\nfrom typing import Any\n\nimport typer\nfrom rich.console import Console\n\nfrom minisweagent import global_config_dir\nfrom minisweagent.agents import get_agent\nfrom minisweagent.agents.utils.prompt_user import _multiline_prompt\nfrom minisweagent.config import builtin_config_dir, get_config_from_spec\nfrom minisweagent.environments import get_environment\nfrom minisweagent.models import get_model\nfrom minisweagent.run.utilities.config import configure_if_first_time\nfrom minisweagent.utils.serialize import UNSET, recursive_merge\n\nDEFAULT_CONFIG_FILE = Path(os.getenv(\"MSWEA_MINI_CONFIG_PATH\", builtin_config_dir / \"mini.yaml\"))\nDEFAULT_OUTPUT_FILE = global_config_dir / \"last_mini_run.traj.json\"\n\n\n_HELP_TEXT = \"\"\"Run mini-SWE-agent in your local environment.\n\n[not dim]\nMore information about the usage: [bold green]https://mini-swe-agent.com/latest/usage/mini/[/bold green]\n[/not dim]\n\"\"\"\n\n_CONFIG_SPEC_HELP_TEXT = \"\"\"Path to config files, filenames, or key-value pairs.\n\n[bold red]IMPORTANT:[/bold red] [red]If you set this option, the default config file will not be used.[/red]\nSo you need to explicitly set it e.g., with [bold green]-c mini.yaml &lt;other options&gt;[/bold green]\n\nMultiple configs will be recursively merged.\n\nExamples:\n\n[bold red]-c model.model_kwargs.temperature=0[/bold red] [red]You forgot to add the default config file! See above.[/red]\n\n[bold green]-c mini.yaml -c model.model_kwargs.temperature=0.5[/bold green]\n\n[bold green]-c swebench.yaml agent.mode=yolo[/bold green]\n\"\"\"\n\nconsole = Console(highlight=False)\napp = typer.Typer(rich_markup_mode=\"rich\")\n\n\n# fmt: off\n@app.command(help=_HELP_TEXT)\ndef main(\n    model_name: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\",),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'litellm' or 'minisweagent.models.litellm_model.LitellmModel')\", rich_help_panel=\"Advanced\"),\n    agent_class: str | None = typer.Option(None, \"--agent-class\", help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\", rich_help_panel=\"Advanced\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment class to use (e.g., 'local' or 'minisweagent.environments.local.LocalEnvironment')\", rich_help_panel=\"Advanced\"),\n    task: str | None = typer.Option(None, \"-t\", \"--task\", help=\"Task/problem statement\", show_default=False),\n    yolo: bool = typer.Option(False, \"-y\", \"--yolo\", help=\"Run without confirmation\"),\n    cost_limit: float | None = typer.Option(None, \"-l\", \"--cost-limit\", help=\"Cost limit. Set to 0 to disable.\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT),\n    output: Path | None = typer.Option(DEFAULT_OUTPUT_FILE, \"-o\", \"--output\", help=\"Output trajectory file\"),\n    exit_immediately: bool = typer.Option(False, \"--exit-immediately\", help=\"Exit immediately when the agent wants to finish instead of prompting.\", rich_help_panel=\"Advanced\"),\n) -&gt; Any:\n    # fmt: on\n    configure_if_first_time()\n\n    # Build the config from the command line arguments\n    console.print(f\"Building agent config from specs: [bold green]{config_spec}[/bold green]\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"run\": {\n            \"task\": task or UNSET,\n        },\n        \"agent\": {\n            \"agent_class\": agent_class or UNSET,\n            \"mode\": \"yolo\" if yolo else UNSET,\n            \"cost_limit\": cost_limit or UNSET,\n            \"confirm_exit\": False if exit_immediately else UNSET,\n            \"output_path\": output or UNSET,\n        },\n        \"model\": {\n            \"model_class\": model_class or UNSET,\n            \"model_name\": model_name or UNSET,\n        },\n        \"environment\": {\n            \"environment_class\": environment_class or UNSET,\n        },\n    })\n    config = recursive_merge(*configs)\n\n    if (run_task := config.get(\"run\", {}).get(\"task\", UNSET)) is UNSET:\n        console.print(\"[bold yellow]What do you want to do?\")\n        run_task = _multiline_prompt()\n        console.print(\"[bold green]Got that, thanks![/bold green]\")\n\n    model = get_model(config=config.get(\"model\", {}))\n    env = get_environment(config.get(\"environment\", {}), default_type=\"local\")\n    agent = get_agent(model, env, config.get(\"agent\", {}), default_type=\"interactive\")\n    agent.run(run_task)\n    if (output_path := config.get(\"agent\", {}).get(\"output_path\")):\n        console.print(f\"Saved trajectory to [bold green]'{output_path}'[/bold green]\")\n    return agent\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> Agent class <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>\"\"\"A small generalization of the default agent that puts the user in the loop.\n\nThere are three modes:\n- human: commands issued by the user are executed immediately\n- confirm: commands issued by the LM but not whitelisted are confirmed by the user\n- yolo: commands issued by the LM are executed immediately without confirmation\n\"\"\"\n\nimport re\nfrom typing import Literal, NoReturn\n\nfrom rich.console import Console\nfrom rich.rule import Rule\n\nfrom minisweagent.agents.default import AgentConfig, DefaultAgent\nfrom minisweagent.agents.utils.prompt_user import _multiline_prompt, prompt_session\nfrom minisweagent.exceptions import LimitsExceeded, Submitted, UserInterruption\nfrom minisweagent.models.utils.content_string import get_content_string\n\nconsole = Console(highlight=False)\n\n\nclass InteractiveAgentConfig(AgentConfig):\n    mode: Literal[\"human\", \"confirm\", \"yolo\"] = \"confirm\"\n    \"\"\"Whether to confirm actions.\"\"\"\n    whitelist_actions: list[str] = []\n    \"\"\"Never confirm actions that match these regular expressions.\"\"\"\n    confirm_exit: bool = True\n    \"\"\"If the agent wants to finish, do we ask for confirmation from user?\"\"\"\n\n\nclass InteractiveAgent(DefaultAgent):\n    _MODE_COMMANDS_MAPPING = {\"/u\": \"human\", \"/c\": \"confirm\", \"/y\": \"yolo\"}\n\n    def __init__(self, *args, config_class=InteractiveAgentConfig, **kwargs):\n        super().__init__(*args, config_class=config_class, **kwargs)\n        self.cost_last_confirmed = 0.0\n\n    def _interrupt(self, content: str, *, itype: str = \"UserInterruption\") -&gt; NoReturn:\n        raise UserInterruption({\"role\": \"user\", \"content\": content, \"extra\": {\"interrupt_type\": itype}})\n\n    def add_messages(self, *messages: dict) -&gt; list[dict]:\n        # Extend supermethod to print messages\n        for msg in messages:\n            role, content = msg.get(\"role\") or msg.get(\"type\", \"unknown\"), get_content_string(msg)\n            if role == \"assistant\":\n                console.print(\n                    f\"\\n[red][bold]mini-swe-agent[/bold] (step [bold]{self.n_calls}[/bold], [bold]${self.cost:.2f}[/bold]):[/red]\\n\",\n                    end=\"\",\n                    highlight=False,\n                )\n            else:\n                console.print(f\"\\n[bold green]{role.capitalize()}[/bold green]:\\n\", end=\"\", highlight=False)\n            console.print(content, highlight=False, markup=False)\n        return super().add_messages(*messages)\n\n    def query(self) -&gt; dict:\n        # Extend supermethod to handle human mode\n        if self.config.mode == \"human\":\n            match command := self._prompt_and_handle_slash_commands(\"[bold yellow]&gt;[/bold yellow] \"):\n                case \"/y\" | \"/c\":\n                    pass\n                case _:\n                    msg = {\n                        \"role\": \"user\",\n                        \"content\": f\"User command: \\n```bash\\n{command}\\n```\",\n                        \"extra\": {\"actions\": [{\"command\": command}]},\n                    }\n                    self.add_messages(msg)\n                    return msg\n        try:\n            with console.status(\"Waiting for the LM to respond...\"):\n                return super().query()\n        except LimitsExceeded:\n            console.print(\n                f\"Limits exceeded. Limits: {self.config.step_limit} steps, ${self.config.cost_limit}.\\n\"\n                f\"Current spend: {self.n_calls} steps, ${self.cost:.2f}.\"\n            )\n            self.config.step_limit = int(input(\"New step limit: \"))\n            self.config.cost_limit = float(input(\"New cost limit: \"))\n            return super().query()\n\n    def step(self) -&gt; list[dict]:\n        # Override the step method to handle user interruption\n        try:\n            console.print(Rule())\n            return super().step()\n        except KeyboardInterrupt:\n            interruption_message = self._prompt_and_handle_slash_commands(\n                \"\\n\\n[bold yellow]Interrupted.[/bold yellow] \"\n                \"[green]Type a comment/command[/green] (/h for available commands)\"\n                \"\\n[bold yellow]&gt;[/bold yellow] \"\n            ).strip()\n            if not interruption_message or interruption_message in self._MODE_COMMANDS_MAPPING:\n                interruption_message = \"Temporary interruption caught.\"\n            self._interrupt(f\"Interrupted by user: {interruption_message}\")\n\n    def execute_actions(self, message: dict) -&gt; list[dict]:\n        # Override to handle user confirmation and confirm_exit, with try/finally to preserve partial outputs\n        actions = message.get(\"extra\", {}).get(\"actions\", [])\n        commands = [action[\"command\"] for action in actions]\n        outputs = []\n        try:\n            self._ask_confirmation_or_interrupt(commands)\n            for action in actions:\n                outputs.append(self.env.execute(action))\n        except Submitted as e:\n            self._check_for_new_task_or_submit(e)\n        finally:\n            result = self.add_messages(\n                *self.model.format_observation_messages(message, outputs, self.get_template_vars())\n            )\n        return result\n\n    def _add_observation_messages(self, message: dict, outputs: list[dict]) -&gt; list[dict]:\n        return self.add_messages(*self.model.format_observation_messages(message, outputs, self.get_template_vars()))\n\n    def _check_for_new_task_or_submit(self, e: Submitted) -&gt; NoReturn:\n        \"\"\"Check if user wants to add a new task or submit.\"\"\"\n        if self.config.confirm_exit:\n            message = (\n                \"[bold yellow]Agent wants to finish.[/bold yellow] \"\n                \"[bold green]Type new task[/bold green] or [bold]Enter[/bold] to quit \"\n                \"([bold]/h[/bold] for commands)\\n\"\n                \"[bold yellow]&gt;[/bold yellow] \"\n            )\n            user_input = self._prompt_and_handle_slash_commands(message).strip()\n            if user_input == \"/u\":  # directly continue\n                self._interrupt(\"Switched to human mode.\")\n            elif user_input in self._MODE_COMMANDS_MAPPING:  # ask again\n                return self._check_for_new_task_or_submit(e)\n            elif user_input:\n                self._interrupt(f\"The user added a new task: {user_input}\", itype=\"UserNewTask\")\n        raise e\n\n    def _should_ask_confirmation(self, action: str) -&gt; bool:\n        return self.config.mode == \"confirm\" and not any(re.match(r, action) for r in self.config.whitelist_actions)\n\n    def _ask_confirmation_or_interrupt(self, commands: list[str]) -&gt; None:\n        if not any(self._should_ask_confirmation(c) for c in commands):\n            return\n        prompt = (\n            f\"[bold yellow]Execute {len(commands)} action(s)?[/] [green][bold]Enter[/] to confirm[/], \"\n            \"[red]type [bold]comment[/] to reject[/], or [blue][bold]/h[/] to show available commands[/]\\n\"\n            \"[bold yellow]&gt;[/bold yellow] \"\n        )\n        match user_input := self._prompt_and_handle_slash_commands(prompt).strip():\n            case \"\" | \"/y\":\n                pass  # confirmed, do nothing\n            case \"/u\":  # Skip execution action and get back to query\n                self._interrupt(\"Commands not executed. Switching to human mode\", itype=\"UserRejection\")\n            case _:\n                self._interrupt(\n                    f\"Commands not executed. The user rejected your commands with the following message: {user_input}\",\n                    itype=\"UserRejection\",\n                )\n\n    def _prompt_and_handle_slash_commands(self, prompt: str, *, _multiline: bool = False) -&gt; str:\n        \"\"\"Prompts the user, takes care of /h (followed by requery) and sets the mode. Returns the user input.\"\"\"\n        console.print(prompt, end=\"\")\n        if _multiline:\n            return _multiline_prompt()\n        user_input = prompt_session.prompt(\"\")\n        if user_input == \"/m\":\n            return self._prompt_and_handle_slash_commands(prompt, _multiline=True)\n        if user_input == \"/h\":\n            console.print(\n                f\"Current mode: [bold green]{self.config.mode}[/bold green]\\n\"\n                f\"[bold green]/y[/bold green] to switch to [bold yellow]yolo[/bold yellow] mode (execute LM commands without confirmation)\\n\"\n                f\"[bold green]/c[/bold green] to switch to [bold yellow]confirmation[/bold yellow] mode (ask for confirmation before executing LM commands)\\n\"\n                f\"[bold green]/u[/bold green] to switch to [bold yellow]human[/bold yellow] mode (execute commands issued by the user)\\n\"\n                f\"[bold green]/m[/bold green] to enter multiline comment\",\n            )\n            return self._prompt_and_handle_slash_commands(prompt)\n        if user_input in self._MODE_COMMANDS_MAPPING:\n            if self.config.mode == self._MODE_COMMANDS_MAPPING[user_input]:\n                return self._prompt_and_handle_slash_commands(\n                    f\"[bold red]Already in {self.config.mode} mode.[/bold red]\\n{prompt}\"\n                )\n            self.config.mode = self._MODE_COMMANDS_MAPPING[user_input]\n            console.print(f\"Switched to [bold green]{self.config.mode}[/bold green] mode.\")\n            return user_input\n        return user_input\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"usage/output_files/","title":"Output files","text":""},{"location":"usage/output_files/#output-files","title":"Output files","text":"<p>Overview</p> <p>mini-SWE-agent saves run results in JSON format. This page documents the structure of these output files.</p>"},{"location":"usage/output_files/#trajectory-files-trajjson","title":"Trajectory files (<code>.traj.json</code>)","text":"<p>v2.0 format changes</p> <p>The output format changed in v2.0 (<code>trajectory_format: mini-swe-agent-1.1</code>). See the v2 migration guide for more information.</p> <p>Viewing trajectory files</p> <p>Use the inspector to browse trajectory files interactively.</p> <p>Trajectory files contain the full history of an agent run, including all messages, configuration, and metadata.</p>"},{"location":"usage/output_files/#structure","title":"Structure","text":"<pre><code>{\n  \"info\": {\n    \"model_stats\": {\n      \"instance_cost\": 0.05,  // total cost of API calls for this run\n      \"api_calls\": 12  // number of API calls made\n    },\n    \"config\": {\n      \"agent\": { ... },  // agent configuration\n      \"agent_type\": \"minisweagent.agents.default.DefaultAgent\",\n      \"model\": { ... },  // model configuration\n      \"model_type\": \"minisweagent.models.litellm_model.LitellmModel\",\n      \"environment\": { ... },  // environment configuration\n      \"environment_type\": \"minisweagent.environments.local.LocalEnvironment\"\n    },\n    \"mini_version\": \"2.0.0\",  // version of mini-SWE-agent used\n    \"exit_status\": \"Submitted\",  // final status (Submitted, LimitsExceeded, etc.)\n    \"submission\": \"...\"  // final output/patch submitted by the agent (if any)\n  },\n  \"messages\": [  // full conversation history\n    {\"role\": \"system\", \"content\": \"...\"},\n    {\"role\": \"user\", \"content\": \"...\"},\n    {\"role\": \"assistant\", \"content\": \"...\"},\n    ...\n  ],\n  \"trajectory_format\": \"mini-swe-agent-1.1\"  // format version identifier\n}\n</code></pre> <p>Messages follow the OpenAI chat format with an additional <code>extra</code> field for mini-SWE-agent metadata. Models may add other fields to messages (e.g., <code>tool_calls</code>, <code>reasoning_content</code>).</p> <p>Toolcall models</p> <p>When using toolcall-based models (e.g., <code>LitellmToolcallModel</code>), the roles differ slightly: assistant messages include <code>tool_calls</code> instead of content, and observation messages use <code>role: \"tool\"</code> with a <code>tool_call_id</code> field.</p> <pre><code>// System message (agent instructions)\n{\"role\": \"system\", \"content\": \"You are a helpful assistant...\"}\n\n// User message (task description)\n{\"role\": \"user\", \"content\": \"Please solve this issue: ...\"}\n\n// Assistant message (model response with parsed actions)\n{\n  \"role\": \"assistant\",\n  \"content\": \"Let me check the files...\\n\\n```mswea_bash_command\\nls -la\\n```\",\n  \"extra\": {\n    \"actions\": [{\"command\": \"ls -la\"}],  // parsed actions to execute\n    \"cost\": 0.003,  // cost of this API call\n    \"timestamp\": 1706000000.0,  // unix timestamp of when this message was created\n    \"response\": { ... }  // raw API response\n  }\n}\n\n// Observation message (execution result)\n{\n  \"role\": \"user\",\n  \"content\": \"&lt;returncode&gt;0&lt;/returncode&gt;\\n&lt;output&gt;\\nfile1.py\\nfile2.py\\n&lt;/output&gt;\",\n  \"extra\": {\n    \"returncode\": 0,\n    \"timestamp\": 1706000001.0\n  }\n}\n\n// Final message (when agent submits)\n{\n  \"role\": \"user\",\n  \"content\": \"\",\n  \"extra\": {\n    \"exit_status\": \"Submitted\",\n    \"submission\": \"diff --git a/file.py...\"\n  }\n}\n</code></pre>"},{"location":"usage/output_files/#predsjson-format","title":"<code>preds.json</code> format","text":"<p>The predictions file aggregates results from all instances in a format compatible with SWE-bench evaluation:</p> <pre><code>{\n  \"owner__repo__123\": {  // keyed by instance_id\n    \"model_name_or_path\": \"anthropic/claude-sonnet-4-5-20250929\",  // model used\n    \"instance_id\": \"owner__repo__123\",  // SWE-bench instance identifier\n    \"model_patch\": \"diff --git a/file.py b/file.py\\n...\"  // generated patch (unified diff)\n  },\n  ...\n}\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"usage/python_bindings/","title":"Basic Python bindings","text":""},{"location":"usage/python_bindings/#python-bindings","title":"Python bindings","text":"<p>Overview</p> <p>This page shows the most basic example of how to use mini-SWE-agent as a Python library. For more advanced usage, subclassing, and mix &amp; match of components, see subclassing and more.</p>"},{"location":"usage/python_bindings/#hello-world","title":"Hello world","text":"<pre><code>import logging\n\nfrom minisweagent.agents.default import DefaultAgent\nfrom minisweagent.models import get_model\nfrom minisweagent.environments.local import LocalEnvironment\n\nlogging.basicConfig(level=logging.DEBUG)\ntask = \"Write a hello world program\"\nmodel_name = \"anthropic/claude-sonnet-4-5-20250929\"\n\nagent = DefaultAgent(\n    get_model(input_model_name=model_name),\n    LocalEnvironment(),\n)\n\n# Run the agent\nagent.run(task)\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"},{"location":"usage/swebench/","title":"SWE-bench","text":""},{"location":"usage/swebench/#swe-bench","title":"SWE-bench","text":"<p>Overview</p> <ul> <li>We provide two scripts to run on the SWE-bench benchmark.</li> <li><code>mini-extra swebench</code> runs on all task instances in batch mode.</li> <li><code>mini-extra swebench-single</code> runs on a single task instance with interactivity (useful for debugging).</li> <li>You can also take a look at the runscripts to figure out how to build your own batch processing pipeline.</li> </ul>"},{"location":"usage/swebench/#usage","title":"Usage","text":"<p>Docker container availability</p> <p>The docker containers for Linux assume an x86 Linux architecture; you might not be able to run them on other architectures.</p> <p>Quickstart</p> <p>We provide two different scripts: <code>swebench</code> and <code>swebench-single</code>:</p> Batch modeSingle instance (for debugging) <p>Batch mode runs on all task instances in parallel.</p> <pre><code>mini-extra swebench --help\n# or\npython src/minisweagent/run/benchmarks/swebench.py --help\n# Example:\nmini-extra swebench \\\n    --model anthropic/claude-sonnet-4-5-20250929 \\\n    --subset verified \\\n    --split test \\\n    --workers 4\n</code></pre> <p>Basic flags:</p> <ul> <li><code>-o</code>, <code>--output</code> - Output directory</li> <li><code>-m</code>, <code>--model</code> - Model to use</li> <li><code>-c</code>, <code>--config</code> - Path to a config file (default: <code>swebench.yaml</code> in the <code>config</code> directory)</li> <li><code>-w</code>, <code>--workers</code> - Number of worker threads for parallel processing (default: <code>1</code>)</li> </ul> <p>Data selection flags:</p> <ul> <li><code>--subset</code> - SWEBench subset to use or path to a dataset (default: <code>lite</code>)</li> <li><code>--split</code> - Dataset split (default: <code>dev</code>)</li> <li><code>--slice</code> - Slice specification (e.g., '0:5' for first 5 instances)</li> <li><code>--filter</code> - Filter instance IDs by regex</li> <li><code>--shuffle</code> - Shuffle instances (default: <code>False</code>)</li> <li><code>--redo-existing</code> - Redo existing instances (default: <code>False</code>)</li> </ul> <p>Advanced flags:</p> <ul> <li><code>--environment-class</code> - Environment type to use (recommended: <code>docker</code> or <code>singularity</code>)</li> </ul> <p>Single instance mode runs on a single task instance with interactivity. This is meant for debugging, and so unlike the batch mode command above, this will not produce a preds.json file.</p> <pre><code>mini-extra swebench-single --help\n# or\npython src/minisweagent/run/benchmarks/swebench_single.py --help\n# Example:\nmini-extra swebench-single \\\n    --subset verified \\\n    --split test \\\n    --model anthropic/claude-sonnet-4-5-20250929 \\\n    -i sympy__sympy-15599\n# or\nmini-extra swebench-single \\\n    --subset verified \\\n    --split test \\\n    -m anthropic/claude-sonnet-4-5-20250929 \\\n    -i 0  # instance index\n</code></pre> <p>Note: If you want to run the script without prompting for confirmation at exit, add the <code>--exit-immediately</code> flag.</p> <p>Basic flags:</p> <ul> <li><code>-m</code>, <code>--model</code> - Model to use</li> <li><code>-c</code>, <code>--config</code> - Path to a config file (default: <code>swebench.yaml</code> in the <code>config</code> directory)</li> <li><code>-o</code>, <code>--output</code> - Output trajectory file (default: saves to global config directory)</li> </ul> <p>Data selection flags:</p> <ul> <li><code>--subset</code> - SWEBench subset to use or path to a dataset (default: <code>lite</code>)</li> <li><code>--split</code> - Dataset split (default: <code>dev</code>)</li> <li><code>-i</code>, <code>--instance</code> - SWE-Bench instance ID (default: <code>0</code>)</li> </ul> <p>Advanced flags:</p> <ul> <li><code>--environment-class</code> - Environment type to use (recommended: <code>docker</code> or <code>singularity</code>)</li> <li><code>--exit-immediately</code> - Exit immediately when the agent wants to finish instead of prompting (default: <code>False</code>)</li> </ul> <p>Evaluating on SWE-bench</p> <p>You have two options to evaluate on SWE-bench: Our free cloud-based evaluation or the SWE-bench CLI.</p> Cloud-based evaluationLocal evaluation <p>You can use the sb-cli for extremely fast, cloud-based evaluations (and it's free!). After installing it and getting a token, simply run:</p> <pre><code>sb-cli submit swe-bench_verified test --predictions_path preds.json --run_id some-id-for-your-run\n</code></pre> <p>Typically you will have results within 20 minutes (this is not limited by how many instances you run, but by the slowest-to-evaluate instance in SWE-bench).</p> <p>You can also use a local installation of SWE-bench for evaluation:</p> <pre><code>python -m swebench.harness.run_evaluation \\\n    --dataset_name princeton-nlp/SWE-bench_Verified \\\n    --predictions_path preds.jsonl \\\n    --max_workers &lt;num_workers&gt; \\\n    --run_id &lt;run_id&gt;\n</code></pre>"},{"location":"usage/swebench/#faq","title":"FAQ","text":"<p>Can I set global cost limits?</p> <p>Yes, you can set global cost limits with the <code>MSWEA_GLOBAL_CALL_LIMIT</code> and <code>MSWEA_GLOBAL_COST_LIMIT</code> environment variables/global config. See global configuration for more details.</p> <p>What happens to uncompleted tasks when I abort with KeyboardInterrupt?</p> <p>Trajectories are only saved upon completion, so most likely, you can just rerun the script to complete the tasks next time. However, you should still check for <code>KeyboardInterrupt</code> in <code>preds.json</code> in case some tasks were aborted but saved.</p> <p>Certain tasks are being stuck even though I deleted the trajectories.</p> <p>The completed instances are inferred from <code>preds.json</code>. Remove the corresponding items from the file.</p> <p>How can I run on a different dataset?</p> <p>As long as it follows the SWE-bench format, you can use <code>--subset /path/to/your/dataset</code> to run on a custom dataset. The dataset needs to be loadable as <code>datasets.load_dataset(path, split=split)</code>.</p> <p>Some progress runners are stuck at 'initializing task' for a very long time / time out</p> <p>They might be pulling docker containers -- the run should start immediately the next time. If you see timeouts because of <code>docker pull</code> operations, you might want to increase <code>environment.pull_timeout</code> from the default of <code>120</code> (seconds).</p> <p>I have some docker issues</p> <p>Try running the docker command manually to see what's going on (it should be printed out in the console). Confirm that it's running with <code>docker ps</code>, and that you can use <code>docker exec -it &lt;container-id&gt; ls</code> to get some output.</p> <p>Docker isn't available on my HPC cluster.</p> <p>You can use the singularity/apptainer backend by setting <code>environment.environment_class</code> to <code>singularity</code> in your agent config file or specify <code>--environment-class singularity</code> from the command line</p> <p>Can I run a startup command in the environment?</p> <p>Yes, you can use the <code>run.env_startup_command</code> config option to run a command in the environment before the agent starts. For example:</p> <pre><code>run:\n  env_startup_command: \"apt-get update &amp;&amp; apt-get install -y python3-pip\"\n</code></pre> <p>The command is rendered with the instance variables as template variables using <code>jinja2</code>. For example, you could use</p> <pre><code>run:\n  env_startup_command: \"git clone {{ repo_url }} . --force\"\n</code></pre> <p>which might be particularly useful when running with environments like <code>bubblewrap</code>.</p> <p>What environment can I use for SWE-bench?</p> <p>See this guide for more details.</p>"},{"location":"usage/swebench/#implementation","title":"Implementation","text":"Default config <ul> <li>Read on GitHub</li> </ul> <pre><code>agent:\n  system_template: |\n    You are a helpful assistant that can interact with a computer shell to solve programming tasks.\n  instance_template: |\n    &lt;pr_description&gt;\n    Consider the following PR description:\n    {{task}}\n    &lt;/pr_description&gt;\n\n    &lt;instructions&gt;\n    # Task Instructions\n\n    ## Overview\n\n    You're a software engineer interacting continuously with a computer by submitting commands.\n    You'll be helping implement necessary changes to meet requirements in the PR description.\n    Your task is specifically to make changes to non-test files in the current directory in order to fix the issue described in the PR description in a way that is general and consistent with the codebase.\n    &lt;IMPORTANT&gt;This is an interactive process where you will think and issue AT LEAST ONE command, see the result, then think and issue your next command(s).&lt;/important&gt;\n\n    For each response:\n\n    1. Include a THOUGHT section explaining your reasoning and what you're trying to accomplish\n    2. Provide one or more bash tool calls to execute\n\n    ## Important Boundaries\n\n    - MODIFY: Regular source code files in /testbed (this is the working directory for all your subsequent commands)\n    - DO NOT MODIFY: Tests, configuration files (pyproject.toml, setup.cfg, etc.)\n\n    ## Recommended Workflow\n\n    1. Analyze the codebase by finding and reading relevant files\n    2. Create a script to reproduce the issue\n    3. Edit the source code to resolve the issue\n    4. Verify your fix works by running your script again\n    5. Test edge cases to ensure your fix is robust\n\n    ## Command Execution Rules\n\n    You are operating in an environment where\n\n    1. You issue at least one command\n    2. The system executes the command(s) in a subshell\n    3. You see the result(s)\n    4. You write your next command(s)\n\n    Each response should include:\n\n    1. **Reasoning text** where you explain your analysis and plan\n    2. At least one tool call with your command\n\n    **CRITICAL REQUIREMENTS:**\n\n    - Your response SHOULD include reasoning text explaining what you're doing\n    - Your response MUST include AT LEAST ONE bash tool call. You can make MULTIPLE tool calls in a single response when the commands are independent (e.g., searching multiple files, reading different parts of the codebase).\n    - Directory or environment variable changes are not persistent. Every action is executed in a new subshell.\n    - However, you can prefix any action with `MY_ENV_VAR=MY_VALUE cd /path/to/working/dir &amp;&amp; ...` or write/load environment variables from files\n\n    Example of a CORRECT response:\n    &lt;example_response&gt;\n    I need to understand the Builder-related code. Let me find relevant files and check the project structure.\n\n    [Makes multiple bash tool calls: {\"command\": \"ls -la\"}, {\"command\": \"find src -name '*.java' | grep -i builder\"}, {\"command\": \"cat README.md | head -50\"}]\n    &lt;/example_response&gt;\n\n    ## Environment Details\n\n    - You have a full Linux shell environment\n    - Always use non-interactive flags (-y, -f) for commands\n    - Avoid interactive tools like vi, nano, or any that require user input\n    - You can use bash commands or invoke any tool that is available in the environment\n    - You can also create new tools or scripts to help you with the task\n    - If a tool isn't available, you can also install it\n\n    ## Submission\n\n    When you've completed your work, you MUST submit your changes as a git patch.\n    Follow these steps IN ORDER, with SEPARATE commands:\n\n    Step 1: Create the patch file\n    Run `git diff -- path/to/file1 path/to/file2 &gt; patch.txt` listing only the source files you modified.\n    Do NOT commit your changes.\n\n    &lt;IMPORTANT&gt;\n    The patch must only contain changes to the specific source files you modified to fix the issue.\n    Do not submit file creations or changes to any of the following files:\n\n    - test and reproduction files\n    - helper scripts, tests, or tools that you created\n    - installation, build, packaging, configuration, or setup scripts unless they are directly part of the issue you were fixing (you can assume that the environment is already set up for your client)\n    - binary or compiled files\n    &lt;/IMPORTANT&gt;\n\n    Step 2: Verify your patch\n    Inspect patch.txt to confirm it only contains your intended changes and headers show `--- a/` and `+++ b/` paths.\n\n    Step 3: Submit (EXACT command required)\n    You MUST use this EXACT command to submit:\n\n    ```bash\n    echo COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT &amp;&amp; cat patch.txt\n    ```\n\n    If the command fails (nonzero exit status), it will not submit.\n\n    &lt;CRITICAL&gt;\n    - Creating/viewing the patch and submitting it MUST be separate commands (not combined with &amp;&amp;).\n    - If you modify patch.txt after verifying, you SHOULD verify again before submitting.\n    - You CANNOT continue working (reading, editing, testing) in any way on this task after submitting.\n    &lt;/CRITICAL&gt;\n    &lt;/instructions&gt;\n  step_limit: 250\n  cost_limit: 3.\n\nenvironment:\n  cwd: \"/testbed\"\n  timeout: 60\n  interpreter: [\"bash\", \"-c\"]\n  env:\n    PAGER: cat\n    MANPAGER: cat\n    LESS: -R\n    PIP_PROGRESS_BAR: \"off\"\n    TQDM_DISABLE: \"1\"\n  environment_class: docker\n\nmodel:\n  observation_template: |\n    {% if output.exception_info -%}\n    &lt;exception&gt;{{output.exception_info}}&lt;/exception&gt;\n    {% endif -%}\n    &lt;returncode&gt;{{output.returncode}}&lt;/returncode&gt;\n    {% if output.output | length &lt; 10000 -%}\n    &lt;output&gt;\n    {{ output.output -}}\n    &lt;/output&gt;\n    {%- else -%}\n    &lt;warning&gt;\n    The output of your last command was too long.\n    Please try a different command that produces less output.\n    If you're looking at a file you can try use head, tail or sed to view a smaller number of lines selectively.\n    If you're using grep or find and it produced too much output, you can use a more selective search pattern.\n    If you really need to see something from the full command's output, you can redirect output to a file and then search in that file.\n    &lt;/warning&gt;\n    {%- set elided_chars = output.output | length - 10000 -%}\n    &lt;output_head&gt;\n    {{ output.output[:5000] }}\n    &lt;/output_head&gt;\n    &lt;elided_chars&gt;\n    {{ elided_chars }} characters elided\n    &lt;/elided_chars&gt;\n    &lt;output_tail&gt;\n    {{ output.output[-5000:] }}\n    &lt;/output_tail&gt;\n    {%- endif -%}\n  format_error_template: |\n    Tool call error:\n\n    &lt;error&gt;\n    {{error}}\n    &lt;/error&gt;\n\n    Here is general guidance on how to submit correct toolcalls:\n\n    Every response needs to use the 'bash' tool at least once to execute commands.\n\n    Call the bash tool with your command as the argument:\n    - Tool: bash\n    - Arguments: {\"command\": \"your_command_here\"}\n\n    If you have completed your assignment, please consult the first message about how to\n    submit your solution (you will not be able to continue working on this task after that).\n  model_name: \"anthropic/claude-sonnet-4-5-20250929\"\n  model_kwargs:\n    drop_params: true\n    temperature: 0.0\n    parallel_tool_calls: true\n</code></pre> <code>swebench.py</code> run script <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>#!/usr/bin/env python3\n\n\"\"\"Run mini-SWE-agent on SWE-bench instances in batch mode.\"\"\"\n# Read this first: https://mini-swe-agent.com/latest/usage/swebench/  (usage docs)\n\nimport concurrent.futures\nimport json\nimport random\nimport re\nimport threading\nimport time\nimport traceback\nfrom pathlib import Path\n\nimport typer\nfrom jinja2 import StrictUndefined, Template\nfrom rich.live import Live\n\nfrom rich.console import Console\n\nfrom minisweagent import Environment\nfrom minisweagent.agents import get_agent_class\nfrom minisweagent.agents.default import DefaultAgent\nfrom minisweagent.config import builtin_config_dir, get_config_from_spec\nfrom minisweagent.environments import get_environment\nfrom minisweagent.models import get_model\nfrom minisweagent.run.benchmarks.utils.batch_progress import RunBatchProgressManager\nfrom minisweagent.utils.log import add_file_handler, logger\nfrom minisweagent.utils.serialize import UNSET, recursive_merge\n\n_console = Console(highlight=False)\n\n_HELP_TEXT = \"\"\"Run mini-SWE-agent on SWEBench instances.\n\n[not dim]\nMore information about the usage: [bold green]https://mini-swe-agent.com/latest/usage/swebench/[/bold green]\n[/not dim]\n\"\"\"\n\n_CONFIG_SPEC_HELP_TEXT = \"\"\"Path to config files, filenames, or key-value pairs.\n\n[bold red]IMPORTANT:[/bold red] [red]If you set this option, the default config file will not be used.[/red]\nSo you need to explicitly set it e.g., with [bold green]-c swebench.yaml &lt;other options&gt;[/bold green]\n\nMultiple configs will be recursively merged.\n\nExamples:\n\n[bold red]-c model.model_kwargs.temperature=0[/bold red] [red]You forgot to add the default config file! See above.[/red]\n\n[bold green]-c swebench.yaml -c model.model_kwargs.temperature=0.5[/bold green]\n\n[bold green]-c swebench.yaml -c agent.max_iterations=50[/bold green]\n\"\"\"\n\nDEFAULT_CONFIG_FILE = builtin_config_dir / \"benchmarks\" / \"swebench.yaml\"\n\nDATASET_MAPPING = {\n    \"full\": \"princeton-nlp/SWE-Bench\",\n    \"verified\": \"princeton-nlp/SWE-Bench_Verified\",\n    \"lite\": \"princeton-nlp/SWE-Bench_Lite\",\n    \"multimodal\": \"princeton-nlp/SWE-Bench_Multimodal\",\n    \"multilingual\": \"swe-bench/SWE-Bench_Multilingual\",\n    \"smith\": \"SWE-bench/SWE-smith\",\n    \"_test\": \"klieret/swe-bench-dummy-test-dataset\",\n    \"rebench\": \"nebius/SWE-rebench\",\n}\n\napp = typer.Typer(rich_markup_mode=\"rich\", add_completion=False)\n_OUTPUT_FILE_LOCK = threading.Lock()\n\n\ndef _make_progress_tracking_class(base_class: type) -&gt; type:\n    \"\"\"Create a progress-tracking subclass of any agent class.\"\"\"\n\n    class ProgressTrackingAgent(base_class):\n        \"\"\"Wrapper that provides progress updates for batch runs.\"\"\"\n\n        def __init__(self, *args, progress_manager: RunBatchProgressManager, instance_id: str = \"\", **kwargs):\n            super().__init__(*args, **kwargs)\n            self.progress_manager: RunBatchProgressManager = progress_manager\n            self.instance_id = instance_id\n\n        def step(self) -&gt; dict:\n            \"\"\"Override step to provide progress updates.\"\"\"\n            self.progress_manager.update_instance_status(\n                self.instance_id, f\"Step {self.n_calls + 1:3d} (${self.cost:.2f})\"\n            )\n            return super().step()\n\n    ProgressTrackingAgent.__name__ = f\"ProgressTracking{base_class.__name__}\"\n    ProgressTrackingAgent.__qualname__ = f\"ProgressTracking{base_class.__name__}\"\n    return ProgressTrackingAgent\n\n\ndef get_swebench_docker_image_name(instance: dict) -&gt; str:\n    \"\"\"Get the image name for a SWEBench instance.\"\"\"\n    image_name = instance.get(\"image_name\", None) or instance.get(\"docker_image\", None)\n    if image_name is None:\n        # Docker doesn't allow double underscore, so we replace them with a magic token\n        iid = instance[\"instance_id\"]\n        id_docker_compatible = iid.replace(\"__\", \"_1776_\")\n        image_name = f\"docker.io/swebench/sweb.eval.x86_64.{id_docker_compatible}:latest\".lower()\n    return image_name\n\n\ndef get_sb_environment(config: dict, instance: dict) -&gt; Environment:\n    env_config = config.setdefault(\"environment\", {})\n    env_config[\"environment_class\"] = env_config.get(\"environment_class\", \"docker\")\n    image_name = get_swebench_docker_image_name(instance)\n    if env_config[\"environment_class\"] in [\"docker\", \"swerex_modal\"]:\n        env_config[\"image\"] = image_name\n    elif env_config[\"environment_class\"] in [\"singularity\", \"contree\"]:\n        env_config[\"image\"] = \"docker://\" + image_name\n\n    env = get_environment(env_config)\n    if startup_command := config.get(\"run\", {}).get(\"env_startup_command\"):\n        startup_command = Template(startup_command, undefined=StrictUndefined).render(**instance)\n        out = env.execute(startup_command)\n        if out[\"returncode\"] != 0:\n            raise RuntimeError(f\"Error executing startup command: {out}\")\n    return env\n\n\ndef update_preds_file(output_path: Path, instance_id: str, model_name: str, result: str):\n    \"\"\"Update the output JSON file with results from a single instance.\"\"\"\n    with _OUTPUT_FILE_LOCK:\n        output_data = {}\n        if output_path.exists():\n            output_data = json.loads(output_path.read_text())\n        output_data[instance_id] = {\n            \"model_name_or_path\": model_name,\n            \"instance_id\": instance_id,\n            \"model_patch\": result,\n        }\n        output_path.write_text(json.dumps(output_data, indent=2))\n\n\ndef remove_from_preds_file(output_path: Path, instance_id: str):\n    \"\"\"Remove an instance from the predictions file.\"\"\"\n    if not output_path.exists():\n        return\n    with _OUTPUT_FILE_LOCK:\n        output_data = json.loads(output_path.read_text())\n        if instance_id in output_data:\n            del output_data[instance_id]\n            output_path.write_text(json.dumps(output_data, indent=2))\n\n\ndef evaluate_submission(env: Environment, instance: dict, submission: str) -&gt; dict | None:\n    \"\"\"Run FAIL_TO_PASS and PASS_TO_PASS tests after the agent has finished.\n\n    This is a post-task evaluation only -- results are logged but never fed\n    back to the agent.\n\n    Returns a results dict or None if tests could not be run.\n    \"\"\"\n    fail_to_pass_raw = instance.get(\"FAIL_TO_PASS\", \"[]\")\n    pass_to_pass_raw = instance.get(\"PASS_TO_PASS\", \"[]\")\n\n    try:\n        fail_to_pass = json.loads(fail_to_pass_raw) if isinstance(fail_to_pass_raw, str) else fail_to_pass_raw\n        pass_to_pass = json.loads(pass_to_pass_raw) if isinstance(pass_to_pass_raw, str) else pass_to_pass_raw\n    except json.JSONDecodeError:\n        logger.warning(\"Could not parse test lists for %s\", instance.get(\"instance_id\", \"?\"))\n        return None\n\n    if not fail_to_pass:\n        logger.info(\"No FAIL_TO_PASS tests for %s, skipping evaluation\", instance.get(\"instance_id\", \"?\"))\n        return None\n\n    _console.print(f\"\\n  [bold cyan]POST-TASK TEST EVALUATION[/bold cyan]  \"\n                    f\"({len(fail_to_pass)} fail_to_pass, {len(pass_to_pass)} pass_to_pass)\")\n\n    try:\n        # Reset to clean state and apply the submission patch\n        env.execute({\"command\": \"cd /testbed &amp;&amp; git checkout -- . &amp;&amp; git clean -fd\"})\n        env.execute({\"command\": f\"cat &gt; /tmp/eval_patch.diff &lt;&lt; 'EVAL_EOF'\\n{submission}\\nEVAL_EOF\"})\n        apply_result = env.execute({\"command\": \"cd /testbed &amp;&amp; git apply /tmp/eval_patch.diff 2&gt;&amp;1\"})\n        if apply_result.get(\"returncode\", -1) != 0:\n            _console.print(f\"  [red]FAIL[/red]  Could not apply patch: {apply_result.get('output', '')[:200]}\")\n            return None\n\n        # Apply test_patch if present (some instances need test file changes)\n        test_patch = instance.get(\"test_patch\", \"\")\n        if test_patch:\n            env.execute({\"command\": f\"cat &gt; /tmp/test_patch.diff &lt;&lt; 'TEST_EOF'\\n{test_patch}\\nTEST_EOF\"})\n            tp_result = env.execute({\"command\": \"cd /testbed &amp;&amp; git apply /tmp/test_patch.diff 2&gt;&amp;1\"})\n            if tp_result.get(\"returncode\", -1) != 0:\n                _console.print(f\"  [yellow]WARN[/yellow]  test_patch failed to apply (may already be present)\")\n\n        # Run FAIL_TO_PASS tests\n        _console.print(f\"\\n  [bold]FAIL_TO_PASS tests ({len(fail_to_pass)}):[/bold]\")\n        f2p_passed = 0\n        f2p_failed = []\n        for test_id in fail_to_pass:\n            passed = _run_single_test(env, test_id)\n            if passed:\n                f2p_passed += 1\n                _console.print(f\"    [green]PASS[/green]  {test_id}\")\n            else:\n                f2p_failed.append(test_id)\n                _console.print(f\"    [red]FAIL[/red]  {test_id}\")\n\n        # Run PASS_TO_PASS tests\n        p2p_passed = 0\n        p2p_failed = []\n        p2p_total = len(pass_to_pass)\n        if p2p_total &gt; 0:\n            _console.print(f\"\\n  [bold]PASS_TO_PASS tests ({p2p_total}):[/bold]\")\n            for test_id in pass_to_pass:\n                passed = _run_single_test(env, test_id)\n                if passed:\n                    p2p_passed += 1\n                    _console.print(f\"    [green]PASS[/green]  {test_id}\")\n                else:\n                    p2p_failed.append(test_id)\n                    _console.print(f\"    [red]FAIL[/red]  {test_id}\")\n\n        # Summary\n        f2p_pct = (f2p_passed / len(fail_to_pass) * 100) if fail_to_pass else 0\n        p2p_pct = (p2p_passed / p2p_total * 100) if p2p_total &gt; 0 else 100\n        all_passed = f2p_pct == 100 and p2p_pct == 100\n\n        _console.print()\n        _console.print(f\"  [bold]FAIL_TO_PASS:[/bold] {f2p_passed}/{len(fail_to_pass)} ({f2p_pct:.0f}%)\")\n        _console.print(f\"  [bold]PASS_TO_PASS:[/bold] {p2p_passed}/{p2p_total} ({p2p_pct:.0f}%)\")\n\n        if all_passed:\n            _console.print(f\"\\n  [green bold]RESOLVED[/green bold]  All tests pass!\")\n        elif f2p_pct &gt; 0 and p2p_pct == 100:\n            _console.print(f\"\\n  [yellow bold]PARTIAL[/yellow bold]  Some FAIL_TO_PASS tests still failing\")\n        else:\n            _console.print(f\"\\n  [red bold]NOT RESOLVED[/red bold]  Tests failing\")\n\n        return {\n            \"all_passed\": all_passed,\n            \"f2p_passed\": f2p_passed,\n            \"f2p_total\": len(fail_to_pass),\n            \"f2p_failed\": f2p_failed,\n            \"p2p_passed\": p2p_passed,\n            \"p2p_total\": p2p_total,\n            \"p2p_failed\": p2p_failed,\n        }\n    except Exception as e:\n        logger.warning(\"Test evaluation error for %s: %s\", instance.get(\"instance_id\", \"?\"), e)\n        return None\n\n\ndef _parse_django_test_id(test_id: str) -&gt; str | None:\n    \"\"\"Parse Django-style test ID like 'test_name (module.tests.ClassName)' into\n    a dotted path suitable for runtests.py: 'module.tests.ClassName.test_name'.\n    Returns None if test_id is not Django-style.\n    \"\"\"\n    m = re.match(r'^(\\S+)\\s+\\(([^)]+)\\)$', test_id)\n    if m:\n        test_name, module_path = m.group(1), m.group(2)\n        return f\"{module_path}.{test_name}\"\n    return None\n\n\ndef _run_single_test(env: Environment, test_id: str, timeout: int = 120) -&gt; bool:\n    \"\"\"Run a single test in the environment. Returns True if passed.\"\"\"\n    django_path = _parse_django_test_id(test_id)\n    if django_path is not None:\n        # Django uses its own test runner, not pytest\n        command = f\"cd /testbed &amp;&amp; python tests/runtests.py --settings=test_sqlite --parallel 1 -v 2 {django_path} 2&gt;&amp;1 | tail -30\"\n    else:\n        command = f\"cd /testbed &amp;&amp; python -m pytest -xvs {test_id} 2&gt;&amp;1 | tail -20\"\n\n    result = env.execute({\n        \"command\": command,\n        \"timeout\": timeout,\n    })\n    output = result.get(\"output\", \"\")\n    rc = result.get(\"returncode\", -1)\n    if rc == 0:\n        return True\n    # Fallback heuristic for pytest\n    if django_path is None and \" passed\" in output and \" failed\" not in output and \" error\" not in output.lower():\n        return True\n    # Fallback heuristic for Django runner: \"OK\" at end means success\n    if django_path is not None and re.search(r'\\bOK\\b', output) and 'FAILED' not in output:\n        return True\n    return False\n\n\ndef process_instance(\n    instance: dict,\n    output_dir: Path,\n    config: dict,\n    progress_manager: RunBatchProgressManager,\n) -&gt; None:\n    \"\"\"Process a single SWEBench instance.\"\"\"\n    instance_id = instance[\"instance_id\"]\n    instance_dir = output_dir / instance_id\n    # avoid inconsistent state if something here fails and there's leftover previous files\n    remove_from_preds_file(output_dir / \"preds.json\", instance_id)\n    (instance_dir / f\"{instance_id}.traj.json\").unlink(missing_ok=True)\n    model = get_model(config=config.get(\"model\", {}))\n    task = instance[\"problem_statement\"]\n\n    progress_manager.on_instance_start(instance_id)\n    progress_manager.update_instance_status(instance_id, \"Pulling/starting environment\")\n\n    agent = None\n    exit_status = None\n    result = None\n    extra_info = {}\n\n    try:\n        env = get_sb_environment(config, instance)\n        agent_config = dict(config.get(\"agent\", {}))\n        agent_class_spec = agent_config.pop(\"agent_class\", \"default\")\n        base_class = get_agent_class(agent_class_spec)\n        TrackedClass = _make_progress_tracking_class(base_class)\n        agent = TrackedClass(\n            model,\n            env,\n            progress_manager=progress_manager,\n            instance_id=instance_id,\n            **agent_config,\n        )\n        info = agent.run(task)\n        exit_status = info.get(\"exit_status\")\n        result = info.get(\"submission\")\n        # Post-task test evaluation (agent is done, results are only logged)\n        if result and exit_status == \"Submitted\":\n            progress_manager.update_instance_status(instance_id, \"Evaluating tests\")\n            test_results = evaluate_submission(env, instance, result)\n            if test_results:\n                extra_info[\"test_results\"] = test_results\n    except Exception as e:\n        logger.error(f\"Error processing instance {instance_id}: {e}\", exc_info=True)\n        exit_status, result = type(e).__name__, \"\"\n        extra_info = {\"traceback\": traceback.format_exc(), \"exception_str\": str(e)}\n    finally:\n        if agent is not None:\n            traj_path = instance_dir / f\"{instance_id}.traj.json\"\n            agent.save(\n                traj_path,\n                {\n                    \"info\": {\n                        \"exit_status\": exit_status,\n                        \"submission\": result,\n                        **extra_info,\n                    },\n                    \"instance_id\": instance_id,\n                },\n            )\n            logger.info(f\"Saved trajectory to '{traj_path}'\")\n        update_preds_file(output_dir / \"preds.json\", instance_id, model.config.model_name, result)\n        progress_manager.on_instance_end(instance_id, exit_status)\n\n\ndef filter_instances(\n    instances: list[dict], *, filter_spec: str, slice_spec: str = \"\", shuffle: bool = False\n) -&gt; list[dict]:\n    \"\"\"Filter and slice a list of SWEBench instances.\"\"\"\n    if shuffle:\n        instances = sorted(instances.copy(), key=lambda x: x[\"instance_id\"])\n        random.seed(42)\n        random.shuffle(instances)\n    before_filter = len(instances)\n    instances = [instance for instance in instances if re.match(filter_spec, instance[\"instance_id\"])]\n    if (after_filter := len(instances)) != before_filter:\n        logger.info(f\"Instance filter: {before_filter} -&gt; {after_filter} instances\")\n    if slice_spec:\n        values = [int(x) if x else None for x in slice_spec.split(\":\")]\n        instances = instances[slice(*values)]\n        if (after_slice := len(instances)) != before_filter:\n            logger.info(f\"Instance slice: {before_filter} -&gt; {after_slice} instances\")\n    return instances\n\n\n# fmt: off\n@app.command(help=_HELP_TEXT)\ndef main(\n    subset: str = typer.Option(\"lite\", \"--subset\", help=\"SWEBench subset to use or path to a dataset\", rich_help_panel=\"Data selection\"),\n    split: str = typer.Option(\"dev\", \"--split\", help=\"Dataset split\", rich_help_panel=\"Data selection\"),\n    slice_spec: str = typer.Option(\"\", \"--slice\", help=\"Slice specification (e.g., '0:5' for first 5 instances)\", rich_help_panel=\"Data selection\"),\n    filter_spec: str = typer.Option(\"\", \"--filter\", help=\"Filter instance IDs by regex\", rich_help_panel=\"Data selection\"),\n    shuffle: bool = typer.Option(False, \"--shuffle\", help=\"Shuffle instances\", rich_help_panel=\"Data selection\"),\n    output: str = typer.Option(\"\", \"-o\", \"--output\", help=\"Output directory\", rich_help_panel=\"Basic\"),\n    workers: int = typer.Option(1, \"-w\", \"--workers\", help=\"Number of worker threads for parallel processing\", rich_help_panel=\"Basic\"),\n    model: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\", rich_help_panel=\"Basic\"),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'anthropic' or 'minisweagent.models.anthropic.AnthropicModel')\", rich_help_panel=\"Advanced\"),\n    redo_existing: bool = typer.Option(False, \"--redo-existing\", help=\"Redo existing instances\", rich_help_panel=\"Data selection\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT, rich_help_panel=\"Basic\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment type to use. Recommended are docker or singularity\", rich_help_panel=\"Advanced\"),\n) -&gt; None:\n    # fmt: on\n    output_path = Path(output)\n    output_path.mkdir(parents=True, exist_ok=True)\n    logger.info(f\"Results will be saved to {output_path}\")\n    add_file_handler(output_path / \"minisweagent.log\")\n\n    from datasets import load_dataset\n\n    dataset_path = DATASET_MAPPING.get(subset, subset)\n    logger.info(f\"Loading dataset {dataset_path}, split {split}...\")\n    instances = list(load_dataset(dataset_path, split=split))\n\n    instances = filter_instances(instances, filter_spec=filter_spec, slice_spec=slice_spec, shuffle=shuffle)\n    if not redo_existing and (output_path / \"preds.json\").exists():\n        existing_instances = list(json.loads((output_path / \"preds.json\").read_text()).keys())\n        logger.info(f\"Skipping {len(existing_instances)} existing instances\")\n        instances = [instance for instance in instances if instance[\"instance_id\"] not in existing_instances]\n    logger.info(f\"Running on {len(instances)} instances...\")\n\n    logger.info(f\"Building agent config from specs: {config_spec}\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"environment\": {\"environment_class\": environment_class or UNSET},\n        \"model\": {\"model_name\": model or UNSET, \"model_class\": model_class or UNSET},\n    })\n    config = recursive_merge(*configs)\n\n    progress_manager = RunBatchProgressManager(len(instances), output_path / f\"exit_statuses_{time.time()}.yaml\")\n\n    def process_futures(futures: dict[concurrent.futures.Future, str]):\n        for future in concurrent.futures.as_completed(futures):\n            try:\n                future.result()\n            except concurrent.futures.CancelledError:\n                pass\n            except Exception as e:\n                instance_id = futures[future]\n                logger.error(f\"Error in future for instance {instance_id}: {e}\", exc_info=True)\n                progress_manager.on_uncaught_exception(instance_id, e)\n\n    with Live(progress_manager.render_group, refresh_per_second=4):\n        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n            futures = {\n                executor.submit(process_instance, instance, output_path, config, progress_manager): instance[\n                    \"instance_id\"\n                ]\n                for instance in instances\n            }\n            try:\n                process_futures(futures)\n            except KeyboardInterrupt:\n                logger.info(\"Cancelling all pending jobs. Press ^C again to exit immediately.\")\n                for future in futures:\n                    if not future.running() and not future.done():\n                        future.cancel()\n                process_futures(futures)\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> <code>swebench_single.py</code> run script <ul> <li>Read on GitHub</li> <li>API reference</li> </ul> <pre><code>\"\"\"Run on a single SWE-Bench instance.\"\"\"\n\nfrom pathlib import Path\n\nimport typer\nfrom datasets import load_dataset\n\nfrom minisweagent import global_config_dir\nfrom minisweagent.agents import get_agent\nfrom minisweagent.config import builtin_config_dir, get_config_from_spec\nfrom minisweagent.models import get_model\nfrom minisweagent.run.benchmarks.swebench import (\n    DATASET_MAPPING,\n    evaluate_submission,\n    get_sb_environment,\n)\nfrom minisweagent.utils.log import logger\nfrom minisweagent.utils.serialize import UNSET, recursive_merge\n\nDEFAULT_OUTPUT_FILE = global_config_dir / \"last_swebench_single_run.traj.json\"\nDEFAULT_CONFIG_FILE = builtin_config_dir / \"benchmarks\" / \"swebench.yaml\"\n\napp = typer.Typer(rich_markup_mode=\"rich\", add_completion=False)\n\n_CONFIG_SPEC_HELP_TEXT = \"\"\"Path to config files, filenames, or key-value pairs.\n\n[bold red]IMPORTANT:[/bold red] [red]If you set this option, the default config file will not be used.[/red]\nSo you need to explicitly set it e.g., with [bold green]-c swebench.yaml &lt;other options&gt;[/bold green]\n\nMultiple configs will be recursively merged.\n\nExamples:\n\n[bold red]-c model.model_kwargs.temperature=0[/bold red] [red]You forgot to add the default config file! See above.[/red]\n\n[bold green]-c swebench.yaml -c model.model_kwargs.temperature=0.5[/bold green]\n\n[bold green]-c swebench.yaml -c agent.mode=yolo[/bold green]\n\"\"\"\n\n\n# fmt: off\n@app.command()\ndef main(\n    subset: str = typer.Option(\"lite\", \"--subset\", help=\"SWEBench subset to use or path to a dataset\", rich_help_panel=\"Data selection\"),\n    split: str = typer.Option(\"dev\", \"--split\", help=\"Dataset split\", rich_help_panel=\"Data selection\"),\n    instance_spec: str = typer.Option(0, \"-i\", \"--instance\", help=\"SWE-Bench instance ID or index\", rich_help_panel=\"Data selection\"),\n    model_name: str | None = typer.Option(None, \"-m\", \"--model\", help=\"Model to use\", rich_help_panel=\"Basic\"),\n    model_class: str | None = typer.Option(None, \"--model-class\", help=\"Model class to use (e.g., 'anthropic' or 'minisweagent.models.anthropic.AnthropicModel')\", rich_help_panel=\"Advanced\"),\n    agent_class: str | None = typer.Option(None, \"--agent-class\", help=\"Agent class to use (e.g., 'interactive' or 'minisweagent.agents.interactive.InteractiveAgent')\", rich_help_panel=\"Advanced\"),\n    environment_class: str | None = typer.Option(None, \"--environment-class\", help=\"Environment class to use (e.g., 'docker' or 'minisweagent.environments.docker.DockerEnvironment')\", rich_help_panel=\"Advanced\"),\n    yolo: bool = typer.Option(False, \"-y\", \"--yolo\", help=\"Run without confirmation\"),\n    cost_limit: float | None = typer.Option(None, \"-l\", \"--cost-limit\", help=\"Cost limit. Set to 0 to disable.\"),\n    config_spec: list[str] = typer.Option([str(DEFAULT_CONFIG_FILE)], \"-c\", \"--config\", help=_CONFIG_SPEC_HELP_TEXT, rich_help_panel=\"Basic\"),\n    exit_immediately: bool = typer.Option(False, \"--exit-immediately\", help=\"Exit immediately when the agent wants to finish instead of prompting.\", rich_help_panel=\"Advanced\"),\n    output: Path | None = typer.Option(DEFAULT_OUTPUT_FILE, \"-o\", \"--output\", help=\"Output trajectory file\", rich_help_panel=\"Basic\"),\n) -&gt; None:\n    # fmt: on\n    \"\"\"Run on a single SWE-Bench instance.\"\"\"\n    dataset_path = DATASET_MAPPING.get(subset, subset)\n    logger.info(f\"Loading dataset from {dataset_path}, split {split}...\")\n    instances = {\n        inst[\"instance_id\"]: inst  # type: ignore\n        for inst in load_dataset(dataset_path, split=split)\n    }\n    if instance_spec.isnumeric():\n        instance_spec = sorted(instances.keys())[int(instance_spec)]\n    instance: dict = instances[instance_spec]  # type: ignore\n\n    logger.info(f\"Building agent config from specs: {config_spec}\")\n    configs = [get_config_from_spec(spec) for spec in config_spec]\n    configs.append({\n        \"agent\": {\n            \"agent_class\": agent_class or UNSET,\n            \"mode\": \"yolo\" if yolo else UNSET,\n            \"cost_limit\": cost_limit or UNSET,\n            \"confirm_exit\": False if exit_immediately else UNSET,\n            \"output_path\": output or UNSET,\n        },\n        \"model\": {\n            \"model_class\": model_class or UNSET,\n            \"model_name\": model_name or UNSET,\n        },\n        \"environment\": {\n            \"environment_class\": environment_class or UNSET,\n        },\n    })\n    config = recursive_merge(*configs)\n\n    env = get_sb_environment(config, instance)\n    agent = get_agent(\n        get_model(config=config.get(\"model\", {})),\n        env,\n        config.get(\"agent\", {}),\n        default_type=\"interactive\",\n    )\n    info = agent.run(instance[\"problem_statement\"])\n    submission = info.get(\"submission\", \"\")\n    if submission and info.get(\"exit_status\") == \"Submitted\":\n        evaluate_submission(env, instance, submission)\n\n\nif __name__ == \"__main__\":\n    app()\n</code></pre> bug_report Something broken/unclear? <p>Open an issue on GitHub!</p> help Open-ended discussions <p>Join our Slack!</p>"}]}